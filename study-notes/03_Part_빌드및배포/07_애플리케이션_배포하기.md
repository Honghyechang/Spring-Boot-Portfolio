# 07_애플리케이션_배포하기
<!--
# 첫 작성 
docs: [Ch07] 애플리케이션 배포하기 - 틀작성완료
-->
## 📌 학습 목표
스프링 부트 애플리케이션을 다양한 환경에 배포하는 방법을 익히고, 톰캣을 활용한 전통적인 방식부터 AWS 엘라스틱 빈스토크를 이용한 클라우드 배포, 도커를 활용한 컨테이너 기반 배포, 그리고 GitHub Actions를 통한 CI/CD 자동화까지 모두 아우르는 실전 배포 전략을 체계적으로 학습합니다.

---

## 📚 배포 학습 로드맵

이 챕터는 배포 기술의 진화 과정을 따라가며, 각 단계에서 발생하는 문제점을 인식하고 이를 해결하는 더 나은 방법을 학습하는 방식으로 구성되어 있습니다.

### 🎯 단계별 학습 개요

| 단계 | 환경/도구 | 배포 대상 | 학습 목표 |
|------|-----------|-----------|-----------|
| **1단계** | EC2 (IaaS) | WAR 및 JAR | IaaS 환경에서의 수동 배포 경험. Java, Tomcat 수동 설치 및 설정을 통해 인프라 관리의 복잡성을 체감 |
| **2단계** | Elastic Beanstalk (PaaS) | WAR 및 JAR | PaaS의 편리함 체감. 인프라 자동 관리를 통해 개발자가 애플리케이션에 집중할 수 있는 환경 이해 |
| **3단계** | Docker + Beanstalk | JAR (컨테이너화) | 환경 표준화 및 이식성 확보. Docker를 통한 "어디서나 동일하게 실행되는" 애플리케이션 구축 |
| **4단계** | GitHub Actions + Docker + Beanstalk | JAR (컨테이너화) | CI/CD 파이프라인 자동화. 코드 push만으로 빌드-테스트-배포까지 자동 실행되는 실무 환경 구축 |

---

## 목차
- [7.1 톰캣 배포 (IaaS 환경 실습)](#71-톰캣-배포-iaas-환경-실습)
- [7.2 AWS 클라우드 배포 (PaaS 환경 실습)](#72-aws-클라우드-배포-paas-환경-실습)
- [7.3 도커 배포 (환경 표준화)](#73-도커-배포-환경-표준화)
- [7.4 CI/CD 자동화 (GitHub Actions)](#74-cicd-자동화-git-actions)
---

# 7.1 톰캣 배포 (IaaS 환경 실습)

## 📖 학습 개요

**핵심 주제**: IaaS(Infrastructure as a Service) 환경에서의 수동 배포  
**사용 기술**: Apache Tomcat, AWS EC2, WAR/JAR 파일  
**학습 목표**: 
- WAR와 JAR 파일의 차이점과 배포 방식 이해
- 서버 환경을 처음부터 수동으로 구축하고 관리하는 전 과정 체험
- IaaS 환경의 복잡성과 운영 부담 실감

---

## 7.1.1 Apache Tomcat 기본 개념

### 🔍 Tomcat이란?

Apache Tomcat은 Java 서블릿(Servlet)과 JSP(JavaServer Pages)를 실행할 수 있는 **WAS(Web Application Server)**이자 **서블릿 컨테이너**입니다.

### 📦 WAR vs JAR

| 구분 | WAR (Web Application Archive) | JAR (Java Archive) |
|------|-------------------------------|-------------------|
| **용도** | 외부 WAS(Tomcat 등)에 배포 | 독립 실행 가능한 애플리케이션 |
| **WAS** | 외부 Tomcat 필요 | Tomcat 내장 (Embedded) |
| **배포 방식** | WAS의 webapps 디렉터리에 복사 | `java -jar` 명령으로 직접 실행 |
| **컨텍스트 경로** | 파일명이 컨텍스트 경로가 됨 | 기본 루트(/) 경로 |

---

## 7.1.2 로컬 환경에서 Tomcat 실습

### 1단계: Tomcat 다운로드 및 설치

#### 다운로드

[Apache Tomcat 10 다운로드 페이지](https://tomcat.apache.org/download-10.cgi)에서 **Core: zip** 파일을 다운로드합니다.

```
다운로드 파일: apache-tomcat-10.1.49.zip
압축 해제 위치: C:\Users\ghddm\Downloads\apache-tomcat-10.1.49\
```

#### 📂 Tomcat 디렉터리 구조

압축을 해제하면 다음과 같은 핵심 디렉터리 구조를 확인할 수 있습니다.

```
C:\Users\ghddm\Downloads\apache-tomcat-10.1.49\apache-tomcat-10.1.49
├── bin/          ⚙️ 실행 및 종료 스크립트
├── conf/         📝 설정 파일 (server.xml, web.xml 등)
├── lib/          📚 라이브러리 파일
├── logs/         📜 로그 파일 저장소
├── temp/         🗂️ 임시 파일
├── webapps/      📦 웹 애플리케이션 배포 위치
└── work/         🔧 JSP 컴파일 결과물
```

**핵심 디렉터리 설명**

| 디렉터리 | 역할 | 주요 내용 |
|----------|------|-----------|
| **bin** | 실행 스크립트 모음 | `startup.sh/bat`, `shutdown.sh/bat`, `catalina.sh/bat` |
| **conf** | 톰캣 설정 | `server.xml` (포트, 호스트 설정), `web.xml` (서블릿 기본 설정) |
| **webapps** | 애플리케이션 배포 | WAR 파일을 이곳에 복사하면 자동 배포됨 |
| **logs** | 로그 기록 | `catalina.out` (서버 로그), `localhost_access_log.txt` (접근 로그) |

---

### 2단계: Tomcat 실행 준비

#### ✅ Java 환경 변수 설정

Tomcat은 Java로 만들어진 프로그램이므로 JVM이 필요합니다. 따라서 `JAVA_HOME` 환경 변수를 설정해야 합니다.

**Windows 명령 프롬프트에서 환경 변수 설정**

```cmd
C:\...\apache-tomcat-10.1.49> set JAVA_HOME=C:\Program Files\Eclipse Adoptium\jdk-21.0.8.9-hotspot
C:\...\apache-tomcat-10.1.49> set CATALINA_HOME=C:\Users\ghddm\Downloads\apache-tomcat-10.1.49\apache-tomcat-10.1.49
```

**환경 변수 설명**

| 변수명 | 역할 | 설정 예시 |
|--------|------|-----------|
| `JAVA_HOME` | JDK 설치 경로 지정 | `C:\Program Files\Eclipse Adoptium\jdk-21.0.8.9-hotspot` |
| `CATALINA_HOME` | Tomcat 설치 루트 경로 지정 | `C:\Users\ghddm\Downloads\apache-tomcat-10.1.49\apache-tomcat-10.1.49` |

#### 🌐 한글 깨짐 방지 설정

콘솔 로그에서 한글이 깨지지 않도록 UTF-8 인코딩을 설정합니다.

```cmd
C:\...\bin> chcp 65001
Active code page: 65001
```

---

### 3단계: Tomcat 실행 명령어

#### 🚀 서버 시작 및 종료 명령어

| 목적 | Windows | Linux/macOS | 실행 방식 | 용도 |
|------|---------|-------------|-----------|------|
| **서버 시작** | `startup.bat` | `startup.sh` | 백그라운드 | 일반 운영 환경 |
| **서버 시작** | `catalina.bat run` | `catalina.sh run` | 포그라운드 | 디버깅 및 테스트 (로그 실시간 확인) |
| **서버 종료** | `shutdown.bat` | `shutdown.sh` | - | 서버 정상 종료 |

**실행 예시**

```cmd
C:\...\bin> catalina run
```

이 명령을 실행하면 Tomcat 서버가 시작되고 콘솔에 실시간 로그가 출력됩니다.

---

### 4단계: WAR 파일 배포

#### 📦 WAR 파일 준비 및 배포

Spring Boot 프로젝트에서 빌드한 WAR 파일을 Tomcat의 `webapps` 디렉터리에 복사하기만 하면 자동으로 배포가 시작됩니다.

**중요: 파일명 = 컨텍스트 경로**

WAR 파일의 이름이 매우 중요합니다. 파일명이 **애플리케이션의 컨텍스트 경로**가 되기 때문입니다.

| 파일명 | 접속 URL | 설명 |
|--------|----------|------|
| `hyechang.war` | `http://localhost:8080/hyechang/` | `/hyechang` 컨텍스트로 접근 |
| `ROOT.war` | `http://localhost:8080/` | 루트(`/`) 경로로 접근 |

**배포 디렉터리 구조**

```
C:\...\apache-tomcat-10.1.49\webapps\
├── ROOT/                    (기본 홈페이지)
├── docs/                    (Tomcat 문서)
├── examples/                (예제 앱)
├── manager/                 (관리자 페이지)
├── hyechang.war            ✅ 복사한 WAR 파일
└── ROOT.war                ✅ 루트 경로 배포용
```

**배포 실행**

```cmd
C:\...\webapps> dir

2025-11-14  오전 11:50    <DIR>          .
2025-11-14  오전 11:07    <DIR>          ..
2025-11-14  오전 11:07    <DIR>          docs
2025-11-14  오전 11:07    <DIR>          examples
2025-11-12  오후 02:22        50,577,654 hyechang.war
2025-11-14  오전 11:07    <DIR>          manager
2025-11-14  오전 11:07    <DIR>          ROOT
2025-11-12  오후 02:22        50,577,654 ROOT.war
```

Tomcat 서버가 실행 중이라면 자동으로 WAR 파일의 압축을 풀고 애플리케이션을 배포합니다.

**접속 확인**

- `http://localhost:8080/hyechang/` → hyechang.war 애플리케이션 실행
- `http://localhost:8080/` → ROOT.war 애플리케이션 실행

---

### 💡 로컬 환경 실습 정리

로컬 PC에서 Tomcat을 설치하고 WAR 파일을 배포하는 과정을 통해:
- ✅ Tomcat의 디렉터리 구조와 역할 이해
- ✅ WAR 파일 배포의 기본 원리 학습
- ✅ 컨텍스트 경로의 개념 파악

**하지만 실제 웹 서비스 운영을 위해서는 외부에서 접속 가능한 서버가 필요합니다.**

다음 단계에서는 이 모든 과정을 **AWS EC2 인스턴스(클라우드 서버)**에서 직접 구현해봅니다.

---

## 7.1.3 EC2 인스턴스에 WAR 파일 배포

이제 AWS의 가상 서버 환경에서 처음부터 끝까지 수동으로 배포 환경을 구축해봅니다.

### 1단계: EC2 인스턴스 생성

#### AWS 콘솔에서 EC2 인스턴스 생성

| 설정 항목 | 선택 값 | 설명 |
|-----------|---------|------|
| **AMI** | Amazon Linux 2023 | 최신 리눅스 배포판 |
| **인스턴스 타입** | t3.micro | 무료 티어 사용 가능 |
| **키 페어** | springTomcatServer.pem | SSH 접속용 개인 키 (자동 다운로드) |
| **보안 그룹** | 22번 포트 (SSH), 8080번 포트 (Tomcat) 허용 | 외부 접속을 위한 포트 개방 |

**보안 그룹 인바운드 규칙**

| 타입 | 포트 | 소스 | 용도 |
|------|------|------|------|
| SSH | 22 | 0.0.0.0/0 | SSH 터미널 접속 |
| Custom TCP | 8080 | 0.0.0.0/0 | Tomcat 웹 서버 접근 |

인스턴스 생성 후 **퍼블릭 IP**를 확인합니다. (예: `3.38.106.137`)

---

### 2단계: SSH로 EC2 인스턴스 접속

#### 💻 PowerShell에서 SSH 접속

다운로드받은 `.pem` 키 파일을 사용하여 EC2 인스턴스에 원격 접속합니다.

```powershell
PS C:\Users\ghddm> ssh -i "C:\Users\ghddm\Downloads\springTomcatServer.pem" ec2-user@3.38.106.137
```

**접속 과정**

```
The authenticity of host '3.38.106.137 (3.38.106.137)' can't be established.
ED25519 key fingerprint is SHA256:ITRFzyYPw0fMC+tAnuUDDZ+3BxfPAKvaUOYLvgnkGdY.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
```

`yes` 입력 후 연결이 성공하면:

```
   ,     #_
   ~\_  ####_        Amazon Linux 2023
  ~~  \_#####\
  ~~     \###|
  ~~       \#/ ___   https://aws.amazon.com/linux/amazon-linux-2023
   ~~       V~' '->
    ~~~         /
      ~~._.   _/
         _/ _/
       _/m/'
[ec2-user@ip-172-31-0-60 ~]$
```

**✅ SSH 연결 성공!** 이제 EC2 리눅스 서버에서 명령어를 실행할 수 있습니다.

---

### 3단계: JDK 설치

Tomcat을 실행하기 위해서는 Java가 필수입니다.

#### ☕ Amazon Corretto JDK 21 설치

```bash
# 시스템 패키지 업데이트
[ec2-user@ip-172-31-0-60 ~]$ sudo dnf update -y

# JDK 21 설치
[ec2-user@ip-172-31-0-60 ~]$ sudo dnf install java-21-amazon-corretto-devel -y
```

#### 🔧 JAVA_HOME 환경 변수 설정

**JDK 설치 경로 확인**

```bash
[ec2-user@ip-172-31-0-60 ~]$ readlink -f /usr/bin/java | sed "s:bin/java::"
/usr/lib/jvm/java-21-amazon-corretto.x86_64/
```

**환경 변수 영구 등록**

```bash
# 기존 설정 삭제 (있다면)
[ec2-user@ip-172-31-0-60 ~]$ sed -i '/JAVA_HOME/d' ~/.bashrc
[ec2-user@ip-172-31-0-60 ~]$ sed -i '/PATH=$PATH:$JAVA_HOME/d' ~/.bashrc

# 새로운 JAVA_HOME 설정 추가
[ec2-user@ip-172-31-0-60 ~]$ echo 'export JAVA_HOME="/usr/lib/jvm/java-21-amazon-corretto.x86_64"' >> ~/.bashrc
[ec2-user@ip-172-31-0-60 ~]$ echo 'export PATH=$PATH:$JAVA_HOME/bin' >> ~/.bashrc

# 설정 즉시 적용
[ec2-user@ip-172-31-0-60 ~]$ source ~/.bashrc
```

**설정 확인**

```bash
[ec2-user@ip-172-31-0-60 ~]$ echo $JAVA_HOME
/usr/lib/jvm/java-21-amazon-corretto.x86_64

[ec2-user@ip-172-31-0-60 ~]$ java -version
openjdk version "21.0.9" 2024-10-15 LTS
OpenJDK Runtime Environment Corretto-21.0.9.10.1 (build 21.0.9+10-LTS)
OpenJDK 64-Bit Server VM Corretto-21.0.9.10.1 (build 21.0.9+10-LTS, mixed mode, sharing)
```

✅ **JDK 설치 및 환경 변수 설정 완료**

---

### 4단계: Tomcat 설치

#### 📥 Tomcat 10.1.49 다운로드 및 설치

```bash
# /opt 디렉터리로 이동 (소프트웨어 설치 표준 위치)
[ec2-user@ip-172-31-0-60 ~]$ cd /opt

# Tomcat 다운로드
[ec2-user@ip-172-31-0-60 opt]$ sudo wget https://dlcdn.apache.org/tomcat/tomcat-10/v10.1.49/bin/apache-tomcat-10.1.49.tar.gz

# 압축 해제
[ec2-user@ip-172-31-0-60 opt]$ sudo tar -xzf apache-tomcat-10.1.49.tar.gz

# 디렉터리 이름 변경 (관리 편의성)
[ec2-user@ip-172-31-0-60 opt]$ sudo mv apache-tomcat-10.1.49 tomcat

# 소유권 변경 (ec2-user가 관리할 수 있도록)
[ec2-user@ip-172-31-0-60 opt]$ sudo chown -R ec2-user:ec2-user tomcat
```

#### 🔧 CATALINA_HOME 환경 변수 설정

```bash
# 홈 디렉터리로 이동
[ec2-user@ip-172-31-0-60 opt]$ cd ~

# CATALINA_HOME 설정 추가
[ec2-user@ip-172-31-0-60 ~]$ echo 'export CATALINA_HOME="/opt/tomcat"' >> ~/.bashrc
[ec2-user@ip-172-31-0-60 ~]$ echo 'export PATH=$PATH:$CATALINA_HOME/bin' >> ~/.bashrc

# 설정 즉시 적용
[ec2-user@ip-172-31-0-60 ~]$ source ~/.bashrc
```

**설정 확인**

```bash
[ec2-user@ip-172-31-0-60 ~]$ echo $CATALINA_HOME
/opt/tomcat
```

✅ **Tomcat 설치 및 환경 변수 설정 완료**

---

### 5단계: WAR 파일 전송

이제 로컬 PC에서 빌드한 WAR 파일을 EC2 서버로 전송합니다.

#### 📤 SCP를 이용한 파일 전송

**로컬 PowerShell에서 실행** (SSH 터미널이 아님!)

```powershell
PS C:\Users\ghddm> scp -i "C:\Users\ghddm\Downloads\springTomcatServer.pem" "C:\Users\ghddm\Desktop\SpringBoot\Spring-Boot-Portfolio\spring-boot-project\Spring-Board-Project\build\libs\Spring-Board-Project-0.0.1-SNAPSHOT-plain.war" ec2-user@3.38.106.137:/tmp/hyechang.war
```

**전송 과정 확인**

```
Spring-Board-Project-0.0.1-SNAPSHOT-plain.war   0%    0     0.0KB/s   --:--
Spring-Board-Project-0.0.1-SNAPSHOT-plain.war   2% 1056KB   1.0MB/s   00:46
Spring-Board-Project-0.0.1-SNAPSHOT-plain.war   4% 1984KB   1.0MB/s   00:46
...
Spring-Board-Project-0.0.1-SNAPSHOT-plain.war 100%   48MB 873.6KB/s   00:56
```

✅ **파일 전송 완료**

---

### 6단계: WAR 파일 배포

#### 📦 webapps 디렉터리로 이동

**SSH 터미널로 돌아와서 실행**

```bash
# /tmp에 파일이 있는지 확인
[ec2-user@ip-172-31-0-60 ~]$ cd /tmp
[ec2-user@ip-172-31-0-60 tmp]$ ls
hyechang.war
hsperfdata_ec2-user
...

# WAR 파일을 Tomcat의 webapps 디렉터리로 이동
[ec2-user@ip-172-31-0-60 tmp]$ sudo mv /tmp/hyechang.war /opt/tomcat/webapps/

# 이동 확인
[ec2-user@ip-172-31-0-60 tmp]$ cd /opt/tomcat/webapps
[ec2-user@ip-172-31-0-60 webapps]$ ls
ROOT  docs  examples  host-manager  hyechang.war  manager
```

✅ **WAR 파일이 webapps 디렉터리에 정상 배치됨**

---

### 7단계: Tomcat 서버 실행

#### 🚀 서버 시작

```bash
[ec2-user@ip-172-31-0-60 webapps]$ startup.sh
Using CATALINA_BASE:   /opt/tomcat
Using CATALINA_HOME:   /opt/tomcat
Using CATALINA_TMPDIR: /opt/tomcat/temp
Using JRE_HOME:        /usr/lib/jvm/java-21-amazon-corretto.x86_64
Using CLASSPATH:       /opt/tomcat/bin/bootstrap.jar:/opt/tomcat/bin/tomcat-juli.jar
Using CATALINA_OPTS:
Tomcat started.
```

**서버 상태 확인**

```bash
[ec2-user@ip-172-31-0-60 webapps]$ ps -ef | grep tomcat
ec2-user  12345  ...  java -Djava.util.logging.config.file=/opt/tomcat/conf/logging.properties ...
```

✅ **Tomcat 서버 실행 성공!**

---

### 8단계: 외부 접속 확인

#### 🌐 웹 브라우저에서 접속

```
http://3.38.106.137:8080/hyechang/
```

애플리케이션이 정상적으로 표시되면 **배포 성공**입니다! 🎉

#### 🛑 서버 종료 방법

```bash
[ec2-user@ip-172-31-0-60 ~]$ shutdown.sh
Using CATALINA_BASE:   /opt/tomcat
Using CATALINA_HOME:   /opt/tomcat
Using CATALINA_TMPDIR: /opt/tomcat/temp
Using JRE_HOME:        /usr/lib/jvm/java-21-amazon-corretto.x86_64
Using CLASSPATH:       /opt/tomcat/bin/bootstrap.jar:/opt/tomcat/bin/tomcat-juli.jar
Using CATALINA_OPTS:
Tomcat stopped.
```

---

### 📊 EC2 WAR 배포 전체 흐름 요약

| 단계 | 실행 환경 | 주요 작업 | 명령어 |
|------|-----------|-----------|--------|
| 1 | AWS 콘솔 | EC2 인스턴스 생성 | 수동 설정 |
| 2 | PowerShell | SSH 접속 | `ssh -i [키] ec2-user@[IP]` |
| 3 | EC2 | JDK 설치 | `sudo dnf install java-21-amazon-corretto-devel -y` |
| 4 | EC2 | Tomcat 설치 | `wget ... && tar -xzf ... && mv ...` |
| 5 | EC2 | 환경 변수 설정 | `echo 'export JAVA_HOME=...' >> ~/.bashrc` |
| 6 | PowerShell | WAR 파일 전송 | `scp -i [키] [파일] ec2-user@[IP]:/tmp/` |
| 7 | EC2 | webapps 배치 | `sudo mv /tmp/hyechang.war /opt/tomcat/webapps/` |
| 8 | EC2 | 서버 실행 | `startup.sh` |
| 9 | 브라우저 | 접속 확인 | `http://[IP]:8080/hyechang/` |

---

## 7.1.4 EC2 인스턴스에 JAR 파일 배포

WAR는 외부 Tomcat이 필요했지만, JAR는 **내장 Tomcat**을 포함하고 있어 독립 실행이 가능합니다.

### 1단계: JAR 파일 전송

#### 📤 SCP로 JAR 파일 전송

**로컬 PowerShell에서 실행**

```powershell
PS C:\Users\ghddm> scp -i "C:\Users\ghddm\Downloads\springTomcatServer.pem" "C:\Users\ghddm\Desktop\SpringBoot\Spring-Boot-Portfolio\spring-boot-project\Spring-Board-Project\build\libs\Spring-Board-Project-0.0.1-SNAPSHOT.jar" ec2-user@3.38.106.137:~/hyechang.jar
```

**전송 결과**

```
Spring-Board-Project-0.0.1-SNAPSHOT.jar   100%   58MB   1.8MB/s   00:32
```

#### ✅ 전송 확인

**SSH 터미널에서 확인**

```bash
[ec2-user@ip-172-31-0-60 ~]$ cd ~/
[ec2-user@ip-172-31-0-60 ~]$ ls
hyechang.jar
```

---

### 2단계: JAR 파일 실행

#### 🚀 백그라운드 실행 (서버 운영 방식)

```bash
[ec2-user@ip-172-31-0-60 ~]$ nohup java -jar hyechang.jar > application.log 2>&1 &
[1] 27717
```

**명령어 상세 설명**

| 부분 | 역할 | 설명 |
|------|------|------|
| `java -jar hyechang.jar` | 실행 명령 | JVM이 JAR 파일 (내장 Tomcat 포함)을 실행 |
| `nohup` | 영구 실행 | SSH 세션 종료 후에도 프로세스 유지 (No Hang Up) |
| `> application.log` | 로그 저장 | 표준 출력을 파일에 기록 |
| `2>&1` | 에러 리디렉션 | 표준 에러도 같은 파일에 기록 |
| `&` | 백그라운드 실행 | 터미널이 다른 명령어를 받을 수 있도록 백그라운드 실행 |

#### 📋 실행 프로세스 확인

```bash
[ec2-user@ip-172-31-0-60 ~]$ ps -ef | grep java | grep hyechang.jar
ec2-user   27717    2386  1 05:15 pts/1    00:00:25 java -jar hyechang.jar
```

**PID(Process ID) 27717**로 실행 중임을 확인할 수 있습니다.

---

### 3단계: 외부 접속 확인

#### 🌐 웹 브라우저에서 접속

```
http://3.38.106.137:8080/
```

**JAR 파일은 기본적으로 루트(`/`) 경로로 실행됩니다.**

애플리케이션이 정상 표시되면 **배포 성공**입니다! 🎉

---

### 4단계: 서버 종료 방법

#### 🛑 프로세스 종료

**1. 실행 중인 프로세스 찾기**

```bash
[ec2-user@ip-172-31-0-60 ~]$ ps -ef | grep java | grep hyechang.jar
ec2-user   27717    2386  1 05:15 pts/1    00:00:25 java -jar hyechang.jar
```

**2. PID를 사용하여 강제 종료**

```bash
[ec2-user@ip-172-31-0-60 ~]$ kill -9 27717
```

**3. 종료 확인**

```bash
[ec2-user@ip-172-31-0-60 ~]$ ps -ef | grep java | grep hyechang.jar
(결과 없음)
```

✅ **프로세스 종료 완료**

---

### 📊 JAR vs WAR 배포 비교

| 비교 항목 | WAR 배포 | JAR 배포 |
|-----------|----------|----------|
| **WAS 필요** | ⭕ Tomcat 별도 설치 필요 | ❌ 내장 Tomcat 포함 |
| **배포 위치** | `/opt/tomcat/webapps/` | 아무 디렉터리나 가능 (`~/`) |
| **실행 명령** | `startup.sh` (Tomcat 구동) | `java -jar hyechang.jar` |
| **컨텍스트 경로** | 파일명에 따라 결정 (`/hyechang`) | 기본 루트 (`/`) |
| **로그 위치** | `/opt/tomcat/logs/` | `application.log` (지정한 위치) |
| **관리 복잡도** | 높음 (Tomcat 설정 관리 필요) | 낮음 (단순 실행) |
| **포트 변경** | `server.xml` 수정 | `application.properties` 또는 실행 옵션 |

---

## 7.1.5 IaaS 배포의 문제점과 한계

지금까지 EC2 인스턴스에서 수동으로 환경을 구축하고 애플리케이션을 배포하는 전 과정을 경험했습니다. 이 과정을 통해 **IaaS(Infrastructure as a Service) 환경의 본질적인 문제점**을 직접 체감할 수 있었습니다.

### 🚨 주요 문제점

#### 1. 수동 환경 구축의 번거로움

**매번 반복해야 하는 작업들**

```bash
# 서버마다 매번 반복
sudo dnf update -y
sudo dnf install java-21-amazon-corretto-devel -y
cd /opt
sudo wget https://dlcdn.apache.org/tomcat/...
sudo tar -xzf apache-tomcat-10.1.49.tar.gz
sudo mv apache-tomcat-10.1.49 tomcat
sudo chown -R ec2-user:ec2-user tomcat
echo 'export JAVA_HOME=...' >> ~/.bashrc
echo 'export CATALINA_HOME=...' >> ~/.bashrc
source ~/.bashrc
```

**문제점:**
- 서버를 새로 만들 때마다 동일한 설정을 반복해야 함
- 실수로 한 단계를 빠뜨리면 전체 배포 실패
- 설정 과정이 길고 복잡하여 시간 소모가 큼

---

#### 2. 환경 불일치 문제

**로컬 vs 서버 환경 차이**

| 환경 | OS | Java 버전 | Tomcat 버전 | 라이브러리 |
|------|----|-----------|-----------|-----------|
| **로컬 개발** | Windows | JDK 21.0.8 | 10.1.49 | 특정 버전 |
| **EC2 서버** | Amazon Linux | JDK 21.0.9 | 10.1.49 | 다른 버전? |
| **다른 서버** | Ubuntu | JDK 17? | 9.x? | 또 다른 버전? |

**발생 가능한 문제:**
- "내 컴퓨터에서는 잘 되는데 서버에서는 안 돼요" 현상
- Java 버전 차이로 인한 호환성 문제
- 라이브러리 의존성 충돌
- OS별 경로 및 명령어 차이

---

#### 3. 확장성의 어려움

**시나리오: 트래픽 증가로 서버 3대 추가 필요**

```
기존: EC2 1대
↓
필요: EC2 4대 (기존 1대 + 신규 3대)
```

**해야 할 작업:**
- 새로운 EC2 인스턴스 3대 생성
- 각 서버마다 JDK 설치 (3번 반복)
- 각 서버마다 Tomcat 설치 및 설정 (3번 반복)
- 각 서버마다 환경 변수 설정 (3번 반복)
- 각 서버마다 WAR/JAR 파일 전송 및 배포 (3번 반복)
- 로드 밸런서 설정 추가

---

#### 4. 운영 부담 증가

**지속적으로 관리해야 하는 항목들**

| 관리 항목 | 작업 내용 | 빈도 |
|----------|-----------|------|
| **OS 패치** | 보안 업데이트 및 버그 수정 | 월 1~2회 |
| **Java 업데이트** | 새 버전 설치 및 환경 변수 재설정 | 분기별 |
| **Tomcat 업데이트** | 보안 패치 및 버전 업그레이드 | 필요 시 |
| **디스크 관리** | 로그 파일 정리, 디스크 용량 모니터링 | 주간 |
| **프로세스 모니터링** | 서버 다운 여부 확인 및 재시작 | 24시간 |
| **백업** | 애플리케이션 및 데이터 백업 | 일간 |

**문제점:**
- 개발자가 인프라 관리에 많은 시간을 소비
- 애플리케이션 개발보다 서버 운영에 더 많은 리소스 투입
- 휴먼 에러 발생 가능성 높음

---

#### 5. 보안 관리의 복잡성

**직접 관리해야 하는 보안 요소**

```bash
# 방화벽 설정
sudo firewall-cmd --add-port=8080/tcp --permanent

# SSL 인증서 설치 및 갱신
sudo certbot renew

# 사용자 권한 관리
sudo useradd deploy
sudo usermod -aG wheel deploy

# 포트 변경
sudo vi /opt/tomcat/conf/server.xml
```

**문제점:**
- 보안 설정 누락 시 해킹 위험
- SSL 인증서 만료 관리
- 방화벽 규칙 실수로 서비스 중단 가능

---

#### 6. 배포 프로세스의 비효율성

**현재 배포 프로세스**

```
1. 로컬에서 빌드 (Gradle/Maven)
   ↓
2. WAR/JAR 파일 생성
   ↓
3. SCP로 EC2에 파일 전송 (PowerShell)
   ↓
4. SSH로 EC2 접속
   ↓
5. 기존 서버 종료
   ↓
6. 파일 이동/배치
   ↓
7. 서버 재시작
   ↓
8. 브라우저에서 테스트
```

**문제점:**
- 최소 8단계의 수동 작업 필요
- 각 단계에서 실수 가능성 존재
- 배포 시간 약 10~15분 소요
- 배포 중 서비스 중단 (다운타임 발생)

---

#### 7. 모니터링 및 로그 관리의 어려움

**로그 확인 방법**

```bash
# Tomcat WAR 배포 시
[ec2-user@ip-172-31-0-60 ~]$ tail -f /opt/tomcat/logs/catalina.out

# JAR 배포 시
[ec2-user@ip-172-31-0-60 ~]$ tail -f ~/application.log
```

**문제점:**
- 서버마다 SSH로 접속하여 로그 확인 필요
- 여러 서버의 로그를 통합 관리 불가
- 에러 발생 시 실시간 알림 없음
- 로그 파일이 계속 쌓여 디스크 용량 부족 가능

---

### 📊 IaaS 배포의 한계 종합

| 문제 영역 | 구체적 문제점 | 영향 |
|----------|--------------|------|
| **시간** | 초기 설정 시간 증가| 개발 생산성 저하 |
| **비용** | 서버 관리 인력 필요, 시간당 비용 증가 | 운영 비용 증가 |
| **안정성** | 수동 작업으로 인한 휴먼 에러 | 서비스 중단 위험 |
| **확장성** | 서버 추가 시 동일 작업 반복 | 빠른 확장 불가 |
| **일관성** | 환경 차이로 인한 예측 불가능한 문제 | 디버깅 어려움 |

---

### 🎯 다음 단계로: PaaS의 필요성

이러한 모든 문제점들을 해결하기 위해 등장한 것이 바로 **PaaS(Platform as a Service)**입니다.

#### PaaS가 해결하는 문제들

| IaaS의 문제 | PaaS의 해결책 |
|------------|-------------|
| 수동 환경 구축 | 플랫폼이 자동으로 Java, Tomcat 등 설치 |
| 환경 불일치 | 표준화된 실행 환경 제공 |
| 확장 어려움 | 자동 스케일링 (트래픽에 따라 서버 자동 증감) |
| 운영 부담 | OS 패치, 보안 업데이트 자동 처리 |
| 배포 복잡 | WAR/JAR 파일만 업로드하면 자동 배포 |
| 모니터링 부족 | 통합 모니터링 대시보드 제공 |

---

### 📝 실습을 통해 배운 핵심 교훈

#### ✅ 기술적 이해

- **WAR vs JAR의 차이**: 외부 WAS 필요 여부, 컨텍스트 경로, 실행 방식
- **Tomcat의 구조**: bin, conf, webapps, logs 디렉터리의 역할
- **리눅스 서버 관리**: SSH 접속, 패키지 설치, 환경 변수 설정
- **배포의 기본 원리**: 빌드 → 전송 → 배치 → 실행 → 확인

#### ✅ 운영의 현실

- **수동 작업의 한계**: 반복 작업은 자동화가 필수
- **환경 일관성의 중요성**: "내 컴퓨터에서는 되는데" 문제의 근본 원인
- **확장성 고려의 필요성**: 서버 1대 관리와 100대 관리는 완전히 다른 문제
- **개발자의 역할 범위**: 애플리케이션 개발에 집중할 수 있어야 함

---


## 📚 7.1 톰캣 배포 섹션 정리

### ✅ 완료한 학습 내용

| 번호 | 학습 주제 | 핵심 내용 |
|------|----------|-----------|
| 1 | **Tomcat 기본 개념** | WAS의 역할, WAR vs JAR의 차이 |
| 2 | **로컬 Tomcat 실습** | Windows 환경에서 설치, 설정, WAR 배포 |
| 3 | **EC2 환경 구축** | 인스턴스 생성, SSH 접속, 보안 그룹 설정 |
| 4 | **EC2에 WAR 배포** | JDK/Tomcat 수동 설치, WAR 전송 및 배포 |
| 5 | **EC2에 JAR 배포** | 내장 WAS 활용, 백그라운드 실행 |
| 6 | **IaaS 한계 분석** | 수동 관리의 문제점, PaaS 필요성 인식 |

### 🎯 획득한 역량

- ✅ **기본 배포 원리 이해**: 빌드부터 실행까지 전체 흐름 파악
- ✅ **리눅스 서버 관리 경험**: SSH, 패키지 관리, 환경 변수 설정
- ✅ **IaaS 한계 체감**: 자동화와 표준화의 필요성 인식
- ✅ **실전 배포 경험**: 실제 클라우드 환경에서 애플리케이션 서비스


---

# 7.2 AWS 클라우드 배포 (PaaS 환경 실습)

## 📖 학습 개요

**핵심 주제**: PaaS(Platform as a Service) 환경에서의 자동화된 배포  
**사용 기술**: AWS Elastic Beanstalk, Amazon RDS, 환경 변수 기반 프로파일 관리  
**학습 목표**: 
- IaaS 환경의 수동 관리 부담을 해소하는 PaaS의 핵심 가치 체험
- 하나의 JAR 파일로 개발/테스트/운영 환경에 유연하게 배포하는 방법 습득
- 환경 변수와 스프링 프로파일을 결합한 실전 배포 전략 이해

---

## 7.2.1 Elastic Beanstalk란?

### 🔍 PaaS의 등장 배경

7.1장에서 경험한 EC2(IaaS) 배포의 문제점들을 다시 떠올려봅시다:

**IaaS의 근본적인 문제점**
- 서버를 새로 만들 때마다 JDK, Tomcat 설치 반복
- 환경 변수 설정, 포트 구성 등 수동 작업 필수
- 로드 밸런서, 오토 스케일링 등 인프라 직접 구축 및 관리
- 서버 추가 시 동일한 설정을 반복해야 하는 비효율성

이러한 문제를 근본적으로 해결하기 위해 등장한 것이 바로 **PaaS(Platform as a Service)**입니다.

### 🚀 Elastic Beanstalk의 핵심 가치

**AWS Elastic Beanstalk(EB)**는 개발자가 애플리케이션 코드에만 집중할 수 있도록, 복잡한 인프라 관리를 AWS가 대신 처리해주는 PaaS 서비스입니다.

| 항목 | EC2 (IaaS) | Elastic Beanstalk (PaaS) |
|------|------------|--------------------------|
| **환경 구성** | JDK, Tomcat 수동 설치 및 설정 | 플랫폼 선택만으로 자동 설치 |
| **배포** | SCP로 파일 전송, 수동 배치 | JAR/WAR 업로드만으로 자동 배포 |
| **확장** | 서버 추가 시 모든 설정 반복 | 로드 밸런서, 오토 스케일링 자동 구성 |
| **관리** | OS 패치, 보안 업데이트 직접 관리 | AWS가 자동으로 관리 |
| **모니터링** | 별도 도구 설치 및 설정 필요 | CloudWatch 통합 모니터링 제공 |

**비유로 이해하기**
- **IaaS (EC2)**: 빈 땅을 받아 직접 집을 짓고, 전기/수도를 연결하고, 가구를 배치하는 것
- **PaaS (EB)**: 원하는 옵션(플랫폼)을 선택하면 이미 모든 것이 갖춰진 아파트에 입주하는 것

---

## 7.2.2 EB와 Docker의 역할 차이 이해

다음 장에서 배울 Docker와 EB는 서로 다른 문제를 해결합니다. 이 차이를 명확히 이해하는 것이 중요합니다.

### 📦 해결하는 문제의 차이

| 구분 | AWS Elastic Beanstalk (EB) | Docker (컨테이너) |
|------|---------------------------|-------------------|
| **핵심 개념** | PaaS (Platform as a Service) | 환경 패키징 및 표준화 |
| **해결 문제** | 인프라/플랫폼 관리 자동화 및 운영 부담 해소 | 환경 불일치 및 이식성(Portability) 확보 |
| **해결 방식** | 플랫폼 선택 시 AWS가 대신 설치/설정 및 로드 밸런서/오토 스케일링 등 인프라 자동 관리 | 애플리케이션과 실행 환경을 하나의 이미지로 묶어 어디서든 동일하게 실행 |
| **개발자 역할** | 애플리케이션 코드(WAR/JAR)만 제공 | 실행 환경이 담긴 Docker Image/Dockerfile 제공 |

### 🎯 비유로 이해하기

| 기술 | 비유 | 설명 |
|------|------|------|
| **EB (PaaS)** | 🏨 풀옵션 임대 아파트 | 원하는 플랫폼(가구/옵션)을 선택하면 집주인(AWS)이 모든 환경을 준비해 줌 |
| **Docker** | 📦 여행용 캐리어 | 실행 환경(옷, 생필품)을 모두 캐리어(이미지)에 담아, 어느 나라(서버)를 가도 그대로 사용 가능 |

### 🔧 버전 관리의 차이

**EB의 버전 관리 (편리하지만 제한적)**
- **설치 주체**: AWS (EB 서비스 내부 로직)
- **버전 선택**: 플랫폼 선택 시 EB가 제공하는 최신 안정 버전 또는 지정 가능한 범위 내에서 선택
- **예시**: "Java 21 with Amazon Linux 2023" 플랫폼 선택 → EB가 특정 Corretto JDK 21 버전 자동 설치
- **한계**: 특정 마이너 버전(예: `JDK 21.0.8`)까지 세밀하게 지정 불가

**Docker의 버전 관리 (완벽한 통제)**
- **설치 주체**: 개발자 (Dockerfile 내 정의)
- **버전 선택**: Dockerfile에서 `FROM` 명령어로 OS, JDK, Tomcat의 특정 버전을 픽스
- **예시**: 
  ```dockerfile
  FROM openjdk:21-jdk-slim
  FROM tomcat:10.1.20-jre21-temurin-jammy
  ```
- **장점**: 모든 구성 요소의 버전을 개발자가 명시적으로 지정하고 통제 가능

### 🤝 실무에서의 혼합 사용

| 배포 방식 | 설명 | 특징 |
|-----------|------|------|
| **EB + WAR/JAR** | 개발자는 WAR/JAR만 업로드, EB가 JDK/Tomcat 자동 설치 | 간편하지만 버전 통제 약함 |
| **EB + Docker** | Dockerfile 또는 Docker 이미지를 EB에 제공, EB는 Docker 런타임만 설치하고 컨테이너 실행 | 편리함 + 완벽한 버전 통제 |

**결론**: 
- **EB**는 "서버를 개설할 때마다 JDK, Tomcat, 환경변수 설정 등을 자동으로 작성"
- **Docker**는 "구체적인 JDK, Tomcat 버전을 포함한 환경을 컨테이너화"
- **혼합 사용**이 실무에서 가장 권장되는 배포 전략

---

## 7.2.3 EB 환경 구축 사전 준비

EB를 사용하기 전에 두 가지 핵심 인프라를 먼저 구축해야 합니다.

### 1️⃣ VPC (Virtual Private Cloud) 생성

#### 📌 VPC란 무엇인가?

**VPC (Virtual Private Cloud)**는 AWS 클라우드에서 사용자만을 위한 독립적이고 격리된 가상 네트워크 환경입니다.

| 개념 | 설명 |
|------|------|
| **가상 사설 네트워크** | 전통적인 데이터센터의 네트워크 환경(라우터, 스위치, IP 대역)을 AWS 클라우드 위에 소프트웨어적으로 구현 |
| **IP 주소 체계 정의** | VPC에 속한 모든 리소스(EC2, RDS 등)가 사용할 사설 IP 주소 범위를 직접 지정 (예: `10.0.0.0/16`) |
| **네트워크 격리** | 사용자의 리소스를 다른 AWS 사용자의 리소스와 논리적으로 분리하여 보안 강화 |
| **서브넷 분할** | Public(인터넷 연결 허용)과 Private(인터넷 연결 차단) 구역으로 나눠서 보안 수준이 다른 리소스 분리 배치 |

#### 🎯 EB 사용 전 VPC를 설정하는 이유

| 이유 | 설명 |
|------|------|
| **보안 강화** | DB 서버(RDS)는 외부 인터넷 접속이 차단된 Private Subnet에 배치하여 보호 |
| **네트워크 일관성** | 개발, 테스트, 운영 등 모든 환경에서 동일하고 표준화된 VPC 구조 재사용 |
| **IP 충돌 방지** | 원하는 IP 대역을 명시적으로 지정하여, 나중에 다른 AWS 환경과 연결 시 충돌 방지 |

> **참고**: 기본 VPC를 사용해도 되지만, 실제 운영 환경에서는 보안과 제어를 위해 사용자 지정 VPC를 설정하는 것이 필수적입니다.

#### 🛠️ VPC 생성 방법

**1단계: VPC 콘솔 접속**
- AWS 콘솔에서 `VPC` 검색 → VPC 대시보드 → `VPC 생성` 클릭

**2단계: 생성할 리소스 선택**
```
생성할 리소스: VPC 및 기타 네트워킹 리소스
```

이 옵션을 선택하면 VPC와 함께 필요한 서브넷, 라우팅 테이블, 인터넷 게이트웨이 등이 한 번에 생성됩니다.

**3단계: 이름 태그 자동 생성 설정**
```
이름 태그 자동 생성: 활성화
값: hyechangSpring
```

이름 태그를 설정하면 VPC뿐만 아니라 함께 생성되는 모든 리소스의 이름에 태그가 자동으로 추가되어 나중에 VPC 관련 리소스를 쉽게 구분할 수 있습니다.

**4단계: 생성 완료**
- 나머지 설정은 기본값 유지
- `VPC 생성` 버튼 클릭

#### 📂 생성된 VPC 구조

```
hyechangSpring-vpc
├── Public Subnet 1 (ap-northeast-2a)   # 웹 서버(EC2) 배치
├── Public Subnet 2 (ap-northeast-2c)   # 로드 밸런서, 고가용성 확보
├── Private Subnet 1 (ap-northeast-2a)  # 데이터베이스(RDS) 배치
└── Private Subnet 2 (ap-northeast-2c)  # RDS 이중화
```

**서브넷 활용 원칙**
| 서브넷 타입 | 배치 리소스 | 특징 |
|------------|------------|------|
| **Public Subnet** | 웹 서버(EC2), 로드 밸런서 | 인터넷과 연결, 퍼블릭 IP 할당 가능 |
| **Private Subnet** | 데이터베이스(RDS) | 인터넷 접속 차단, 내부 통신만 허용 |

**고가용성을 위한 2개의 서브넷**
- 각 타입(Public/Private)마다 2개씩 생성되는 이유는 **가용 영역(Availability Zone, AZ)**에 따른 분산 때문입니다
- 하나의 AZ에 문제가 생겨도 다른 AZ에서 서비스를 계속할 수 있도록 설계

---

### 2️⃣ IAM 역할 생성

#### 🔑 IAM이란?

**IAM (Identity and Access Management)**은 AWS 자원에 접근하고 사용할 수 있는 권한을 관리하는 AWS의 핵심 보안 서비스입니다.

**핵심 개념**: IAM은 **"누가(사용자, 서비스, 리소스), 무엇을(EC2, S3, RDS), 어떻게(읽기, 쓰기, 생성) 할 수 있는지"**를 정의하고 통제합니다.

#### 🎯 EB에 필요한 두 가지 IAM 역할

EB 환경을 생성하려면 두 가지 역할이 필요합니다:

| 역할 | 주체 (권한을 받는 대상) | 역할 (무엇을 하는가?) | 생성 시기 |
|------|----------------------|-------------------|----------|
| **1. EB 서비스 롤** | Elastic Beanstalk 서비스 | 환경 구축 및 관리 (EC2 생성, JDK 설치, 로드 밸런서 설정 등) | EB 생성 시 함께 만들 수 있음 |
| **2. EC2 인스턴스 프로파일** | EB가 생성한 EC2 인스턴스 | 애플리케이션 실행 중 AWS 리소스 접근 (S3 파일 읽기, CloudWatch에 로그 쓰기 등) | **사전 생성 필수** |

#### 🔧 EB 서비스 롤

**역할 설명**
```
"EB야, 네가 이 환경을 자동으로 설정하고 관리할 수 있는 권한을 내가 줄게!"
```

- **권한 부여 대상**: Elastic Beanstalk 서비스 자체
- **역할**: EB가 사용자 대신 AWS 환경에서 복잡한 리소스 관리 작업 수행
- **예시**: EB가 EC2 인스턴스를 만들고, JDK를 설치하고, 로드 밸런서를 생성하고, 보안 그룹을 설정
- **필요성**: 이 롤이 없으면 EB는 AWS 인프라 리소스를 건드릴 권한이 없어 환경을 만들 수 없음

#### 🔑 EC2 인스턴스 프로파일

**역할 설명**
```
"EB가 만든 그 EC2 인스턴스에서 애플리케이션을 돌릴 때, 필요한 AWS 리소스에 접근할 권한을 줄게!"
```

- **권한 부여 대상**: EB가 생성한 EC2 인스턴스 자체
- **역할**: EC2 인스턴스 위에서 실행되는 애플리케이션(JAR/WAR)이 다른 AWS 서비스와 상호작용
- **예시**: EC2 인스턴스가 로그를 CloudWatch에 올리고, S3에서 이미지 파일을 읽어오고, RDS 데이터베이스에 접속

**JAR 실행 권한은 왜 별도로?**
- JAR 파일을 실행하는 것 자체는 EC2 인스턴스의 OS 권한으로 충분
- 하지만 실행된 애플리케이션이 AWS 클라우드 환경 내의 다른 서비스(S3, RDS, CloudWatch 등)를 이용하려면 AWS IAM 권한이 필요
- 이 권한은 EC2 인스턴스 프로파일을 통해 부여되고, 애플리케이션이 실행될 때 상속받아 사용

#### 🛠️ EC2 인스턴스 프로파일 생성 방법

**중요**: EC2 인스턴스 프로파일은 EB 환경 생성 시 함께 만들 수 없으므로 반드시 사전에 생성해야 합니다.

**1단계: IAM 콘솔 접속**
- AWS 콘솔에서 `IAM` 검색 → IAM 대시보드 → `액세스 관리` → `역할` → `역할 생성`

**2단계: 신뢰할 수 있는 엔터티 유형 선택**
```
신뢰할 수 있는 엔터티 유형: AWS 서비스
사용 사례: EC2
```

**3단계: 권한 정책 연결**

스프링 부트 애플리케이션 배포를 위해 필요한 권한:
```
AWSElasticBeanstalkWebTier
```

이 정책은 EB의 웹 계층(EC2 인스턴스)에서 실행되는 애플리케이션이 필요로 하는 기본 권한들을 포함합니다.

**4단계: 역할 이름 지정**
```
역할 이름: aws-elasticbeanstalk-instance-profile
```

**5단계: 역할 생성 완료**

#### 🛠️ EB 서비스 롤 생성 방법

**참고**: 실제로는 EB 서비스 롤도 사전에 생성하도록 변경되었지만, 역할 생성 버튼을 클릭하면 자동으로 세팅되어서 쉽게 생성할 수 있습니다.

**자동 생성 과정**
1. EB 환경 생성 마법사의 "서비스 액세스" 단계에서 `역할 생성` 버튼 클릭
2. AWS가 자동으로 필요한 정책이 포함된 역할을 생성
3. 최종 역할 이름: `aws-elasticbeanstalk-service-role`

---

## 7.2.4 개발 환경 (Dev) 배포

### 📋 환경 개요

| 항목 | 설정값 |
|------|--------|
| **환경 이름** | `Spring-demo-dev` |
| **인스턴스 구성** | 단일 인스턴스 (고가용성 불필요) |
| **데이터베이스** | H2 내장 DB (프로파일: `dev`) |
| **서브넷** | Public Subnet (외부 접근 필요) |
| **목적** | 기능 구현, 간편 테스트 |

### 🚀 1단계: 애플리케이션 생성

**애플리케이션은 EB의 최상위 컨테이너**로, 여러 환경(Dev, Test, Prod)을 그룹핑하는 역할을 합니다.

#### 애플리케이션 생성
```
AWS 콘솔 → Elastic Beanstalk → 애플리케이션 생성
애플리케이션 이름: spring-demo
```

### 🛠️ 2단계: 환경 생성 - 기본 구성

#### 환경 티어 선택
```
환경 티어: 웹 서버 환경
```

**환경 티어란?**
| 티어 타입 | 용도 | 특징 |
|----------|------|------|
| **웹 서버 환경** | HTTP 요청을 처리하는 웹 애플리케이션 | 로드 밸런서, 오토 스케일링 지원 |
| **작업자 환경** | 백그라운드 작업 처리 (SQS 메시지 처리 등) | 로드 밸런서 없음 |

#### 환경 정보
```
환경 이름: Spring-demo-dev
```

#### 플랫폼 설정

**핵심 개념**: Spring Boot 애플리케이션은 JVM 위에서 실행되므로 **Java 플랫폼**을 선택해야 합니다.

```
플랫폼: Java
플랫폼 브랜치: Corretto 25 running on 64bit Amazon Linux 2023
플랫폼 버전: 최신 버전 (권장)
```

**플랫폼 선택 기준**
- Spring Boot 프로젝트의 JDK 버전과 동일하거나 호환성에 문제가 없는 버전 선택
- 최신 버전을 선택하면 AWS가 보안 패치를 자동으로 적용

#### 애플리케이션 코드

**코드 업로드 옵션 비교**

| 옵션 | 설명 | 사용 시기 |
|------|------|----------|
| **샘플 애플리케이션** | EB가 제공하는 임시 애플리케이션 | 환경 테스트용 |
| **기존 버전** | 이미 EB에 배포된 애플리케이션 버전 | 재배포 또는 롤백 시 |
| **코드 업로드** | 로컬 PC의 JAR/WAR 파일 업로드 | **실제 애플리케이션 배포 (선택)** |

**코드 업로드 설정**
```
소스 코드 원본: 로컬 파일
파일: Spring-Board-Project-0.0.1-SNAPSHOT.jar
버전 레이블: 1.0.0
```

**JAR vs WAR 파일 업로드 시 EB의 동작**

| 파일 형식 | WAS 사용 방식 | EB의 자동 처리 과정 |
|----------|-------------|------------------|
| **`.jar`** | 내장 WAS (Embedded Tomcat/Jetty 등) | EB는 EC2에 JDK만 설치하고, `java -jar [파일 이름]` 명령을 실행하여 JAR 파일 안에 포함된 WAS를 구동 |
| **`.war`** | 외부 WAS (Standalone Tomcat) | EB는 EC2에 JDK와 별도의 외부 Tomcat 서버를 자동으로 설치하고, WAR 파일을 Tomcat의 `/webapps` 디렉터리에 배치한 후 Tomcat 실행 |

**중요**: "Java" 플랫폼 선택 시, EB는 WAR 파일에 대해 자동으로 Apache Tomcat을 사용하도록 내부적으로 구성되어 있습니다. 사용자가 별도로 WAS를 지정할 필요가 없습니다.

#### 사전 설정

```
환경 유형: 단일 인스턴스
```

**환경 유형 비교**

| 환경 유형 | 인스턴스 수 | 로드 밸런서 | 용도 |
|----------|-----------|-----------|------|
| **단일 인스턴스** | 1대 (고정) | 없음 | 개발/테스트 환경 (비용 절감) |
| **고가용성 (로드 밸런싱)** | 최소 2대 이상 (자동 확장) | 있음 (ELB) | 운영 환경 (안정성 확보) |

---

### 🔐 3단계: 서비스 액세스 구성

이 단계에서는 사전에 생성한 IAM 역할을 등록합니다.

```
서비스 역할: aws-elasticbeanstalk-service-role
EC2 인스턴스 프로파일: aws-elasticbeanstalk-instance-profile
```

**역할 등록의 의미**
- **EB 서비스 롤**: EB가 환경을 자동으로 구축하고 관리할 수 있는 권한 부여
- **EC2 인스턴스 프로파일**: 애플리케이션이 실행될 때 AWS 리소스에 접근할 수 있는 권한 부여

---

### 🌐 4단계: 네트워킹, 데이터베이스 및 태그 설정

#### VPC 설정
```
VPC: hyechangSpring-vpc (사전에 생성한 VPC 선택)
퍼블릭 IP 주소: 활성화 ✅
```

**퍼블릭 IP 활성화 이유**: 단일 인스턴스 환경에서는 로드 밸런서가 없으므로, EC2 인스턴스가 직접 외부 인터넷과 통신하기 위해 퍼블릭 IP가 필요합니다.

#### 인스턴스 서브넷 선택

**단일 인스턴스에서 Public Subnet을 선택하는 이유**

현재는 로드 밸런서가 없는 단일 인스턴스 구성이므로, 외부에서 애플리케이션에 직접 접근하기 위해 EC2 인스턴스를 Public Subnet에 배치해야 합니다.

```
인스턴스 서브넷: 
  - hyechangSpring-subnet-public1-ap-northeast-2a ✅
  - hyechangSpring-subnet-public2-ap-northeast-2c ✅
```

**Public Subnet이 2개인 이유**

현재는 단일 인스턴스만 사용하지만, VPC는 나중에 운영 환경으로 확장할 때를 대비하여 고가용성 구조로 설계됩니다.

| 시나리오 | 서브넷 사용 | 이유 |
|---------|-----------|------|
| **현재 (단일 인스턴스)** | Public Subnet 1개만 사용 | 비용 절감 |
| **미래 (운영 환경)** | Public Subnet 2개 모두 사용 | 로드 밸런서를 2개의 가용 영역(AZ)에 분산 배치하여 한 AZ에 문제가 생겨도 서비스 지속 |

#### 데이터베이스 설정

개발 환경에서는 스프링 부트 애플리케이션이 H2 내장 데이터베이스를 사용하므로 RDS를 활성화하지 않습니다.

```
데이터베이스 가용성: 비활성화
```

---

### ⚙️ 5단계: 인스턴스 트래픽 및 크기 조정 구성

단일 인스턴스를 사용하기로 했으므로 이 단계에서는 별도로 선택할 항목이 없습니다.

```
(기본값유지)
```

---

### 📊 6단계: 업데이트, 모니터링 및 로깅 구성

이 단계는 **EB 환경 설정의 핵심**입니다. 여기서 Nginx의 역할과 환경 변수를 통한 프로파일 관리를 이해하는 것이 매우 중요합니다.

#### 🌐 Nginx의 역할 및 포트 포워딩 원리

EB가 생성한 EC2 인스턴스에는 **리버스 프록시(Reverse Proxy)** 역할을 하는 Nginx가 기본으로 탑재되어 있습니다.

**포트 포워딩 흐름**

| 주체 | 역할 | 포트 |
|------|------|------|
| **외부 사용자** | 웹 요청 | 80 포트 (표준 HTTP 포트) |
| **Nginx (EC2 내부)** | 리버스 프록시 | 80 포트 요청을 받아 → 내부 5000 포트로 포워딩 |
| **Spring Boot App (EC2 내부)** | 애플리케이션 실행 | 5000 포트 (Nginx가 요청을 던져주는 포트) |

**Nginx를 사용하는 이유**

1. **포트 단순화**: 외부 사용자는 `http://EC2-IP:8080` 대신 표준 웹 포트인 `http://EC2-IP:80`으로만 접근
2. **WAS 포트 은닉**: 내부적으로 Spring Boot 앱이 몇 번 포트를 사용하는지 외부에 노출할 필요 없음
3. **포트 충돌 방지**: EB는 내부적으로 5000번 포트를 애플리케이션 포트의 표준으로 정하고 Nginx를 설정

#### 🔑 환경 변수를 통한 설정 덮어쓰기

EB 환경 변수를 통해 `application.properties`의 설정을 런타임에 덮어쓸 수 있습니다. 이것이 바로 **프로파일 기반 환경 관리의 핵심**입니다.

**환경 속성 설정**

```
환경 속성:
  GRADLE_HOME: /usr/local/gradle
  M2: /usr/local/apache-maven/bin
  M2_HOME: /usr/local/apache-maven
  PROFILES: dev
  SERVER_PORT: 5000
```

**핵심 환경 변수 설명**

| 환경 변수 | 설정값 | 매핑되는 Spring 속성 | 역할 |
|----------|--------|---------------------|------|
| **`SERVER_PORT`** | `5000` | `server.port` | Nginx의 포워딩 규칙(80→5000)에 맞추기 위해 애플리케이션의 실행 포트를 5000으로 강제 |
| **`PROFILES`** | `dev` | `spring.profiles.active` (via `${profiles}`) | 개발 환경 설정 파일(`application-dev.properties`) 활성화 |

**환경 변수 매핑 원리**

Spring Boot는 환경 변수의 **대문자_언더바 규칙**을 자동으로 인식하여 `application.properties`의 설정을 덮어씁니다.

| 환경 변수 | Spring 속성 | 변환 규칙 |
|----------|------------|----------|
| `SERVER_PORT` | `server.port` | 대문자 → 소문자, `_` → `.` |
| `SPRING_PROFILES_ACTIVE` | `spring.profiles.active` | 대문자 → 소문자, `_` → `.` |

#### 📝 애플리케이션 코드와의 연동

**`application.properties`**

```properties
spring.application.name=Spring-Board-Project
profiles=dev
spring.profiles.active=${profiles}

spring.sql.init.mode=always
spring.sql.init.encoding=utf-8
spring.jpa.hibernate.ddl-auto=none
```

**동작 원리**
1. EB 환경 변수 `PROFILES=dev`가 설정됨
2. Spring Boot 실행 시 `profiles` 변수에 `dev` 값이 주입됨
3. `spring.profiles.active=${profiles}`가 `spring.profiles.active=dev`로 해석됨
4. `application-dev.properties` 파일이 활성화됨

**`application-dev.properties`**

```properties
spring.datasource.url=jdbc:h2:mem:demo
spring.h2.console.enabled=true
```

**결과**: 개발 환경에서는 H2 내장 데이터베이스를 사용하고, H2 콘솔도 활성화됩니다.

#### 🎯 환경 변수 적용의 중요성

이러한 방식은 **"프로그램 실행 옵션 > 운영체제 환경변수 > application.properties"**라는 스프링 부트 설정 우선순위를 활용하는 것이며, 다음과 같은 장점을 제공합니다:

**핵심 장점**
- ✅ **코드 수정 없이 환경 전환**: 동일한 JAR 파일로 Dev, Test, Prod 환경에 배포 가능
- ✅ **유연한 설정 관리**: 환경 변수만 변경하여 데이터베이스, 포트, 로깅 레벨 등 조정
- ✅ **보안 강화**: 민감한 정보(DB 비밀번호 등)를 코드에 하드코딩하지 않고 환경 변수로 관리

---

### ✅ 7단계: 환경 생성 완료 및 확인

모든 설정을 마친 후 `제출` 버튼을 클릭하면 EB가 자동으로 환경을 구축합니다.

**EB의 자동 작업 내역**
1. ✅ EC2 인스턴스 생성
2. ✅ Amazon Corretto JDK 21 설치
3. ✅ Nginx 설치 및 포트 포워딩 설정 (80 → 5000)
4. ✅ 보안 그룹 구성 (80번 포트 개방)
5. ✅ JAR 파일 배포 및 실행 (`java -jar`)
6. ✅ CloudWatch 모니터링 설정

**환경 생성 완료 화면**

```
환경 개요
  상태: Ok ✅
  도메인: Spring-demo-dev.eba-2w2jyb3b.ap-northeast-2.elasticbeanstalk.com
  환경 ID: e-np3hyizgmj
  애플리케이션 이름: spring-demo
```

#### 🌐 애플리케이션 접속

브라우저에서 다음 URL로 접속하여 애플리케이션이 정상 작동하는지 확인합니다:

```
http://Spring-demo-dev.eba-2w2jyb3b.ap-northeast-2.elasticbeanstalk.com
```

**접속 성공 시**: 스프링 부트 애플리케이션의 메인 페이지가 표시됩니다. 🎉

---

### 📊 개발 환경 최종 정리

**6단계 환경 구성 요약**

| 단계 | 설정 항목 | 설정 값 |
|------|----------|---------|
| **1단계** | 환경 이름 | `Spring-demo-dev` |
| | 플랫폼 | `Corretto 25 running on 64bit Amazon Linux 2023` |
| | 애플리케이션 코드 | `Spring-Board-Project-0.0.1-SNAPSHOT.jar` (버전: 1.0.0) |
| **2단계** | 서비스 역할 | `aws-elasticbeanstalk-service-role` |
| | EC2 인스턴스 프로파일 | `aws-elasticbeanstalk-instance-profile` |
| **3단계** | VPC | `hyechangSpring-vpc` |
| | 퍼블릭 IP 주소 | 활성화 |
| | 인스턴스 서브넷 | Public Subnet 2개 |
| | 데이터베이스 | 비활성화 (H2 사용) |
| **4단계** | 환경 유형 | 단일 인스턴스 |
| **5단계** | 환경 속성 | `PROFILES=dev`, `SERVER_PORT=5000` |

---

## 7.2.5 테스트 환경 (Test) 배포

### 📋 환경 개요

| 항목 | 설정값 |
|------|--------|
| **환경 이름** | `Spring-demo-test` |
| **인스턴스 구성** | 단일 인스턴스 |
| **데이터베이스** | RDS MySQL (프로파일: `aws`) |
| **서브넷** | EC2: Public, RDS: Private |
| **목적** | 통합 테스트, 검증 (데이터 영속성 확보) |

### 🔄 개발 환경과의 차이점

테스트 환경은 개발 환경과 대부분 동일하지만, **데이터베이스**가 핵심 차이점입니다.

| 항목 | 개발 환경 (Dev) | 테스트 환경 (Test) |
|------|----------------|-------------------|
| **데이터베이스** | H2 내장 DB (휘발성) | RDS MySQL (영구 저장) |
| **프로파일** | `dev` | `aws` |
| **데이터 유지** | 재시작 시 초기화 | 재시작 후에도 데이터 유지 |

### 🗄️ RDS (Relational Database Service) 이해

#### RDS란?

**RDS (Relational Database Service)**는 MySQL, PostgreSQL과 같은 관계형 데이터베이스를 쉽게 설치, 운영, 관리할 수 있도록 해주는 AWS 서비스입니다.

**RDS의 핵심 역할**

| 항목 | 설명 |
|------|------|
| **컴퓨팅 자원** | RDS도 내부적으로 EC2 인스턴스를 사용하지만, 데이터베이스 서버 역할만 수행하며 AWS가 완전히 관리 |
| **관리 자동화** | OS 패치, 보안 업데이트, 디스크 관리를 AWS가 자동으로 처리 |
| **고가용성** | 멀티-AZ 배포 시 자동으로 이중화 및 장애 조치(Failover) |
| **백업/복구** | 자동 백업 및 특정 시점 복구(Point-in-time recovery) 기능 제공 |

#### 🔗 EB와 RDS의 관계

**중요**: 애플리케이션 서버(EC2)와 데이터베이스 서버(RDS)는 분리되어 독립적으로 운영됩니다.

```
┌─────────────────────┐
│  Elastic Beanstalk  │
│  (애플리케이션 계층)   │
│                     │
│  ┌───────────────┐  │
│  │  EC2 인스턴스  │  │ ← Spring Boot JAR 실행
│  │  (Web Server) │  │
│  └───────┬───────┘  │
└──────────┼──────────┘
           │ 네트워크 연결
           │ (VPC 내부)
           ▼
    ┌─────────────┐
    │     RDS     │
    │ (DB 계층)    │
    │             │
    │ ┌─────────┐ │
    │ │  MySQL  │ │ ← 데이터베이스 서버
    │ └─────────┘ │
    └─────────────┘
```

**분리 원칙**
- ❌ 하나의 EC2 인스턴스에 JAR 애플리케이션과 MySQL 서버를 모두 실행하는 구조는 사용하지 않음
- ✅ 안정성과 확장성을 위해 두 서버는 항상 분리됨

### 🛠️ 테스트 환경 생성 (차이점 중심)

개발 환경과 동일한 부분은 생략하고, **차이점만** 설명합니다.

#### 1단계: 기본 구성

```
환경 이름: Spring-demo-test
```

**애플리케이션 코드 선택**

```
옵션 1 (기존 버전 사용): 기존 버전 → 1.0.0 선택
옵션 2 (새 버전 업로드): 코드 업로드 → 수정된 JAR 파일 업로드 → 버전 레이블: 2.0.0
```

**JAR 파일 수정 이유**: `application-aws.properties` 파일 추가 등 RDS 연동을 위한 설정 포함

#### 2단계: 서비스 액세스 (동일)

```
서비스 역할: aws-elasticbeanstalk-service-role
EC2 인스턴스 프로파일: aws-elasticbeanstalk-instance-profile
```

#### 3단계: 네트워킹, 데이터베이스 및 태그 설정 (핵심 차이점)

**VPC 및 인스턴스 서브넷 (동일)**

```
VPC: hyechangSpring-vpc
퍼블릭 IP 주소: 활성화
인스턴스 서브넷: Public Subnet 2개 선택
```

**데이터베이스 설정 (핵심 차이점) 🔑**

```
데이터베이스 가용성: 활성화 ✅
```

데이터베이스를 활성화하면 EB가 자동으로 RDS 인스턴스를 생성하고 연결합니다.

**데이터베이스 서브넷 선택**

```
데이터베이스 서브넷: 
  - hyechangSpring-subnet-private1-ap-northeast-2a ✅
  - hyechangSpring-subnet-private2-ap-northeast-2c ✅
```

**Private Subnet을 선택하는 이유**
- 데이터베이스는 외부 인터넷에서 직접 접속할 필요가 없음
- 보안을 위해 인터넷 접속이 완전히 차단된 Private Subnet에 배치
- 애플리케이션(EC2)은 VPC 내부 네트워크를 통해서만 RDS에 접근

**데이터베이스 자격 증명 설정**

```
데이터베이스 엔진: MySQL 8.0.43
데이터베이스 인스턴스 클래스: db.t3.small
데이터베이스 사용자 이름: myuser
데이터베이스 암호: [강력한 암호 입력]
데이터베이스 스토리지: 20 GB
```

**중요**: 이 사용자 이름과 암호는 AWS 콘솔 로그인 정보나 EC2 인스턴스 접속 정보가 **아닙니다**. RDS MySQL 서버의 **마스터 사용자(Master User)** 계정을 생성하는 것입니다.

#### 🔑 RDS 마스터 사용자 계정의 역할

**1. 계정 생성 및 권한 부여**

- **생성 행위**: 입력한 자격 증명으로 RDS 서비스가 MySQL 서버를 초기화하면서 **마스터 사용자(Master User)**를 생성
- **권한**: 이 마스터 사용자는 해당 RDS 인스턴스 내에서 **최고 권한(슈퍼 유저)**을 가짐
- **가능한 작업**: 데이터베이스 생성, 테이블 조작(CRUD), 사용자 관리 등 모든 관리 작업

**2. 환경 변수 전달 및 사용**

EB는 이 마스터 사용자의 자격 증명을 **환경 변수**로 변환하여 애플리케이션이 실행되는 EC2 인스턴스에 전달합니다.

| RDS 정보 | 환경 변수 이름 | 설명 |
|---------|--------------|------|
| **Hostname** | `RDS_HOSTNAME` | RDS 서버 주소 |
| **Port** | `RDS_PORT` | MySQL 포트 (기본: 3306) |
| **DB Name** | `RDS_DB_NAME` | 데이터베이스 이름 |
| **Username** | `RDS_USERNAME` | 마스터 사용자 이름 |
| **Password** | `RDS_PASSWORD` | 마스터 사용자 암호 |

**3. Spring Boot 애플리케이션의 RDS 접속**

Spring Boot 애플리케이션은 이 환경 변수를 읽어 MySQL 서버에 접속합니다.

**`application-aws.properties`**

```properties
spring.datasource.url=jdbc:mysql://${rds.hostname}:${rds.port}/${rds.db.name}
spring.datasource.username=${rds.username}
spring.datasource.password=${rds.password}

spring.session.jdbc.initialize-schema=always
```

**환경 변수 바인딩 원리**

Spring Boot는 EB가 주입한 환경 변수를 자동으로 소문자 속성명으로 매핑합니다:

| 환경 변수 | Spring 속성 |
|----------|------------|
| `RDS_HOSTNAME` | `rds.hostname` |
| `RDS_PORT` | `rds.port` |
| `RDS_DB_NAME` | `rds.db.name` |
| `RDS_USERNAME` | `rds.username` |
| `RDS_PASSWORD` | `rds.password` |

**최종 연결 과정**

1. **RDS 생성**: AWS RDS가 MySQL 서버를 생성하고 마스터 사용자 계정 생성
2. **정보 전달**: EB가 RDS 접속 정보를 환경 변수로 EC2 인스턴스에 주입
3. **변수 바인딩**: `application-aws.properties`의 플레이스홀더(`${rds.hostname}` 등)에 환경 변수 값 대입
4. **DB 접속**: Spring Boot가 완성된 URL과 인증 정보로 RDS MySQL 서버에 접속
5. **세션 관리**: `spring.session.jdbc.initialize-schema=always` 설정으로 세션 저장용 테이블 자동 생성

```
최종 연결 URL 예시:
jdbc:mysql://mydb.abc123.ap-northeast-2.rds.amazonaws.com:3306/ebdb
```

#### 4단계: 인스턴스 트래픽 및 크기 조정 (동일)

```
(기본값 유지)
```

#### 5단계: 업데이트, 모니터링 및 로깅 구성 (환경 변수 차이)

**환경 속성 설정**

```
환경 속성:
  GRADLE_HOME: /usr/local/gradle
  M2: /usr/local/apache-maven/bin
  M2_HOME: /usr/local/apache-maven
  PROFILES: aws  ← 개발 환경과 다름!
  SERVER_PORT: 5000
```

**`PROFILES=aws` 설정의 의미**

1. `application.properties`의 `spring.profiles.active=${profiles}`가 `spring.profiles.active=aws`로 해석됨
2. `application-aws.properties` 파일이 활성화됨
3. RDS MySQL 연결 설정이 적용됨

#### 6단계: 환경 생성 및 확인

`제출` 버튼을 클릭하면 EB가 다음 작업을 자동으로 수행합니다:

**EB의 자동 작업 (테스트 환경)**
1. ✅ EC2 인스턴스 생성 (Public Subnet)
2. ✅ RDS MySQL 인스턴스 생성 (Private Subnet, 2개 AZ에 걸쳐 배치)
3. ✅ JDK, Nginx 설치 및 설정
4. ✅ RDS 접속 정보를 환경 변수로 EC2에 주입
5. ✅ JAR 파일 배포 및 실행
6. ✅ 보안 그룹 구성 (EC2 ↔ RDS 통신 허용)

**환경 생성 완료**

```
환경 개요
  상태: Ok ✅
  도메인: Spring-demo-test.eba-xxxxxxx.ap-northeast-2.elasticbeanstalk.com
```

---

### ⚠️ SQL 초기화 충돌 문제 및 해결

테스트 환경 배포 후 애플리케이션 접속 시 다음과 같은 오류가 발생할 수 있습니다:

```
HTTP Status 500 - Internal Server Error
Caused by: Table 'member' already exists
```

#### 🔍 문제 원인 분석

| 원인 요소 | 설명 |
|----------|------|
| **`spring.sql.init.mode=always`** | `application.properties`에 설정되어 있어, Spring Boot가 시작 시마다 `schema.sql` 스크립트를 실행하여 테이블 생성을 강제 |
| **RDS의 데이터 영속성** | RDS는 영구 데이터베이스이므로, 이전 배포 시 생성된 테이블을 그대로 유지 |
| **충돌 발생** | 애플리케이션이 다시 시작할 때 이미 존재하는 테이블을 또 만들려 하니 충돌 발생 |

**개발 vs 운영 환경의 차이**

| 환경 | 데이터베이스 | SQL 초기화 필요성 | 문제 발생 여부 |
|------|------------|----------------|--------------|
| **개발 (H2)** | 휘발성 (재시작 시 초기화) | `always` 필수 | 문제 없음 ✅ |
| **테스트/운영 (RDS)** | 영구 저장 (데이터 유지) | `never` 필요 | 충돌 발생 ❌ |

#### ✅ 해결 방법: 환경 변수로 설정 덮어쓰기

**1. EB 콘솔 접속**

```
Elastic Beanstalk → 환경 → Spring-demo-test → 구성 → 소프트웨어 → 편집
```

**2. 환경 속성 추가**

```
환경 속성:
  SPRING_SQL_INIT_MODE: never  ← 추가!
  PROFILES: aws
  SERVER_PORT: 5000
```

**3. 적용 및 재배포**

`적용` 버튼 클릭 → EB가 자동으로 환경을 업데이트하고 애플리케이션 재시작

**해결 원리**

1. 환경 변수 `SPRING_SQL_INIT_MODE=never` 설정
2. Spring Boot가 `application.properties`의 `spring.sql.init.mode=always`를 `never`로 덮어씀
3. 애플리케이션은 테이블 초기화를 시도하지 않고 정상 구동

**중요**: 
- ✅ 애플리케이션 코드(JAR 파일)는 수정하지 않음
- ✅ 환경 변수만 변경하여 문제 해결
- ✅ RDS의 기존 테이블과 데이터는 그대로 유지

---

### 📊 테스트 환경 최종 정리

**테스트 환경의 핵심 특징**

| 항목 | 설정 |
|------|------|
| **환경 이름** | `Spring-demo-test` |
| **인스턴스** | 단일 인스턴스 (Public Subnet) |
| **데이터베이스** | RDS MySQL (Private Subnet, 2개 AZ) |
| **프로파일** | `aws` |
| **환경 변수** | `PROFILES=aws`, `SERVER_PORT=5000`, `SPRING_SQL_INIT_MODE=never` |
| **데이터 영속성** | ✅ 재배포 후에도 데이터 유지 |

**배포 후 검증 사항**
- ✅ 애플리케이션 정상 접속
- ✅ 데이터베이스 연결 확인 (회원 가입, 게시글 작성 등)
- ✅ 재배포 후에도 기존 데이터 유지 확인

---

## 7.2.6 운영 환경 (Production) 배포

### 📋 환경 개요

| 항목 | 설정값 |
|------|--------|
| **환경 이름** | `Spring-demo-prod` |
| **인스턴스 구성** | 고가용성 (로드 밸런싱) |
| **인스턴스 수** | 최소 2대, 최대 4대 (오토 스케일링) |
| **데이터베이스** | RDS MySQL (프로파일: `aws,health`) |
| **서브넷** | EC2: Private, ELB: Public, RDS: Private |
| **목적** | 실서비스, 무중단 운영, 고가용성 확보 |

### 🎯 운영 환경의 핵심 차이점

테스트 환경과의 가장 큰 차이는 **고가용성 아키텍처**입니다.

| 항목 | 테스트 환경 | 운영 환경 |
|------|------------|----------|
| **환경 유형** | 단일 인스턴스 | 로드 밸런싱 |
| **EC2 인스턴스 수** | 1대 고정 | 2~4대 (자동 확장/축소) |
| **로드 밸런서** | 없음 | ELB (Application Load Balancer) |
| **EC2 서브넷** | Public | Private (보안 강화) |
| **외부 접근** | EC2에 직접 접근 | ELB를 통해서만 접근 |
| **장애 대응** | 인스턴스 다운 시 서비스 중단 | 다른 인스턴스가 즉시 트래픽 처리 |

### 🛠️ 운영 환경 생성 (차이점 중심)

#### 1단계: 기본 구성

```
환경 이름: Spring-demo-prod
```

**애플리케이션 코드**

```
기존 버전 사용: 2.0.0 선택
```

**이미 검증된 버전을 사용하는 것이 운영 환경의 원칙입니다.**

**사전 설정 (핵심 차이점)**

```
환경 유형: 고가용성 ✅
```

이 설정만으로 EB는 완전히 다른 아키텍처를 구축합니다.

#### 2단계: 서비스 액세스 (동일)

```
서비스 역할: aws-elasticbeanstalk-service-role
EC2 인스턴스 프로파일: aws-elasticbeanstalk-instance-profile
```

#### 3단계: 네트워킹, 데이터베이스 및 태그 설정

**VPC 설정**

```
VPC: hyechangSpring-vpc
퍼블릭 IP 주소: 비활성화 ❌
```

**퍼블릭 IP 비활성화 이유**: 운영 환경에서는 EC2 인스턴스를 Private Subnet에 배치하여 외부 인터넷으로부터 격리하고, 로드 밸런서를 통해서만 접근하도록 강제합니다.

**인스턴스 서브넷 선택 (핵심 차이점)**

```
인스턴스 서브넷: 
  - hyechangSpring-subnet-private1-ap-northeast-2a ✅
  - hyechangSpring-subnet-private2-ap-northeast-2c ✅
```

**Private Subnet을 선택하는 이유**
- 애플리케이션 서버를 외부 인터넷으로부터 격리
- 로드 밸런서를 통해서만 접근하도록 강제
- 최고 수준의 보안 확보

**로드 밸런서 서브넷 (자동 설정)**

```
로드 밸런서 서브넷: 
  - hyechangSpring-subnet-public1-ap-northeast-2a ✅
  - hyechangSpring-subnet-public2-ap-northeast-2c ✅
```

EB가 자동으로 Public Subnet을 로드 밸런서 배치 위치로 선택합니다.

**데이터베이스 설정**

```
데이터베이스 가용성: 활성화 ✅
데이터베이스 엔진: MySQL 8.0.43
데이터베이스 인스턴스 클래스: db.t3.small
데이터베이스 사용자 이름: produser
데이터베이스 암호: [강력한 암호 입력]
데이터베이스 서브넷: Private Subnet 2개 선택
```

**보안 원칙**: 운영 환경에서는 테스트 환경과 다른 데이터베이스 자격 증명을 사용하는 것이 권장됩니다.

---

#### 4단계: 인스턴스 트래픽 및 크기 조정 구성 (핵심 설정)

이 단계가 운영 환경의 핵심입니다. 여기서 **오토 스케일링**과 **헬스 체크**를 설정합니다.

**용량 설정**

```
환경 유형: 로드 밸런싱된 환경
인스턴스:
  최소: 2
  최대: 4
```

**오토 스케일링 동작 원리**

| 상황 | 인스턴스 수 | ASG의 동작 |
|------|-----------|----------|
| **평상시** | 2대 (최소값) | 항상 최소 2개의 EC2 인스턴스를 유지하며, 로드 밸런서(ELB)를 통해 트래픽 분산 |
| **트래픽 증가 시** | 2 → 3 → 4대 (Scale-Out) | CPU 사용률 등 설정된 지표가 높아지면, 최대 4개까지 새로운 EC2 인스턴스를 자동으로 생성하고 ELB에 연결 |
| **트래픽 감소 시** | 4 → 3 → 2대 (Scale-In) | 트래픽이 줄어들어 지표가 낮아지면, 최소 2개가 될 때까지 불필요한 인스턴스를 자동으로 종료하여 비용 절감 |

**오토 스케일링의 장점**
- ✅ **탄력성**: 트래픽 패턴에 따라 자동으로 용량 조정
- ✅ **비용 최적화**: 필요한 만큼만 리소스 사용
- ✅ **고가용성**: 항상 최소 2대 이상 운영으로 장애 대응

---

**프로세스 설정 (헬스 체크 구성) 🔑**

```
프로세스 추가 버튼 클릭

프로세스 설정:
  이름: default
  포트: 80
  프로토콜: HTTP
  상태 확인 경로: /health  ← 핵심!
  HTTP 코드: 200
  고정성: Disabled
```

**설정 항목 상세 설명**

| 항목 | 설정값 | 역할 |
|------|--------|------|
| **포트** | `80` | ELB가 외부 트래픽을 받는 포트 (HTTP 표준) |
| **프로토콜** | `HTTP` | 통신 프로토콜 |
| **상태 확인 경로** | `/health` | ELB가 인스턴스의 상태를 확인할 때 접속할 경로 |
| **HTTP 코드** | `200` | `/health` 경로로 접속했을 때, 200 OK 응답을 받아야만 인스턴스를 정상(Healthy)으로 판단 |

#### 🏥 `/health` 헬스 체크의 역할

**헬스 체크(Health Check)**는 ELB가 애플리케이션의 '건강 상태'를 자동으로, 그리고 주기적으로 확인하는 핵심 기능입니다.

**1. `/health` 엔드포인트의 역할**

`/health`는 일반적으로 Spring Boot의 **Actuator 모듈**이 제공하는 상태 확인 엔드포인트입니다.

```
요청: GET http://인스턴스-IP:5000/health

응답 (정상):
{
  "status": "UP",
  "components": {
    "db": { "status": "UP" },
    "diskSpace": { "status": "UP" }
  }
}
```

**상태 검사 항목**
- ✅ 데이터베이스 연결 상태
- ✅ 디스크 공간
- ✅ 메모리 사용량
- ✅ 커스텀 비즈니스 로직 상태

**2. 누가 `/health`를 요청하는가? (주체: ELB)**

| 주체 | 요청 빈도 | 목적 |
|------|----------|------|
| **로드 밸런서(ELB)** | 30초마다 (설정 가능) | 각 EC2 인스턴스가 정상적으로 작동하는지 자동 확인 |

**ELB의 자동 요청 과정**

```
매 30초마다:
  ELB → EC2 인스턴스 1: GET /health
  ELB → EC2 인스턴스 2: GET /health
  ELB → EC2 인스턴스 3: GET /health (확장된 경우)
```

**상태 판별 로직**

| 응답 결과 | ELB의 판단 | 트래픽 라우팅 |
|----------|-----------|-------------|
| **200 OK 수신** | 정상(Healthy) | 계속 트래픽 전송 ✅ |
| **오류 코드 또는 시간 초과** | 비정상(Unhealthy) | 트래픽 전송 중단, 오토 스케일링 그룹에 보고 ❌ |

**3. 헬스 체크를 하는 이유**

**시나리오: DB 연결 끊김**

```
인스턴스 상태:
  - 웹 서버(Nginx, Tomcat): 정상 실행 중
  - 애플리케이션(Spring Boot): 실행 중이지만 DB 연결 끊김
  - 실제 비즈니스 로직: 작동 불가 (좀비 상태)
```

| 상태 확인 경로 | 판단 결과 | 문제점 |
|-------------|----------|--------|
| **`/` (루트)** | 인스턴스 살아있음 → 정상 | DB 연결 끊김을 감지 못함 ❌ |
| **`/health`** | DB 연결 끊김 → 비정상 | 좀비 인스턴스 즉시 격리 ✅ |

**헬스 체크의 자동 복구 흐름**

```
1. ELB가 /health 요청 → 인스턴스 A가 503 Service Unavailable 응답
   ↓
2. ELB가 인스턴스 A를 비정상으로 표시
   ↓
3. ELB는 인스턴스 A로 트래픽 전송 중단 (사용자는 정상 인스턴스로만 연결됨)
   ↓
4. 오토 스케일링 그룹(ASG)이 비정상 인스턴스 A를 종료
   ↓
5. ASG가 새로운 정상 인스턴스를 자동으로 생성하여 교체
   ↓
6. 사용자는 서비스 중단을 전혀 느끼지 못함 (무중단 운영)
```

**4. 단일 인스턴스 vs 로드 밸런싱 환경에서의 차이**

| 환경 유형 | 헬스 체크 작동 여부 | 누가 확인하는가? | 주요 목적 |
|----------|------------------|---------------|----------|
| **로드 밸런싱 환경** | 매우 활발하게 작동 | 로드 밸런서(ELB) | 트래픽을 비정상 인스턴스에 보내지 않고, 장애 발생 시 자동으로 인스턴스를 격리/교체 (핵심!) |
| **단일 인스턴스 환경** | 제한적으로 작동 | Elastic Beanstalk 서비스 자체 | 인스턴스가 다운되었는지 여부만 확인. `/health` 경로를 이용한 정교한 애플리케이션 상태 확인의 필요성 및 활용도가 낮음 |

**결론**: `/health` 헬스 체크는 로드 밸런싱 환경에서 무중단 서비스를 보장하기 위한 자동화된 자가진단 시스템입니다.

---

**`application-health.properties` 파일 추가**

헬스 체크를 제대로 활용하려면 Actuator 설정이 필요합니다.

```properties
# application-health.properties

# 1. 모든 Actuator 엔드포인트를 웹을 통해 노출
management.endpoints.web.exposure.include=*

# 2. 헬스 체크 결과에 상세 정보를 항상 포함
management.endpoint.health.show-details=always

# 3. 데이터베이스 헬스 체크를 항상 활성화
management.health.db.enabled=true
```

**설정 효과**
- ✅ `/health` 엔드포인트가 DB 연결 상태 등 내부 상태를 포함하여 응답
- ✅ ELB가 애플리케이션의 실제 건강 상태를 정확히 판단 가능
- ✅ DB 연결 끊김 등의 문제 발생 시 즉시 감지

---

#### 5단계: 업데이트, 모니터링 및 로깅 구성

**환경 속성 설정**

```
환경 속성:
  GRADLE_HOME: /usr/local/gradle
  M2: /usr/local/apache-maven/bin
  M2_HOME: /usr/local/apache-maven
  PROFILES: aws,health  ← 복수 프로파일 활성화!
  SERVER_PORT: 5000
  SPRING_SQL_INIT_MODE: never
```

**`PROFILES=aws,health` 설정의 의미**

복수 프로파일을 활성화하여 설정을 모듈화합니다:

| 프로파일 | 활성화되는 파일 | 역할 |
|---------|--------------|------|
| **`aws`** | `application-aws.properties` | RDS 연결 설정 |
| **`health`** | `application-health.properties` | Actuator 헬스 체크 설정 |

**동작 원리**

```
1. EB 환경 변수: PROFILES=aws,health
   ↓
2. application.properties: spring.profiles.active=${profiles}
   ↓
3. 최종 해석: spring.profiles.active=aws,health
   ↓
4. 활성화: application-aws.properties + application-health.properties
```

**충돌 시 우선순위**: 동일한 속성이 여러 프로파일에 정의된 경우, 나중에 명시된 프로파일(`health`)의 값이 우선 적용됩니다.

---

#### 6단계: 환경 생성 및 확인

`제출` 버튼을 클릭하면 EB가 운영 환경의 복잡한 인프라를 자동으로 구축합니다.

**EB의 자동 작업 (운영 환경)**

1. ✅ **로드 밸런서(ELB) 생성** (Public Subnet에 배치, 2개 AZ에 걸쳐 분산)
2. ✅ **EC2 인스턴스 2대 생성** (Private Subnet에 배치)
3. ✅ **오토 스케일링 그룹(ASG) 구성** (최소 2, 최대 4)
4. ✅ **RDS MySQL 인스턴스 생성** (Private Subnet, 멀티-AZ 가능)
5. ✅ **보안 그룹 구성**:
   - ELB: 인터넷(0.0.0.0/0) → ELB(80번 포트) 허용
   - EC2: ELB → EC2(5000번 포트) 허용
   - RDS: EC2 → RDS(3306번 포트) 허용
6. ✅ **헬스 체크 설정** (ELB가 30초마다 `/health` 요청)
7. ✅ **CloudWatch 모니터링 통합**

**환경 생성 완료**

```
환경 개요
  상태: Ok ✅
  도메인: Spring-demo-prod.eba-xxxxxxx.ap-northeast-2.elasticbeanstalk.com
  로드 밸런서: 활성화 ✅
  인스턴스: 2대 실행 중
```

---

### 🏗️ 운영 환경 아키텍처 최종 구조

```
                    ┌─────────────┐
                    │   Internet  │
                    └──────┬──────┘
                           │ HTTP 요청
                           │
            ┌──────────────▼──────────────┐
            │  Public Subnet (2개 AZ)      │
            │                              │
            │  ┌────────────────────────┐  │
            │  │  Load Balancer (ELB)   │  │ ← 외부 진입점
            │  │  포트 80                │  │
            │  └─────────┬──────────────┘  │
            └────────────┼─────────────────┘
                         │ 트래픽 분산
         ┌───────────────┼───────────────┐
         │               │               │
         ▼               ▼               ▼
┌────────────────┐ ┌────────────────┐ ┌────────────────┐
│ Private Subnet │ │ Private Subnet │ │ Private Subnet │
│                │ │                │ │ (확장 시)      │
│ ┌────────────┐ │ │ ┌────────────┐ │ │ ┌────────────┐ │
│ │ EC2 #1     │ │ │ │ EC2 #2     │ │ │ │ EC2 #3     │ │
│ │ (Spring)   │ │ │ │ (Spring)   │ │ │ │ (Spring)   │ │
│ │ 포트 5000  │ │ │ │ 포트 5000  │ │ │ │ 포트 5000  │ │
│ └─────┬──────┘ │ │ └─────┬──────┘ │ │ └─────┬──────┘ │
└───────┼────────┘ └───────┼────────┘ └───────┼────────┘
        │                  │                  │
        └──────────────────┼──────────────────┘
                           │ DB 접속
                           ▼
                ┌──────────────────┐
                │  Private Subnet  │
                │                  │
                │  ┌────────────┐  │
                │  │    RDS     │  │
                │  │   MySQL    │  │
                │  │  포트 3306 │  │
                │  └────────────┘  │
                └──────────────────┘
```

**보안 레이어**

| 레이어 | 위치 | 외부 접근 | 역할 |
|--------|------|----------|------|
| **1. 로드 밸런서** | Public Subnet | 허용 (80번 포트) | 외부 요청을 받아 정상 인스턴스로만 분산 |
| **2. 애플리케이션** | Private Subnet | 차단 (ELB를 통해서만) | 비즈니스 로직 처리 |
| **3. 데이터베이스** | Private Subnet | 차단 (EC2에서만) | 데이터 저장 및 관리 |

---

### 📊 운영 환경 최종 정리

**환경 구성 요약**

| 항목 | 설정 |
|------|------|
| **환경 이름** | `Spring-demo-prod` |
| **환경 유형** | 로드 밸런싱 |
| **인스턴스 수** | 최소 2, 최대 4 (오토 스케일링) |
| **EC2 서브넷** | Private Subnet 2개 |
| **로드 밸런서** | Public Subnet 2개 |
| **데이터베이스** | RDS MySQL (Private Subnet) |
| **프로파일** | `aws,health` |
| **헬스 체크** | `/health` 경로, 30초마다 확인 |
| **보안** | 3계층 분리 (ELB → EC2 → RDS) |

**운영 환경의 핵심 특징**

| 특징 | 설명 | 효과 |
|------|------|------|
| **고가용성** | 최소 2대의 인스턴스가 항상 실행 | 한 인스턴스 다운 시에도 서비스 지속 |
| **자동 확장** | 트래픽에 따라 2~4대 자동 조정 | 부하 분산 및 비용 최적화 |
| **무중단 헬스 체크** | ELB가 `/health`로 30초마다 확인 | 비정상 인스턴스 자동 격리 및 교체 |
| **보안 강화** | EC2와 RDS를 Private Subnet에 배치 | 외부 공격으로부터 보호 |
| **자동 복구** | ASG가 비정상 인스턴스를 자동 교체 | 운영자 개입 없이 자동 복구 |

---

## 7.2.7 환경별 배포 전략 종합 비교

### 📊 개발/테스트/운영 환경 비교표

| 항목 | 개발 (Dev) | 테스트 (Test) | 운영 (Production) |
|------|-----------|--------------|------------------|
| **환경 이름** | `Spring-demo-dev` | `Spring-demo-test` | `Spring-demo-prod` |
| **인스턴스 구성** | 단일 인스턴스 | 단일 인스턴스 | 로드 밸런싱 (2~4대) |
| **EC2 서브넷** | Public | Public | Private |
| **로드 밸런서** | 없음 | 없음 | 있음 (ELB) |
| **데이터베이스** | H2 (내장) | RDS MySQL | RDS MySQL |
| **데이터 영속성** | 없음 (휘발성) | 있음 (영구 저장) | 있음 (영구 저장) |
| **프로파일** | `dev` | `aws` | `aws,health` |
| **SQL 초기화** | `always` | `never` | `never` |
| **헬스 체크** | 없음 | 제한적 | 활발 (`/health`) |
| **비용** | 최소 | 중간 | 최대 |
| **목적** | 기능 구현, 간편 테스트 | 통합 테스트, 검증 | 실서비스, 무중단 운영 |

---

## 7.2.8 Elastic Beanstalk 사용 후기 및 핵심 교훈

### 💡 EB 사용을 통해 얻은 핵심 가치

#### 1. ⚙️ 환경 구성의 자동화 및 인프라 관리 부담 해소

**IaaS (EC2)와의 비교**

| 작업 | EC2 (IaaS) | Elastic Beanstalk (PaaS) |
|------|------------|--------------------------|
| **JDK 설치** | 매번 수동 설치 및 버전 관리 | 플랫폼 선택만으로 자동 설치 |
| **Tomcat 설치** | 다운로드, 압축 해제, 환경 변수 설정 | WAR 파일 업로드 시 자동 설치 |
| **Nginx 설정** | 포트 포워딩 수동 설정 | 자동 구성 (80 → 5000) |
| **로드 밸런서** | 별도로 생성 및 연결 | 환경 유형 선택만으로 자동 생성 |
| **오토 스케일링** | ASG 수동 구성 | 최소/최대 인스턴스만 지정 |
| **보안 그룹** | 수동으로 규칙 설정 | 자동으로 안전하게 구성 |

**결과**: 개발자는 순수한 JAR/WAR 파일만 준비하여 업로드하면 됩니다.

---

#### 2. 🔄 코드와 환경 설정의 완벽한 분리

**하나의 JAR 파일, 여러 환경**

```
동일한 JAR 파일: Spring-Board-Project-0.0.1-SNAPSHOT.jar

├─ Dev 환경   (PROFILES=dev)        → H2 사용, 포트 5000
├─ Test 환경  (PROFILES=aws)        → RDS MySQL 사용, 포트 5000
└─ Prod 환경  (PROFILES=aws,health) → RDS MySQL + Actuator, 포트 5000
```

**환경 변수를 통한 동적 제어**

| 환경 | 환경 변수 | 활성화되는 설정 | 결과 |
|------|----------|--------------|------|
| **Dev** | `PROFILES=dev` | `application-dev.properties` | H2 내장 DB 사용 |
| **Test** | `PROFILES=aws`, `SPRING_SQL_INIT_MODE=never` | `application-aws.properties` | RDS MySQL 사용, SQL 초기화 안 함 |
| **Prod** | `PROFILES=aws,health`, `SPRING_SQL_INIT_MODE=never` | `application-aws.properties` + `application-health.properties` | RDS MySQL + Actuator 헬스 체크 |

**핵심 장점**
- ✅ 애플리케이션 코드(JAR 파일) 수정 없이 환경 전환
- ✅ 하나의 빌드 결과물로 모든 환경에 배포 가능
- ✅ 관리 효율성 극대화

---

#### 3. 🛡️ 환경별 아키텍처의 손쉬운 분리와 확장성 확보

**환경별 최적화된 인프라**

| 환경 | 인프라 | 구축 방법 | 시간 |
|------|--------|----------|------|
| **Dev/Test** | 단일 EC2 (Public Subnet) | EB 콘솔에서 클릭 몇 번 | 5분 |
| **Prod** | ELB + 2~4대 EC2 (Private Subnet) + 멀티-AZ RDS | EB 콘솔에서 클릭 몇 번 | 10분 |

만약 EC2(IaaS)에서 직접 구축한다면:
- 로드 밸런서 생성 및 리스너 규칙 설정
- 오토 스케일링 그룹 생성 및 정책 설정
- 시작 템플릿 작성
- 보안 그룹 규칙 정의
- CloudWatch 알람 설정
- **예상 소요 시간: 수 시간 ~ 수일**

---

### 🗄️ RDS 사용의 추가적인 이점

#### 데이터베이스 서버 직접 구동 및 관리 부담 해소

| 관리 항목 | EC2에 MySQL 직접 설치 (IaaS) | RDS 사용 (PaaS) |
|----------|----------------------------|----------------|
| **초기 설치** | MySQL 엔진 설치, `my.cnf` 구성, 환경 변수 설정 | AWS가 자동으로 설치 및 구성 |
| **OS 관리** | DB 서버의 OS 패치, 보안 업데이트, 디스크 관리 | AWS가 모든 OS 레벨 관리 및 보안 업데이트 자동 처리 |
| **고가용성** | DB 복제(Replication) 및 장애 조치(Failover)를 수동으로 구축 | 멀티-AZ 배포 시, 자동으로 이중화 및 장애 감지/복구 |
| **백업/복구** | 백업 스크립트 작성, 스토리지 관리, 복구 테스트 | 자동 백업 및 특정 시점 복구(Point-in-time recovery) 기능 자동 제공 |

**결과**: 개발자는 DB 서버의 설치, 보안, 백업, 복구에 신경 쓸 필요 없이, 오직 애플리케이션에 필요한 SQL 스키마와 쿼리에만 집중할 수 있습니다.

---

### 🎯 PaaS를 통한 배포 자동화 완성

**EB + RDS 결합의 시너지**

```
Elastic Beanstalk (EB)
  ↓
애플리케이션의 실행과 확장을 자동화
  +
Amazon RDS
  ↓
데이터베이스의 관리와 안정성을 자동화
  =
진정한 PaaS 경험
```

**개발자의 역할 변화**

| 항목 | IaaS (EC2+ 직접 MySQL) | PaaS (EB + RDS) |
|------|-------------------|-----------------|
| **인프라 관리** | 서버 생성, OS 패치, 보안 업데이트, 미들웨어 설치 | 플랫폼 선택만 |
| **배포** | SCP 전송, 수동 배치, 서버 재시작 | JAR 파일 업로드만 |
| **스케일링** | 수동으로 서버 추가, 로드 밸런서 설정 | 최소/최대 값만 지정 |
| **모니터링** | 별도 도구 설치 및 설정 | CloudWatch 자동 통합 |
| **DB 관리** | 설치, 백업, 복구 스크립트 작성 | RDS가 자동 처리 |
| **집중 영역** | 인프라 + 애플리케이션 | 애플리케이션만 |

---

## 7.2.9 실무 배포 프로세스

### 🔄 일반적인 배포 워크플로

**1. 코드 작성 및 로컬 테스트**

```bash
# 로컬에서 개발 및 테스트
./gradlew bootRun
```

**2. JAR 파일 빌드**

```bash
# 프로젝트 루트 디렉터리에서
./gradlew clean bootJar

# 빌드 결과 확인
ls build/libs/
# Spring-Board-Project-0.0.1-SNAPSHOT.jar
```

**3. EB 콘솔에서 새 버전 업로드**

```
Elastic Beanstalk → 애플리케이션 → spring-demo → 애플리케이션 버전

업로드 버튼 클릭:
  버전 레이블: 2.1.0
  소스: Spring-Board-Project-0.0.1-SNAPSHOT.jar
```

**4. 원하는 환경에 배포**

```
옵션 1: 기존 환경 업데이트 (무중단 배포)
  환경 선택 → Spring-demo-prod → 배포
  새 버전 선택 → 2.1.0
  배포 방법: Rolling (점진적 배포)

옵션 2: 새 환경 생성 (블루-그린 배포)
  새 환경 생성 → Spring-demo-prod-v2
  안정화 후 DNS 전환
```

**5. 배포 확인**

```
환경 상태: Ok ✅
인스턴스: 2대 모두 Healthy
헬스 체크: 통과

브라우저 접속:
http://Spring-demo-prod.eba-xxxxxxx.ap-northeast-2.elasticbeanstalk.com
```

---

### 🚀 고급 배포 전략

#### Rolling 배포 (점진적 배포)

**동작 방식**

```
시작: 4대의 인스턴스 모두 v1.0 실행

1. ELB가 인스턴스 1, 2를 트래픽에서 제외
2. 인스턴스 1, 2에 v2.0 배포 및 시작
3. 헬스 체크 통과 확인
4. ELB가 인스턴스 1, 2를 다시 트래픽에 포함
5. ELB가 인스턴스 3, 4를 트래픽에서 제외
6. 인스턴스 3, 4에 v2.0 배포 및 시작
7. 헬스 체크 통과 확인
8. ELB가 인스턴스 3, 4를 다시 트래픽에 포함

완료: 4대의 인스턴스 모두 v2.0 실행
```

**장점**
- ✅ 서비스 중단 없음 (항상 최소 2대는 실행 중)
- ✅ 추가 비용 없음 (기존 인스턴스만 사용)

**단점**
- ⚠️ 배포 중 용량 감소 (일시적으로 절반만 서비스)

---

#### Blue-Green 배포

**동작 방식**

```
Blue 환경 (현재 운영):
  Spring-demo-prod (v1.0)
  인스턴스 4대
  
Green 환경 (새 버전):
  Spring-demo-prod-v2 (v2.0)
  인스턴스 4대 (새로 생성)

1. Green 환경 완전히 구축 및 테스트
2. DNS를 Blue → Green으로 전환
3. 문제 없으면 Blue 환경 종료
4. 문제 발생 시 DNS를 Blue로 즉시 롤백
```

**장점**
- ✅ 완전한 롤백 가능 (Blue 환경 유지)
- ✅ 배포 중 용량 유지 (두 환경 모두 전체 용량)

**단점**
- 💰 배포 중 비용 2배 (두 환경 동시 운영)

---

### 🚀 7.3장 예고: Docker 배포 (환경 표준화)

7.2장에서 EB(PaaS)의 장점을 충분히 경험했습니다. 하지만 EB도 한계가 있습니다:

**EB의 한계**
- ⚠️ 구체적인 JDK/Tomcat 버전 지정 불가 (AWS가 선택한 버전 사용)
- ⚠️ 플랫폼 브랜치가 업데이트되면 버전이 바뀔 수 있음
- ⚠️ 로컬 개발 환경과 EB 환경의 미묘한 차이 가능성
- ⚠️ 단일 JAR 파일(단일 애플리케이션)만 배포 가능.


---
# 7.3 도커 배포 (환경 표준화)

## 📖 학습 개요

**핵심 주제**: Docker를 활용한 컨테이너 기반 배포 및 환경 표준화  
**사용 기술**: Docker, Dockerfile, Docker Image, Docker Container, Docker Hub, AWS Elastic Beanstalk  
**학습 목표**: 
- Docker의 핵심 개념(Dockerfile, Image, Container)을 완벽히 이해
- IaaS와 PaaS의 한계를 극복하는 컨테이너 기술의 가치 체험
- 스프링 부트 애플리케이션을 컨테이너화하여 배포하는 2가지 방식 실습
- "어디서나 동일하게 실행되는" 환경 표준화 달성

---

## 7.3.1 왜 Docker가 필요한가?

### 🔍 이전 배포 방식의 한계 재조명

7.1장과 7.2장에서 경험한 배포 방식들의 근본적인 문제점을 다시 정리해봅시다.

**IaaS (EC2)의 문제점**
- 서버마다 JDK, Tomcat을 수동 설치해야 함
- 환경 설정 실수로 인한 "내 컴퓨터에서는 되는데" 문제 발생
- 확장 시 동일한 설정을 반복해야 하는 비효율성

**PaaS (Elastic Beanstalk)의 한계**
- AWS가 제공하는 플랫폼 버전에 종속됨
- 구체적인 JDK 마이너 버전(예: `21.0.8`)까지 세밀하게 지정 불가
- 플랫폼 브랜치 업데이트 시 예상치 못한 버전 변경 가능성
- 단일 JAR 파일만 배포 가능 (복수 애플리케이션 구성 불가)

### 🎯 Docker가 해결하는 문제

| 문제 | IaaS/PaaS | Docker |
|------|-----------|--------|
| **환경 불일치** | 개발/테스트/운영 환경이 미묘하게 다를 수 있음 | 동일한 이미지를 어디서나 사용 |
| **버전 통제** | 플랫폼 제공 버전에 의존 | Dockerfile에서 모든 버전을 명시적으로 지정 |
| **복잡한 구성** | 단일 애플리케이션만 간단히 배포 가능 | 여러 서비스를 독립적으로 실행 가능 |
| **이식성** | 특정 클라우드 환경에 종속 | 로컬, AWS, Azure 등 어디서나 동일하게 실행 |

---

## 7.3.2 Docker 핵심 개념

### 📦 Docker란?

**Docker**는 컨테이너 기술을 기반으로 가상의 독립된 환경을 제공하는 플랫폼입니다. 하이퍼바이저 기술을 기반으로 한 가상 머신과 달리 도커는 호스트 OS의 커널을 그대로 사용해 CPU 및 메모리 리소스를 상대적으로 적게 사용함으로써 물리적인 하드웨어 자원을 더욱 효율적으로 사용이 가능하도록 지원합니다.

### 🔑 Docker의 3대 핵심 개념

Docker를 이해하기 위해서는 다음 세 가지 핵심 개념을 명확히 구분해야 합니다.

```
Dockerfile (설명서) → Build → Docker Image (청사진) → Run → Docker Container (실행 환경)
```

| 개념 | 역할 | 비유 |
|------|------|------|
| **Dockerfile** | 설계도 / 레시피 | 어떻게 패키징할 것인지를 순서대로 정의한 텍스트 파일 |
| **Docker Image** | 패키징된 결과물 | Dockerfile을 이용해 만든 실행에 필요한 모든 것이 담긴 읽기 전용 파일 |
| **Docker Container** | 실행 가능한 환경 | Docker Image를 메모리에서 동작시키는 독립된 실행 단위 |

**흐름 요약:**
1. 당신은 **Dockerfile**을 작성합니다.
2. `docker build` 명령으로 Dockerfile을 입력하여 **Docker Image**를 만듭니다.
3. `docker run` 명령으로 Docker Image를 실행하여 **Docker Container**를 생성하고 구동합니다.

---

### 🖥️ 가상 머신 vs Docker

#### "호스트 OS 커널을 그대로 사용한다"는 의미

| 구분 | VMware 방식 | Docker 방식 |
|------|-------------|-------------|
| **커널 사용** | 하이퍼바이저를 통해 **전체 Guest OS(커널 포함)**를 호스트 OS 위에 새로 설치하여 완벽히 독립된 가상 환경을 만듭니다. (무겁고 느림) | 윈도우 위에 리눅스 OS를 새로 설치하는 대신, **리눅스 커널의 특정 기능(격리 기능)**만을 사용하여 애플리케이션 실행 환경을 분리합니다. |
| **리소스 사용** | 각 VM마다 OS를 실행하므로 메모리/CPU 소모가 큼 | 호스트 커널을 공유하므로 경량화됨 |
| **부팅 속도** | 느림 (OS 부팅 필요) | 빠름 (프로세스 시작만 필요) |

---

### 🪟 Windows에서 Docker 사용: WSL2의 역할

#### 1. 🎯 왜 리눅스 환경이 필수인가?

도커 컨테이너 기술은 **호스트 OS의 커널**이 제공하는 특정 기능에 전적으로 의존하여 작동합니다.

| 도커 작업 | 필요한 이유 (리눅스 의존성) |
|----------|---------------------------|
| **컨테이너 생성/실행** | 컨테이너는 별도의 OS를 설치하지 않고, 호스트 커널의 **Namespace** (프로세스, 네트워크 등을 격리)와 **Control Groups (cgroups)** (CPU, 메모리 자원 할당 및 제한) 기능을 사용하여 독립성을 확보합니다. 이 두 핵심 기술은 리눅스 커널에만 내장되어 있습니다. |
| **도커 이미지 빌드** | 대부분의 서버 애플리케이션(Alpine, Ubuntu 기반) 자체가 리눅스에서 구동되도록 설계되었습니다. 이미지를 만드는 과정(파일 복사, 패키지 설치 등) 역시 이 리눅스 기반 파일 시스템 위에서 수행되어야 합니다. |

**결론**: 컨테이너의 핵심인 격리와 자원 제어 기능이 리눅스 커널에서만 제공되므로, 도커를 제대로 사용하려면 리눅스 커널이 반드시 필요합니다.

#### 2. 🪟 Windows의 문제와 WSL2의 등장 배경

| 문제 상황 | 해결책의 등장 배경 |
|----------|------------------|
| **Windows의 한계** | Windows의 자체 커널은 리눅스 커널이 제공하는 Namespace나 cgroups와 같은 기능을 갖고 있지 않습니다. 따라서 Windows 커널 위에서는 리눅스 컨테이너를 직접 실행할 수 없습니다. |
| **초기 해결책** | 초기에는 Oracle VirtualBox 같은 무거운 전통적인 VM을 띄워 그 위에 도커 환경을 설치해야 했습니다. 이는 느리고 비효율적이었습니다. |
| **WSL2의 등장** | Microsoft는 이 문제를 해결하기 위해 **WSL2 (Windows Subsystem for Linux 2)**를 개발했습니다. WSL2는 Windows 시스템과 긴밀하게 통합된 **"작고 최적화된 리눅스 VM"**을 제공합니다. |

**WSL2 덕분에** Windows 사용자는 무거운 VM을 직접 관리할 필요 없이, 도커의 모든 기능을 Windows 환경에서 가볍고 빠르게 사용할 수 있게 되었습니다.

#### 3. ⚙️ WSL2를 통한 작동 원리

사용자가 Windows CMD나 PowerShell에서 도커 명령을 실행할 때 실제 컨테이너가 실행되는 과정은 다음과 같습니다.

| 단계 | 실행 환경 | 상세 역할 |
|------|----------|----------|
| **1. 명령 입력** | Windows 터미널 | 사용자가 `docker build` 또는 `docker run` 명령을 입력합니다. |
| **2. 명령 전달** | Docker Desktop | Docker Desktop 애플리케이션이 이 명령을 가로채서 백그라운드에서 실행 중인 WSL2 VM으로 전달합니다. |
| **3. 빌드/실행** | WSL2 내부의 리눅스 커널 | WSL2 VM이 리눅스 커널 기능을 사용하여 이미지 빌드 또는 컨테이너 생성/실행 작업을 수행합니다. |
| **4. 결과 반환** | Windows 터미널 | 작업 결과(로그 또는 컨테이너 ID)를 다시 Windows 터미널로 반환합니다. |

**결론**: WSL2는 Windows와 리눅스 컨테이너 기술 사이를 연결하는 필수적인 다리(Bridge) 역할을 하며, 사용자에게는 마치 도커가 Windows 프로그램처럼 작동하는 것처럼 보이게 해줍니다.

---

### 🖼️ 컨테이너의 정체: 서버인가? 가상환경인가?

컨테이너는 서버 그 자체(컴퓨터)는 아니지만, 서버의 역할을 수행하는 '가상 환경'입니다. 이는 **'Tomcat WAS가 돌아가는, 작고 격리된 리눅스 서버'**라고 이해하시면 가장 정확합니다.

#### 도커 컨테이너의 정의 (최종 요약)

도커 컨테이너는 다음과 같은 복합적인 성격을 가집니다.

| 관점 | 설명 |
|------|------|
| **서버가 아님** | 물리적/가상적 컴퓨터(EC2) 자체는 아닙니다. |
| **서버 역할 수행** | 그러나 **서버 프로그램(Tomcat WAS)**을 실행하고 HTTP 요청을 처리하는 역할을 합니다. |
| **가상 환경** | 호스트 OS의 커널을 공유하는 격리된 환경입니다. |
| **리눅스 기반** | 대부분의 경우 리눅스 OS 환경을 복제합니다. |

---

## 7.3.3 Docker 설치 및 기본 명령어

### 📥 Docker 설치

#### Docker Desktop 설치

[Docker 공식 웹사이트](https://www.docker.com/products/docker-desktop/)에서 Docker Desktop을 다운로드하여 설치합니다.

**설치 후 확인**

```cmd
C:\Users\ghddm> docker info
```

이 명령어가 정상적으로 실행되면 Docker Desktop 애플리케이션이 백그라운드에서 WSL2 리눅스 커널 위에서 도커 데몬을 성공적으로 구동시키고 있는 것입니다.

---

### 🔍 Docker 기본 명령어

Docker를 효과적으로 사용하기 위해서는 명령어에 익숙해져야 합니다. 서버 환경에서 도커를 운영하기 위해서는 콘솔 UI보다 커맨드 라인 사용이 필수입니다.

#### 1. 이미지 검색: `docker search`

`docker search` 명령어는 Docker Hub에 등록된 이미지를 검색할 수 있습니다.

```cmd
C:\Users\ghddm> docker search mysql
NAME                   DESCRIPTION                                      STARS     OFFICIAL
mysql                  MySQL is a widely used, open-source relation…   15983     [OK]
bitnami/mysql          Bitnami Secure Image for mysql                   145
circleci/mysql         MySQL is a widely used, open-source relation…   32
```

**이미지 이름 규칙**
- **사용자 계정/리포지토리이름**: 일반 사용자가 올린 이미지 (예: `bitnami/mysql`)
- **리포지토리이름만**: 공식 이미지로 인정받은 경우 사용자 계정이 생략됨 (예: `mysql`)

**OFFICIAL 컬럼**: `[OK]`로 표시되면 Docker Hub에서 공식적으로 인증한 이미지를 의미합니다.

---

#### 2. 이미지 다운로드: `docker pull`

`docker pull` 명령어는 Docker Hub와 같은 레지스트리에서 이미지를 다운로드합니다.

**기본 사용법**

| 방식 | 명령어 | 설명 |
|------|--------|------|
| **최신 버전** | `docker pull mysql` | 태그를 생략하면 자동으로 `latest` 태그가 붙은 이미지를 다운로드 (실제: `docker pull mysql:latest`) |
| **특정 버전** | `docker pull mysql:8.0.35` | 콜론(`:`)을 붙이고 버전 태그를 명시하여 특정 버전 다운로드 |

**다운로드 예시**

```cmd
C:\Users\ghddm> docker pull mysql
Using default tag: latest
latest: Pulling from library/mysql
21aa606d8d58: Pull complete
834e15e3ed24: Pull complete
480d01bd7a6a: Pull complete
...
Status: Downloaded newer image for mysql:latest
docker.io/library/mysql:latest
```

**Repository와 이미지 이름**

| 이미지 형태 | 참조 위치 | 설명 |
|-----------|----------|------|
| **공식 이미지** | `mysql`, `nginx` | 이름만 사용할 경우 공식 Docker Hub 계정의 이미지를 참조 |
| **비공식 이미지** | `bitnami/mysql` | `/` 앞에 계정 이름이 붙으면 **특정 사용자(bitnami)**가 올린 비공식 이미지를 참조 |

---

#### 3. 로컬 이미지 목록 확인: `docker image list`

`docker image list` 명령어는 로컬 컴퓨터에 현재 다운로드되어 있는 이미지들을 보여줍니다.

```cmd
C:\Users\ghddm> docker image list
REPOSITORY   TAG       IMAGE ID       CREATED       SIZE
mysql        latest    569c4128dfa6   3 weeks ago   1.27GB
```

**중요**: 이 명령의 결과는 Docker Hub의 이미지가 아니라, **당신의 로컬 컴퓨터(Docker Desktop이 설치된 환경)의 저장소**에 현재 다운로드되어 있는 이미지들을 보여주는 것입니다.

---

#### 4. 이미지 삭제: `docker image rm`

`docker image rm` 명령어는 로컬 저장소에 있는 **도커 이미지(Image)**를 삭제합니다.

**기본 사용법**

| 삭제 대상 | 명령어 예시 |
|----------|------------|
| **이미지 이름 + 태그** | `docker image rm mysql:latest` |
| **이미지 ID** | `docker image rm 569c4128dfa6` |
| **이미지 이름만** | `docker image rm mysql` (태그를 지정하지 않으면 자동으로 `latest` 태그가 적용됨) |

**삭제 예시**

```cmd
C:\Users\ghddm> docker image rm mysql
# 또는
C:\Users\ghddm> docker image rm mysql:latest
# 또는
C:\Users\ghddm> docker image rm 569c4128dfa6
```

**참고**: `latest` 태그 자동 적용 - 명령어에서 `docker image rm mysql`처럼 태그를 지정하지 않으면 도커는 `mysql:latest` 이미지를 삭제하라는 의미로 해석합니다.

---

#### 5. 컨테이너 실행: `docker run`

`docker run` 명령어는 **이미지를 컨테이너로 만들고 실행**하는 가장 기본적인 명령어입니다.

**기본 형식**

```
docker run [옵션] [이미지 이름]:[태그]
```

| 구성 요소 | 예시 | 역할 |
|----------|------|------|
| `docker run` | `docker run` | 컨테이너를 생성하고 바로 실행하는 명령어 |
| `[이미지 이름]` | `mysql` | Docker Hub에 등록된 저장소(Repository) 이름을 지정 |
| `:[태그]` (선택) | `:8.0` 또는 `:latest` | 사용할 버전을 지정. 생략하면 자동으로 **`:latest`**가 사용됨 |

**중요**: `docker run`의 의미를 제대로 알아야 합니다!

#### `docker run` 명령어의 내부 동작

`docker run` 명령어는 다음의 두 단계를 순차적으로 실행하는 편리한 단축키입니다.

1. **`docker create` (생성)**: 이미지를 기반으로 컨테이너 인스턴스를 생성합니다. 이 단계에서 컨테이너의 파일 시스템, 네트워크 설정, 환경 변수 등이 설정됩니다. 이 시점에는 컨테이너가 존재하지만 아직 실행되고 있지는 않습니다.
2. **`docker start` (시작)**: 생성된 컨테이너 인스턴스를 **실행 상태(Running)**로 전환하여 내부 프로세스(MySQL 서버 등)가 작동하도록 만듭니다.

**결론**: 이미지로부터 컨테이너를 만들고!! 실행하는 과정을 하나의 명령어로 수행하는 것입니다.

---

#### 6. 컨테이너 관리 명령어

컨테이너를 생성, 시작, 중지, 삭제하는 명령어들을 정리합니다.

| 명령어 | 역할 | 목적 |
|--------|------|------|
| `docker create [이미지]` | 컨테이너를 생성만 하고 실행하지 않습니다. | 환경 설정이 복잡한 컨테이너를 미리 준비해 둘 때 사용합니다. |
| `docker start [컨테이너명]` | 기존에 중지된 컨테이너를 다시 실행합니다. | 설정이 완료된 컨테이너를 삭제하지 않고 재사용할 때 사용합니다. |
| `docker stop [컨테이너명]` | 실행 중인 컨테이너를 안전하게 중지합니다. | 컨테이너를 잠시 멈추고 싶을 때 사용합니다. |
| `docker restart [컨테이너명]` | 중지된 컨테이너를 다시 시작하거나, 실행 중인 컨테이너를 잠시 멈췄다가 다시 시작합니다. | 설정 변경 후 재시작이 필요할 때 사용합니다. |
| `docker rm [컨테이너명]` | 컨테이너를 영구적으로 삭제합니다. | ⚠️ 삭제 전에 반드시 `stop`해야 합니다. |

**결론**: 개발 환경에서는 `docker run`을 자주 사용하지만, 배포 환경에서는 컨테이너를 껐다가 다시 켜기 위해 **`docker stop`**과 **`docker start`**를 주로 사용합니다.

---

#### 7. `docker run` 주요 옵션

`docker run` 명령어에서 사용할 수 있는 주요 옵션들을 상세히 설명합니다.

##### 옵션 1: `--name` (컨테이너 이름 지정)

**역할**: 컨테이너에 식별 가능한 이름을 부여합니다.

**중요한 점**: 컨테이너 이름은 단순히 식별자를 넘어, **네트워크 내에서 해당 컨테이너의 호스트 이름(Hostname)** 역할을 합니다.

**예시**

```cmd
docker run --name my-db-server mysql
```

만약 컨테이너 이름을 `my-db-server`라고 지정했다면, 다른 컨테이너는 이 이름을 DNS 주소처럼 사용하여 `my-db-server:3306`으로 데이터베이스에 접속할 수 있습니다.

**컨테이너 이름의 의미**

컨테이너는 가상환경, 가상컴퓨터라고 했는데, 이 컴퓨터의 IP 즉 DNS 주소처럼 사용할 수 있다는 것입니다.

**예시**: Spring Container가 DB Container (`--name my-db-server`)에 접속할 때:
```
jdbc:mysql://my-db-server:3306/mydb
```

3306에 MySQL 서버가 열려있는데, 어떤 컴퓨터에? 아까 만든 `my-db-server` 가상 컴퓨터의 3306 포트로 열려있는 것에 접근한다와 같이 사용할 수 있습니다!

---

##### 옵션 2: `-e` (환경 변수 설정)

**역할**: 컨테이너의 환경 변수를 설정합니다.

#### 🔑 `-e` 옵션의 역할: 환경 변수 설정

`-e` 옵션은 컨테이너 내부의 OS 환경에 직접 변수를 주입하는 역할을 합니다.

**1. 설정 시점**
- **실행 직전**: `docker run` 명령이 컨테이너를 시작하는 직전에 변수가 설정됩니다.
- **프로세스 환경**: 컨테이너 내부에서 실행되는 모든 프로세스(특히 Tomcat WAS 프로세스)는 이 설정된 환경 변수를 자신의 실행 환경으로 상속받아 사용하게 됩니다.

**2. Spring Boot에서의 활용**

Spring Boot 애플리케이션은 실행 시 다음 순서로 설정값을 읽어옵니다.

1. 환경 변수 (`-e`로 설정된 값)
2. 커맨드 라인 인자
3. `application.properties` / `.yml` 파일

이 때문에 `-e`로 설정한 값은 `application.yml`에 있는 값보다 우선권을 가지므로, 애플리케이션의 설정(예: 데이터베이스 접속 정보, Spring Profile 등)을 외부에서 동적으로 변경하는 데 매우 유용합니다.

---

##### 옵션 3: `-d` (Detached Mode - 백그라운드 실행)

**역할**: 컨테이너 내부에서 실행되는 서버 프로세스(MySQL, 톰캣 등)를 **백그라운드(Detached mode)**에서 실행하도록 지시합니다.

#### 🔑 `-d` 옵션의 역할 (Detached Mode)

**1. 콘솔 분리 및 백그라운드 실행**
- **목적**: 컨테이너 실행에 사용한 현재 터미널/CMD 창을 컨테이너의 로그로부터 분리하여, 사용자가 다른 작업을 할 수 있도록 제어권을 돌려줍니다.
- **작동**: `docker run -d mysql`을 실행하면, 터미널에는 컨테이너 ID만 출력되고, 컨테이너는 호스트 OS의 백그라운드에서 계속 실행됩니다.

**2. 서버 프로세스에 필수적**

MySQL, 톰캣과 같은 서버 프로세스는 한번 실행되면 계속해서 요청을 대기해야 합니다.
- **`-d`가 없다면** (포그라운드 실행), 서버 프로세스의 로그가 터미널을 점유하여 다른 명령을 입력할 수 없게 됩니다.
- 서버 애플리케이션이나 데이터베이스는 지속적인 구동이 필요하므로, **`-d` 옵션은 필수적**으로 사용됩니다.

**요약**: `-d` 옵션은 컨테이너 내부의 Tomcat WAS나 MySQL 같은 서버 프로세스들이 터미널에 묶이지 않고 백그라운드에서 24시간 서비스를 제공할 수 있도록 해줍니다.

---

##### 옵션 4: `-p` (포트 매핑)

**역할**: 호스트의 포트와 컨테이너 내부 포트를 연결(매핑)합니다.

#### 🔑 `-p` 옵션의 핵심 개념

핵심은 **호스트(Host) 컴퓨터가 외부와의 통신 창구를 제공**하고, **`-p` 옵션이 이 창구와 컨테이너 내부를 연결하는 '다리' 역할**을 한다는 것입니다.

**Docker 포트 매핑 및 `-p` 옵션의 역할**

| 용어 | 역할 | 예시 값 |
|------|------|---------|
| **호스트 (Host)** | 외부 요청의 입구 | 컨테이너가 실행되는 실제 컴퓨터 (당신의 PC 또는 AWS EC2 인스턴스)를 의미합니다. 클라이언트가 접근할 수 있는 물리적/가상적 서버입니다. |
| **호스트 포트** | 외부 노출 포트 | `9000`. 클라이언트가 요청하는 포트(`localhost:9000`)이며, 호스트 OS가 열어줍니다. |
| **컨테이너 포트** | 내부 목적지 포트 | `8080`. 컨테이너 내부에서 Tomcat WAS 프로세스가 실제로 듣고 있는 포트입니다. |
| **`-p` 옵션** | 매핑 (연결) | `9000:8080`은 호스트 OS에게 "9000번 포트로 들어온 모든 요청을 해당 컨테이너의 8080번 포트로 전달(포워딩)하라"고 지시합니다. |

#### 🔍 작동 원리

```
1. 클라이언트 요청: 브라우저에서 localhost:9000으로 요청합니다.
   ↓
2. 호스트 수신: 당신의 컴퓨터(호스트)가 9000 포트에서 이 요청을 받습니다.
   ↓
3. 도커 라우팅: 도커 데몬은 설정된 -p 규칙에 따라, 9000 포트 트래픽을 격리된 컨테이너 내부의 8080 포트로 정확하게 전달합니다.
   ↓
4. WAS 응답: 컨테이너 내부의 톰캣 프로세스가 요청을 처리하고 응답을 돌려줍니다.
```

**결론**: `-p 9000:8080`은 호스트의 문(9000)을 열어 컨테이너 내부의 서버(8080)와 연결하는 필수적인 설정입니다.

---

#### 도커 포트 격리 및 충돌 회피 원리

도커 컨테이너 환경에서 Tomcat WAS의 포트 번호가 겹쳐도 문제가 없는 이유는 다음과 같습니다.

**1. 내부 포트는 격리되어 있습니다.**

| 개념 | 설명 |
|------|------|
| **Tomcat의 역할** | 각 JAR 파일 내의 Tomcat WAS는 자신의 환경(컨테이너) 내에서 내부 포트(8080, 7070 등)를 열고 실행됩니다. 이 포트는 컨테이너 내부 프로세스를 식별하기 위해 존재합니다. |
| **격리** | 컨테이너는 운영체제(OS) 수준에서 네트워크가 **완전히 분리(격리)**되어 있습니다. 따라서 컨테이너 A의 8080번 포트와 컨테이너 B의 8080번 포트는 서로 다른 가상 공간에 존재하므로, 절대 충돌하지 않습니다. |

**2. 호스트 포트만 중복을 피하면 됩니다.**

| 개념 | 설명 |
|------|------|
| **외부 접근** | 외부 클라이언트가 접근할 수 있는 유일한 경로는 **호스트 컴퓨터(당신의 PC)**가 열어둔 포트입니다. 이를 호스트 포트라고 합니다. |
| **충돌 회피** | 도커는 이 호스트 포트와 컨테이너 내부 포트를 연결해 주는 라우팅 다리를 만듭니다. 이 호스트 포트만 운영체제 내에서 겹치지 않으면 됩니다. |

**포트 매핑 예시**

| 컨테이너 | 내부 포트 (겹침 허용) | 호스트 포트 (겹치면 안 됨) |
|----------|-------------------|------------------------|
| A (hyechang) | 8080 | 8080 (외부 접근용) |
| B (woohyun) | 8080 | 8081 (외부 접근용) |

**결론**: 컨테이너 내부의 8080은 내부 포트이므로 겹쳐도 상관없고, 외부에서 접근하기 위해 설정하는 호스트 포트(8080, 8081)만 중복되지 않도록 `-p` 옵션을 통해 잘 매핑해주면 됩니다.

---

#### 8. 실전 예시: MySQL 컨테이너 실행

지금까지 배운 옵션들을 종합하여 MySQL 컨테이너를 실행해봅시다.

```cmd
C:\Users\ghddm> docker run --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes -e MYSQL_DATABASE=mydb -e MYSQL_USER=myuser -e MYSQL_PASSWORD=mypassword -d mysql

f26e1dce67362a577c33c3ce3e3443abbc34e52d0ca2b5902a2a6f231005ddff
```

#### 🚀 `docker run` 명령어 작동 분석

**1. 컨테이너 생성 및 실행**

```
docker run --name mysql -d mysql
```

| 부분 | 의미 |
|------|------|
| `mysql` (이미지) | Docker Hub에서 `mysql:latest` 이미지를 다운로드하거나 로컬 이미지를 사용합니다. |
| `--name mysql` | 생성될 컨테이너에 `mysql`이라는 이름을 부여합니다. 이 이름은 나중에 다른 컨테이너(Spring Boot 앱)가 네트워크에서 DB를 찾을 때 사용할 호스트 이름이 됩니다. |
| `-d` | MySQL 서버 프로세스를 백그라운드에서 실행하도록 지시합니다. |

**가상 환경과 포트**: 이 명령은 **작은 가상 환경(컨테이너)**을 만들고, 그 내부에서 MySQL 서버 프로세스가 기본 포트인 3306을 열고 구동되도록 합니다.

**2. 환경 변수 (`-e`)를 통한 설정 (핵심)**

`-e` 옵션들은 컨테이너가 처음 시작될 때 MySQL 서버를 초기 설정하도록 지시하는 환경 변수입니다.

| 환경 변수 | 값 | 역할 및 의미 |
|----------|-----|------------|
| `MYSQL_RANDOM_ROOT_PASSWORD` | `yes` | root 계정의 비밀번호를 자동으로 랜덤하게 생성하여 보안을 강화합니다. |
| `MYSQL_DATABASE` | `mydb` | MySQL 서버가 구동된 후, `mydb`라는 이름의 데이터베이스를 자동으로 생성하도록 지시합니다. |
| `MYSQL_USER` | `myuser` | `myuser`라는 일반 사용자 계정을 생성하도록 지시합니다. |
| `MYSQL_PASSWORD` | `mypassword` | 생성된 `myuser` 계정의 비밀번호를 `mypassword`로 설정합니다. |

**3. 최종 결론**

이 명령은 MySQL 서버 프로세스를 구동하기 전에, `mydb`라는 데이터베이스를 미리 만들고 `myuser`라는 계정까지 설정해놓습니다. 이 `myuser`와 `mypassword` 정보는 나중에 Spring Boot 애플리케이션의 `application.properties` 파일에 설정되어 데이터베이스에 접속할 때 사용됩니다.

---

#### 9. 컨테이너 로그 확인: `docker logs`

백그라운드로 실행중인 서버 프로세스의 상태를 보고 싶다면 `docker logs` 명령어를 사용합니다.

```cmd
docker logs -f mysql
```

**컨테이너 로그 확인 명령어**

| 명령어 부분 | 역할 | 설명 |
|-----------|------|------|
| `docker logs` | 로그 조회 명령 | 실행이 끝난 컨테이너 또는 현재 실행 중인 컨테이너의 표준 출력(Stdout)과 표준 에러(Stderr)를 가져옵니다. |
| `-f` (옵션) | Follow (실시간 스트리밍) | 로그 파일을 따라가며, 새롭게 기록되는 내용을 실시간으로 터미널에 계속 출력합니다. (MySQL 서버의 초기화 과정이나 쿼리 실행 로그를 볼 때 유용합니다.) |
| `mysql` | 컨테이너 이름 | `--name mysql` 옵션으로 지정한 컨테이너 이름(또는 컨테이너 ID)을 사용하여 로그를 조회할 대상을 지정합니다. |

**결론**: `docker logs -f mysql`을 실행하면, MySQL 서버가 부팅되는 과정과 모든 백그라운드 활동을 실시간으로 확인하면서 서버가 정상적으로 구동되었는지 검증할 수 있습니다.

---

#### 10. 컨테이너 목록 확인

실행 중인 컨테이너를 확인하는 명령어는 다음 두 가지입니다.

```cmd
C:\Users\ghddm> docker container list
CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                    NAMES
f26e1dce6736   mysql     "docker-entrypoint.s…"   About an hour ago   Up About an hour   3306/tcp, 33060/tcp   mysql

C:\Users\ghddm> docker ps
CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                    NAMES
f26e1dce6736   mysql     "docker-entrypoint.s…"   About an hour ago   Up About an hour   3306/tcp, 33060/tcp   mysql
```

**명령어 비교**

| 명령어 | 설명 |
|--------|------|
| `docker container list` | 표준화된 방식 (Docker 1.13 이후 권장) |
| `docker ps` | 레거시(구식) 방식 또는 간소화된 별칭 |

**Docker 명령어의 간소화**: 도커는 버전 1.13부터 명령어의 가독성과 일관성을 높이기 위해 명령어 스키마를 `docker [관리 대상] [명령]` 형태로 표준화했습니다. 현재 도커는 두 가지 방식 모두를 지원하며, **`container`**와 같은 관리 대상을 생략하고 **`docker ps`**처럼 사용하는 것을 허용합니다.

**결론**: 두 명령 모두 실행 중인 컨테이너 목록을 보여줍니다. 실무에서는 간결함을 위해 `docker ps`를 더 많이 사용합니다.

---

#### 11. 컨테이너 관리 명령어 종합

| 명령어 | 역할 | 설명 |
|--------|------|------|
| **중지** | `docker stop [컨테이너 ID 또는 이름]` | 실행 중인 컨테이너를 안전하게 중지합니다. 컨테이너 상태는 `Exited`로 변경됩니다. |
| **다시 시작** | `docker restart [컨테이너 ID 또는 이름]` | 중지된 컨테이너를 다시 시작하거나, 실행 중인 컨테이너를 잠시 멈췄다가 다시 시작합니다. |
| **시작** | `docker start [컨테이너 ID 또는 이름]` | 중지된(`Exited` 상태인) 컨테이너를 다시 실행 상태(`Running`)로 만듭니다. |
| **삭제** | `docker rm [컨테이너 ID 또는 이름]` | 컨테이너를 영구적으로 삭제합니다. (⚠️ 삭제 전에 반드시 `stop`해야 합니다.) |

**명령어 간소화 비교**

| 표준화된 방식 | 간소화된 방식 | 설명 |
|-------------|-------------|------|
| `docker container stop` | `docker stop` | 두 명령 모두 동일하게 작동 |
| `docker container start` | `docker start` | 두 명령 모두 동일하게 작동 |

**예시**

```cmd
C:\Users\ghddm> docker container stop mysql
mysql

C:\Users\ghddm> docker container start mysql
mysql
```

---

#### 12. 추가 유용한 명령어

**모든 컨테이너 목록 확인 (중지된 것 포함)**

```cmd
docker ps -a
# 또는
docker container list -a
```

**컨테이너 강제 삭제**

```cmd
docker rm -f [컨테이너명]
```

`-f` 옵션은 실행 중인 컨테이너도 강제로 삭제합니다. (일반적으로는 먼저 `stop` 후 `rm`을 권장)

**중지된 모든 컨테이너 일괄 삭제**

```cmd
docker container prune
```

**사용하지 않는 이미지 일괄 삭제**

```cmd
docker image prune
```

---

## 7.3.4 Spring Boot 이미지 빌드 방식 비교

Spring Boot 애플리케이션을 도커 이미지로 만드는 방법은 크게 **2가지**가 있습니다.

| 방식 | Dockerfile (전통적) | Buildpacks (Spring Boot 플러그인) |
|------|--------------------|------------------------------------|
| **명령어 예시** | `docker build -t app .` | `./gradlew bootBuildImage` (또는 Maven) |
| **구현 방법** | 개발자가 **모든 단계(`FROM`, `COPY`, `CMD`)**를 직접 작성합니다. | Spring Boot 플러그인이 자동으로 이미지를 분석하고 빌드합니다. (Dockerfile 작성 불필요) |
| **이미지 최적화** | 개발자가 신경 써야 함 (멀티 스테이지 빌드 필요). | 자동으로 계층화(Layering)하여 이미지 크기를 최소화하고 보안을 위해 종속성을 최신 상태로 유지합니다. |
| **실무 선호도** | 복잡한 요구사항 (예: Nginx 프록시 포함)이나 최대 제어가 필요할 때. | 🥇 대부분의 표준 Spring 앱 개발 및 CI/CD 환경. (단순함과 효율성 때문에 선호) |

---

### 이미지 생성 방식에 따른 배포 파일

도커 이미지를 만드는 방법에 따라 **EB에 배포하는 방식**이 달라집니다.

#### 1. Buildpacks 사용 시 (Pull 전략)

Buildpacks를 사용하는 경우, **이미지를 미리 만들어 놓는 것이 핵심**입니다.

| 단계 | 파일 | 역할 |
|------|------|------|
| **선행 작업 (CI/CD)** | JAR → Docker Image | 당신은 로컬이나 CI/CD 환경에서 `./gradlew bootBuildImage`를 실행하여 Docker Image를 만들고, 이 이미지를 Docker Hub/ECR에 Push합니다. |
| **EB 배포 시** | `Dockerrun.aws.json` | EB에는 이 JSON 파일을 올립니다. 이 파일은 EB에게 "저장소(Registry)에 있는 **[이미지 주소]:[태그]**를 다운로드(Pull)하여 실행해라"고 지시합니다. |

**요약**: 이미지를 만들 필요 없이, 이미지 주소(JSON)만 배포합니다.

---

#### 2. Dockerfile 사용 시 (Build 전략)

Dockerfile을 사용하는 경우, **빌드에 필요한 원본 재료를 서버에 제공**합니다.

| 단계 | 파일 | 역할 |
|------|------|------|
| **선행 작업 (Local)** | JAR 파일 | Gradle 빌드를 통해 애플리케이션 JAR 파일을 생성합니다. |
| **EB 배포 시** | `.zip` 패키지 | **Dockerfile**과 **JAR 파일**을 포함하여 필요한 설정 파일들을 하나의 `.zip` 파일로 묶어 EB에 업로드합니다. |

**요약**: EB는 이 ZIP 파일을 EC2 서버로 가져가서, Dockerfile을 읽고 JAR 파일을 이미지에 넣어 빌드를 수행한 후 실행합니다. 이 경우 **빌드 과정이 배포 서버에서 일어납니다.**

---

**중요**: 이미지를 만드는 방법에 따라 배포 방식이 달라진다는 점을 주의해야 합니다! 나중에 Elastic Beanstalk에 JAR가 아닌 컨테이너와 관련된 것을 올릴 때 무엇을 올릴지는 위 방법에 따라 달라집니다. 두 방법 모두 직접 사용해보도록 하겠습니다.

---

## 7.3.5 방법 1: 스프링 이미지 빌드 기능 사용

### 📦 CNB (Cloud Native Buildpacks) 이미지 생성

스프링 부트에는 이미지 빌드 기능이 내장되어 있어 메이븐과 그래들에서 **CNB (Cloud Native Buildpacks)**를 사용해 이미지를 패키징하기 위한 태스크를 제공합니다.

**사용 조건**: 이 기능을 사용하기 위해서는 빌드 환경에 도커 데몬이 실행되어 있어야 합니다.

#### 도커 데몬 확인

```cmd
C:\Users\ghddm> docker info
```

Docker Desktop 애플리케이션을 켜 놓는 것만으로, 백그라운드에서 WSL2 리눅스 커널 위에서 도커 데몬을 성공적으로 구동시키고 있는 것입니다.

---

### 1단계: 프로젝트 루트로 이동

`gradlew` (Gradle Wrapper 스크립트) 명령어를 실행하려면, 해당 프로젝트의 **루트 폴더(최상위 디렉터리)**로 이동해야 합니다.

```cmd
C:\Users\ghddm> cd C:\Users\ghddm\Desktop\SpringBoot\Spring-Boot-Portfolio\spring-boot-project\Spring-Board-Project
```

---

### 2단계: 이미지 빌드 실행

이동 후, `gradlew bootBuildImage` 를 수행합니다.

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> gradlew bootBuildImage
```

---

### ⚠️ 이미지 빌드 실패 원인 분석 및 해결

처음 `gradlew bootBuildImage` 명령을 실행했을 때, 빌드가 실패할 수 있습니다. 원인과 해결 과정은 다음과 같습니다.

| 문제 유형 | 오류 내용 | 원인 분석 | 해결 방안 |
|----------|----------|----------|----------|
| **이미지 이름 형식 위반** | `Execution failed for task ':bootBuildImage'. > 'value' [Spring-Board-Project] must be a parsable name...` | Spring Boot Buildpacks가 **프로젝트 이름(`Spring-Board-Project`)**을 그대로 이미지 이름으로 사용하려 했으나, Docker의 명명 규칙(모두 소문자만 허용)을 위반하여 발생했습니다. | `build.gradle` 파일에 `tasks.named('bootBuildImage')` 블록을 추가하고, **`imageName = "spring-board-project:latest"`**와 같이 소문자로 명시적으로 지정하여 문제를 해결했습니다. |

#### 해결 방법

**build.gradle**

```gradle
tasks.named('bootBuildImage') {
    // Docker 이미지 이름을 설정하는 올바른 위치
    imageName = "spring-board-project:latest"
}
```

이미지 이름을 직접 명시합니다!

---

### 3단계: 이미지 생성 확인

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker image list
REPOSITORY                               TAG       IMAGE ID       CREATED        SIZE
paketobuildpacks/ubuntu-noble-run-tiny   0.0.39    59ae515469d3   4 days ago     34.7MB
mysql                                    latest    569c4128dfa6   3 weeks ago    1.27GB
spring-board-project                     latest    19ac4dc0e730   45 years ago   612MB
paketobuildpacks/builder-noble-java-tiny latest    fedc06d972cb   45 years ago   1.18GB
```

`spring-board-project`가 만들어진 것을 볼 수 있습니다.

**⚠️ 주의**: `CREATED`에 `45 years ago`처럼 잘못 나온 것을 볼 수 있는데, 이는 Buildpacks의 메타데이터 처리 이슈입니다.

---

### 4단계: CREATED 날짜 수정

#### 해결방법 1: `build.gradle` 수정

```gradle
tasks.named('bootBuildImage') {
    // Docker 이미지 이름을 설정하는 올바른 위치
    imageName = "spring-board-project:latest"
    createdDate = "now"
}
```

`createdDate` 속성을 지정해줍니다.

#### 해결방법 2: 실행 옵션 사용

```cmd
gradlew bootBuildImage --imageName=hyechang_cnb --createdDate=now
```

**참고**: `hyechang_cnb:version`을 명시하지 않으면 `version`은 `latest`로 자동으로 선택됩니다.

#### 실행 결과

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> gradlew bootBuildImage --imageName=hyechang_cnb --createdDate=now

C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker image list
REPOSITORY                               TAG       IMAGE ID       CREATED             SIZE
hyechang_cnb                             latest    9b341b7cc7e6   About a minute ago  612MB
paketobuildpacks/ubuntu-noble-run-tiny   0.0.39    59ae515469d3   4 days ago          34.7MB
mysql                                    latest    569c4128dfa6   3 weeks ago         1.27GB
spring-board-project                     latest    19ac4dc0e730   45 years ago        612MB
paketobuildpacks/builder-noble-java-tiny latest    fedc06d972cb   45 years ago        1.18GB
```

`hyechang_cnb`가 생성된 것을 볼 수 있습니다.

**참고**: IntelliJ 사용 시 CMD에서 할 필요 없이 `Gradle → tasks → build → bootBuildImage`를 실행하면 됩니다.

---

### 5단계: 컨테이너 실행

이제 만든 이미지를 컨테이너로 만들고 실행해봅시다.

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker run -d --name my-spring-app -p 8888:8080 hyechang_cnb:latest
fb8ea1fcbd76c3954b920ff80309ae819054be4f9c0a2215f3a5dc7c85f85908

C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker container list
CONTAINER ID   IMAGE                COMMAND            CREATED         STATUS         PORTS                    NAMES
fb8ea1fcbd76   hyechang_cnb:latest  "/cnb/process/web"  40 seconds ago  Up 39 seconds  0.0.0.0:8888->8080/tcp, [::]:8888->8080/tcp  my-spring-app
f26e1dce6736   mysql                "docker-entrypoint.s…"   2 hours ago     Up 51 minutes  3306/tcp, 33060/tcp      mysql
```

**접속 확인**: `localhost:8888` 접속 시 앱이 보입니다! ✅

---

### 6단계: 컨테이너 종료

```cmd
C:\Users\ghddm> docker stop my-spring-app
my-spring-app
```

---

### 🏗️ Buildpacks 이미지 생성의 마법

`./gradlew bootBuildImage` 명령이 성공하면, 개발 환경의 세세한 설정을 신경 쓸 필요 없이 애플리케이션 실행에 필요한 모든 환경이 포함된 하나의 완벽한 도커 이미지를 자동으로 만들어줍니다.

#### 🏗️ Buildpacks 이미지 생성의 마법

이 과정은 **CNB(Cloud Native Buildpacks)** 기술을 사용하여 이루어지며, 개발자가 Dockerfile을 직접 작성할 필요 없이 환경을 표준화합니다.

#### 1. 포함되는 모든 환경 요소 (All-in-One Package)

성공적으로 빌드된 도커 이미지에는 다음 요소가 포함됩니다.

| 요소 | 설명 |
|------|------|
| **운영체제 기반 (Base OS)** | 최소한의 리눅스 배포판 (주로 경량화된Ubuntu Bionic 또는 Alpine 기반) |
| **런타임 (JDK)** | 애플리케이션의 `build.gradle` 파일에 명시된 정확한 Java Development Kit (JDK) 버전 |
| **WAS (웹 서버)** | Spring Boot Starter가 포함하고 있는 Tomcat (또는 Jetty) 서버의 구동 파일 |
| **애플리케이션 코드** | 최종적으로 컴파일된 실행 가능한 JAR 파일 |

#### 2. 자동 감지 및 설정 (Buildpacks의 역할)

Buildpacks는 소스 코드를 분석하여 다음을 자동으로 판단하고 설정합니다.

| 항목 | 설명 |
|------|------|
| **JDK 버전 결정** | `build.gradle`의 `java` 블록에 지정된 `languageVersion`을 보고 필요한 JDK 버전을 자동으로 설치합니다. |
| **WAS 구성** | `spring-boot-starter-web` 의존성이 감지되면, Tomcat을 WAS로 사용할 것을 자동 인식하고 컨테이너에 포함시킵니다. |
| **실행 파일** | Buildpacks는 실행 가능한 JAR 파일을 찾아 이미지 내부의 최적화된 위치에 복사하고, 이 JAR 파일을 실행하도록 **시작 명령어(Entrypoint)**까지 자동으로 설정합니다. |

**결론**: 개발자는 애플리케이션 코드를 작성하고 Gradle 태스크만 실행하면, Buildpacks가 **"어떤 버전의 JDK와 톰캣이 필요한지"**를 모두 판단하여 표준화된, 바로 실행 가능한 도커 이미지를 만들어주는 것입니다.

**요약**: 내 애플리케이션에 필요한 환경을 모두 정리해서 패키징 → 도커 이미지를 만들어주고, 단순히 이 도커 이미지를 컨테이너로 만들어서 이 컨테이너를 실행시키면 됩니다!

---

## 7.3.6 Docker Hub에 이미지 Push

만든 이미지를 Docker Hub에 업로드하여 다른 환경에서도 사용할 수 있도록 해봅시다.

### 1단계: Docker Hub 로그인

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker login
USING WEB-BASED LOGIN
i Info → To sign in with credentials on the command line, use 'docker login -u <username>'

Your one-time device confirmation code is: XVGQ-PKKH
Press ENTER to open your browser or submit your device code here: https://login.docker.com/activate

Waiting for authentication in the browser…
Login Succeeded
```

---

### 2단계: 이미지 태그 변경

#### docker tag의 필요성

`docker tag` 명령으로 사용자 ID를 이미지 이름 앞에 붙이는 이유는 당신의 **개인 저장소(Repository)**를 명확히 지정하기 위해서입니다.

#### 🔑 태그 변경의 이유: 네임스페이스 지정

**1. 로컬 이름의 문제**

`hyechang_cnb:latest`와 같은 이름으로 이미지를 푸시(`docker push`)하려고 하면, 도커는 이 이미지를 **`docker.io/library/hyechang_cnb`**와 같이 **Docker Hub의 공식 라이브러리 저장소(Official Library)**에 올리려고 시도합니다. 이 공식 라이브러리 영역은 접근이 엄격하게 제한되어 있어 일반 사용자는 이미지를 올릴 수 없습니다.

**2. 네임스페이스(Namespace) 지정**

**`hyechang2071148/hyechang_cnb:latest`**와 같이 `사용자 ID/저장소 이름` 형식을 사용하는 것은 Docker Hub에 **"이 이미지를 hyechang2071148 계정의 개인 저장소에 저장해 주세요"**라고 정확한 주소를 지정하는 행위입니다. 이 새로운 태그는 당신의 이미지가 Docker Hub의 광활한 저장소에서 정확히 당신의 영역(Namespace) 아래에 위치하도록 보장해 줍니다.

**결론**: 태그를 변경하는 것은 이미지의 주소를 **'특정 계정의 개인 저장소 주소'**로 변경하여, 푸시가 성공하도록 만드는 필수적인 과정입니다.

#### 태그 변경 명령어

```cmd
# 형식: docker tag [기존 이미지 이름]:[태그] [YOUR_USERNAME]/[새 이미지 이름]:[새 태그]
C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker tag hyechang_cnb:latest hyechang2071148/hyechang_cnb:latest

C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker image list
REPOSITORY                               TAG       IMAGE ID       CREATED          SIZE
hyechang2071148/hyechang_cnb             latest    9b341b7cc7e6   About an hour ago  612MB
hyechang_cnb                             latest    9b341b7cc7e6   About an hour ago  612MB
paketobuildpacks/ubuntu-noble-run-tiny   0.0.39    59ae515469d3   4 days ago         34.7MB
mysql                                    latest    569c4128dfa6   3 weeks ago        1.27GB
spring-board-project                     latest    19ac4dc0e730   45 years ago       612MB
paketobuildpacks/builder-noble-java-tiny latest    fedc06d972cb   45 years ago       1.18GB
```

새 태그 `hyechang2071148/hyechang_cnb`가 추가되었습니다.

---

### 3단계: Docker Hub에 Push

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker push hyechang2071148/hyechang_cnb:latest
```

#### 이미지 푸시 과정 분석

```
The push refers to repository [docker.io/hyechang2071148/hyechang_cnb]
[HASH]: Mounted from...
[HASH]: Pushed
latest: digest: sha256:...
```

| 로그 내용 | 의미 |
|----------|------|
| `The push refers to repository [docker.io/hyechang2071148/hyechang_cnb]` | 이미지가 당신의 Docker Hub 계정 네임스페이스로 전송됨을 확인합니다. |
| `[HASH]: Mounted from...` | 도커 이미지는 여러 개의 레이어(층)로 구성되는데, 이 레이어는 **이미 Docker Hub의 다른 저장소(주로 Buildpacks의 기본 레이어)**에 존재한다는 뜻입니다. 따라서 데이터 전송 없이 참조만 연결하여 푸시 속도를 높이고 저장 공간을 절약합니다. |
| `[HASH]: Pushed` | 당신의 애플리케이션 코드(JAR 파일) 등이 포함된 새로운 레이어는 실제로 데이터가 전송(Push)되어 업로드되었습니다. |
| `latest: digest: sha256:...` | 푸시가 성공적으로 완료되었으며, `latest` 태그가 이 새로운 이미지 다이제스트(고유 ID)를 가리킨다는 것을 확인합니다. |

**결론**: 이미지는 `hyechang2071148` 계정의 `hyechang_cnb` 저장소에 성공적으로 등록되었습니다.

---

### 4단계: Docker Hub에서 확인

업로드된 이미지를 웹에서 확인하려면 Docker Hub 웹사이트의 당신의 개인 저장소로 접속하면 됩니다.

1. **Docker Hub 접속**: 웹 브라우저에서 https://hub.docker.com/으로 이동합니다.
2. **로그인**: 당신의 계정(`hyechang2071148`)으로 로그인합니다.
3. **저장소 확인**: `Repositories` 탭을 클릭하거나 다음 주소로 이동합니다.

**확인 주소**: `https://hub.docker.com/r/hyechang2071148/hyechang_cnb`

https://hub.docker.com/repositories/hyechang2071148 에 가보면 `hyechang2071148/hyechang_cnb` 이미지가 업로드된 것을 볼 수 있습니다.

#### Push 성공 요약

| 상태 | 내용 |
|------|------|
| **docker push 성공** | `hyechang2071148/hyechang_cnb:latest` 이미지가 당신의 Docker Hub 계정으로 전송 완료되었습니다. |
| **현재 상태** | 저장 완료. 이제 AWS Elastic Beanstalk (EB) 같은 다른 환경에서 이 주소를 사용하여 이미지를 **다운로드(Pull)**할 수 있습니다. |

---

## 7.3.7 EB 배포를 위한 인증 정보 준비

이제 AWS Elastic Beanstalk(EB)가 당신의 이미지를 안전하게 다운로드(Pull)할 수 있도록 준비하는 단계가 필요합니다. 

AWS의 **S3 (Simple Storage Service)**는 무제한의 파일 저장소로, 개발자가 웹사이트 파일, 백업 데이터, 이미지, 영상 등 모든 종류의 파일을 저장하고, 언제 어디서든 인터넷을 통해 접근할 수 있도록 설계되었습니다.

**왜 S3에 계정 정보를 작성해야 하는가?**

AWS Elastic Beanstalk에서 내 계정으로 올린 도커 이미지를 PULL(다운로드) 받아야 하기 때문입니다.

---

### 단계 1: Docker Hub Access Token 생성 및 .dockercfg 파일 준비

#### 1-1. Docker Hub Access Token 생성

1. Docker Hub에 로그인 후 `Personal access tokens` 메뉴로 이동
2. `New access token` 클릭

**토큰 설정**

| 항목 | 설정 값 | 역할 및 의미 |
|------|---------|------------|
| **Access token description** | `My_Spring_App_Token` | 이 토큰의 용도를 명확히 합니다. 나중에 여러 토큰 중 어떤 것이 AWS 배포에 사용되는지 관리하기 쉽습니다. |
| **Expiration date** | `90 days (90일)` | 보안을 위해 만료 기간을 설정했습니다. 만료일이 지나면 이 토큰은 자동으로 무효화되므로, 토큰이 유출되더라도 장기적인 위험이 줄어듭니다. |
| **Access permissions** | `Read & Write` | 이 토큰을 사용하여 당신의 저장소에 있는 이미지를 **다운로드(Read)**하고, 필요하면 **업로드(Write)**할 수 있는 권한을 부여했습니다. EB 배포 시에는 Read 권한만 있어도 충분하지만, Read & Write는 향후 CI/CD 환경 구축 등에도 유연하게 대처할 수 있는 일반적인 설정입니다. |

**생성된 토큰**

```
Token (Password): 랜덤토크 ex abcdefg
```

이 토큰은 당신의 Docker Hub 비밀번호를 대체하는 역할을 하며, 이제 이 정보를 사용하여 AWS Elastic Beanstalk(EB)에 필요한 **인증 파일(`.dockercfg`)**을 만들어야 합니다.

**토큰을 만든 이유**: Pull하려면 아이디와 비밀번호를 제공해주어야 하는데, 비밀번호를 직접 제공해주는 것은 위험하므로 유효한 토큰을 만들어서 비밀번호를 대체합니다!

---

#### 1-2. 인증 정보 조합 및 Base64 인코딩

**1. 인증 정보 조합**

```
Username: hyechang2071148
Token (Password): abcdefg
결합 문자열: hyechang2071148:abcdefg
```

**2. Base64 인코딩 실행**

PowerShell에서 다음 명령을 실행합니다.

```powershell
PS C:\Users\ghddm> [System.Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes("hyechang2071148:abcdefg"))
aHllY2hhbmcyMDcxMTQ4OmRja3JfcGF0XzY2bmtDZ3VyWklwSTBTMHdHd0IzNkdfLWxzNA==
```

출력된 문자열은 Docker Hub에 로그인하기 위해 AWS Elastic Beanstalk(EB)이 필요로 하는 인증 문자열입니다.

---

#### 1-3. .dockercfg 파일 생성

메모장에 다음 내용을 작성합니다.

```json
{
  "https://index.docker.io/v1/": {
    "auth": "aHllY2hhbmcyMDcxMTQ4OmRja3JfcGF0XzY2bmtDZ3VyWklwSTBTMHdHd0IzNkdfLWxzNA=="
  }
}
```

이 파일을 **확장자 없이** `.dockercfg`로 저장합니다.

---

### 단계 2: AWS S3에 인증 정보 업로드

S3는 AWS에서 데이터를 저장하는 공간입니다. 즉 여기다가 아이디와 비밀번호를 Base64로 인코딩한 결과인 `.dockercfg`를 올려놓고, 나중에 JSON에서 이미지를 요청할 때 그 계정을 저장한 S3 위치를 알려줄게~ 거기서 계정 아이디, 비번 참고하고 그걸로 로그인해서 Pull해줘~라는 개념입니다! 이 개념을 명확하게 이해하는 것이 중요합니다.

#### 2-1. AWS 콘솔 접속 및 S3 버킷 생성

1. **AWS 콘솔 접속**: AWS Management Console에 로그인합니다.
2. **S3 이동**: 상단 검색창에 'S3'를 검색하여 서비스로 이동합니다.
3. **버킷 생성**: '버킷 만들기(Create bucket)' 버튼을 클릭합니다.
4. **이름 지정**: 버킷 이름(예: `my-eb-docker-creds-bucket-hyechang`)을 입력합니다. (버킷 이름은 AWS 내에서 전역적으로 유일해야 합니다.)
5. **나머지 설정**: 기본 설정(리전 등)을 유지하고 버킷을 생성합니다.

---

#### 2-2. 파일 저장 경로 설정 (Key 생성)

인증 파일은 보안상 바로 버킷 루트에 두지 않고 폴더를 만들어 관리하는 것이 좋습니다.

1. **버킷 진입**: 방금 만든 버킷 이름을 클릭하여 내부로 들어갑니다.
2. **폴더 생성**: **'폴더 만들기(Create folder)'**를 클릭하여 원하는 폴더 이름(예: `docker-credentials`)을 입력하고 생성합니다.

---

#### 2-3. .dockercfg 파일 업로드

1. **폴더 진입**: `docker-credentials` 폴더를 클릭하여 진입합니다.
2. **파일 업로드**: '업로드(Upload)' 버튼을 클릭하고, 로컬에 저장해 둔 `.dockercfg` 파일을 선택하여 업로드합니다.
3. **최종 경로 확인**: 업로드가 완료되면, 파일의 **전체 경로(Key)**가 다음과 같이 완성됩니다.

```
Key = docker-credentials/.dockercfg
```

#### ✅ S3 인증 정보 설정 완료 요약

| 항목 | 상세 내용 | 역할 |
|------|----------|------|
| **S3 버킷 이름** | `my-eb-docker-creds-bucket-hyechang` | 이 버킷이 인증 파일의 저장소입니다. 이 이름이 `Dockerrun.aws.json` 파일의 `"bucket"` 필드에 들어갑니다. |
| **폴더 (Key 경로)** | `docker-credentials/` | 보안을 위해 파일 경로를 명확히 지정했습니다. |
| **인증 파일** | `.dockercfg` | Docker Hub 로그인 정보(Base64 인코딩된 ID:토큰)를 담고 있습니다. |
| **최종 Key 값** | `docker-credentials/.dockercfg` | 이 경로가 `Dockerrun.aws.json` 파일의 `"key"` 필드에 들어갑니다. |

**예시 (나중에 사용할 JSON 부분)**

```json
"Authentication": {
  "Bucket": "my-eb-docker-creds-bucket-hyechang",
  "Key": "docker-credentials/.dockercfg"
}
```

---

## 7.3.8 Dockerrun.aws.json 작성 및 배포

### 배포 파일 작성

이제 AWS Elastic Beanstalk(EB)에 배포할 `Dockerrun.aws.json` 파일을 최종적으로 완성할 수 있습니다.

#### 중요 개념 정리

앞서 도커 이미지를 만들고 배포하는 방법 2가지를 설명했습니다:

1. **지금 하고 있는 스프링 빌드 이용**: 도커 이미지 만들고, 이 이미지를 다운받을 수 있게 JSON 만들고, 이것을 ZIP 파일로 만들어서 업로드하는 것! 결국 JSON 파일을 업로드한다는 것!
2. **Dockerfile을 만들고**: JAR 파일과 묶어서 ZIP 파일을 업로드하는 것

중요한 것은 이 1, 2 두 가지 방법 모두 **단일 컨테이너**! 내가 만든 지금 스프링 게시판 JAR에 대한 도커 이미지를 만들고, 이 도커 이미지를 컨테이너로 만들 것이고, 이 컨테이너 1개를 실행한다는 것입니다.

---

### EB Docker 배포 방식 및 버전별 원칙

| 구분 | 버전 1 | 버전 2 | 버전 3 |
|------|--------|--------|--------|
| **환경 유형** | 단일 컨테이너 Docker | 다중 컨테이너 Docker (ECS 기반) | 다중 컨테이너 Docker (Docker Compose 기반) |
| **주요 파일** | **Dockerrun.aws.json** | **Dockerrun.aws.json** | **docker-compose.yml** (YAML) |
| **파일 형식** | JSON | JSON | YAML (또는 JSON) |
| **컨테이너 수** | 1개 (하나의 애플리케이션 이미지) | 2개 이상 (여러 서비스 정의 가능) | 2개 이상 (여러 서비스 정의 가능) |
| **컨테이너 관리** | EB가 단일 Docker 프로세스로 관리 | EB가 Amazon ECS를 사용하여 관리 | EB가 Docker Compose를 사용하여 관리 |
| **사용 목적** | 가장 간단한 단일 서비스 배포 | ECS를 통해 다중 컨테이너를 관리하려는 경우. 현재는 잘 사용되지 않음 | 다중 서비스 (MSA) 배포. 개발 환경과 동일한 표준 Docker Compose 사용 |
| **현재 추세** | 빠른 단일 서비스 배포에 여전히 많이 사용됨 | 거의 사용되지 않음 | 다중 컨테이너 배포의 표준으로 가장 권장됨 |
| **예시 항목** | `Image, Ports, Authentication` | `containerDefinitions, volumes` (ECS 작업 정의와 유사) | `services, networks, volumes` (표준 Compose 문법) |

지금은 **version 1**을 사용해서 내가 만든 단일 컨테이너를 배포하는 코드를 작성할 것입니다!

---

### Dockerrun.aws.json 파일 작성

#### 버전 1 양식 (AWS 공식 샘플)

```json
{
  "AWSEBDockerrunVersion": "1",
  "Image": {
    "Name": "janedoe/image",
    "Update": "true"
  },
  "Ports": [
    {
      "ContainerPort": "1234"
    }
  ],
  "Volumes": [
    {
      "HostDirectory": "/var/app/mydb",
      "ContainerDirectory": "/etc/mysql"
    }
  ],
  "Logging": "/var/log/nginx",
  "Entrypoint": "/app/bin/myapp",
  "Command": "--argument"
}
```

#### 실제 작성한 JSON

**Dockerrun.aws.json**

```json
{
  "AWSEBDockerrunVersion": "1",
  
  "Image": {
    "Name": "hyechang2071148/hyechang_cnb:latest",
    "Update": "true"
  },
  
  "Ports": [
    {
      "ContainerPort": "8080"
    }
  ],
  
  "Authentication": {
    "Bucket": "my-eb-docker-creds-bucket-hyechang",
    "Key": "docker-credentials/.dockercfg"
  }
}
```

---

### Dockerrun.aws.json (버전 1) 상세 분석

이 JSON 파일은 Amazon Elastic Beanstalk (EB) 환경에게 단일 컨테이너 애플리케이션을 어떻게 배포하고 실행해야 하는지를 알려주는 지침서입니다.

#### 1. ⚙️ 버전 정보 (AWSEBDockerrunVersion)

| 필드 | 값 | 의미 |
|------|-----|------|
| `"AWSEBDockerrunVersion"` | `"1"` | 이 파일이 단일 컨테이너 Docker 환경 배포에 사용되는 설정 파일임을 명시합니다. |

---

#### 2. 🖼️ 이미지 정보 (Image)

| 필드 | 값 | 의미 |
|------|-----|------|
| `"Name"` | `"hyechang2071148/hyechang_cnb:latest"` | Elastic Beanstalk이 Docker 환경을 구성할 때 가져와야 할 Docker 이미지의 이름입니다. 이 이미지는 Docker Hub와 같은 컨테이너 레지스트리에 저장되어 있습니다. |
| `"Update"` | `"true"` | Elastic Beanstalk이 배포 시점에 레지스트리에서 이 이미지를 다시 다운로드하여 최신 버전을 사용해야 함을 지시합니다. (기본값은 `true`이며, 일반적으로 최신 이미지를 사용하도록 명시합니다.) |

---

#### 3. 🚪 포트 매핑 (Ports)

| 필드 | 값 | 의미 |
|------|-----|------|
| `"ContainerPort"` | `"8080"` | 컨테이너 내부에서 애플리케이션(예: 스프링 부트 서버)이 실제로 듣고 있는 포트 번호입니다. EB는 이 포트와 호스트(EC2 인스턴스)의 외부 포트(일반적으로 80)를 연결합니다. |

**ContainerPort를 지정하는 이유**

EB의 자동 포트 포워딩 메커니즘:

1. **외부 접속 (80번)**: 사용자 또는 로드 밸런서가 EB 환경의 URL로 접속하면, 이는 표준 HTTP 포트인 80번 (또는 HTTPS를 위한 443번) 포트로 들어옵니다. 이 요청은 EB 환경의 EC2 인스턴스(호스트)로 들어갑니다.

2. **호스트 포트 (EB의 기본값)**: EB는 특별히 HostPort를 지정하지 않으면, 외부 접속 포트(80번)를 컨테이너 포트와 연결하기 위한 중계 포트로 사용합니다.

3. **컨테이너 연결 (ContainerPort)**: `Dockerrun.aws.json`에 정의된 `"ContainerPort": "8080"` 정보를 확인합니다. EB 환경은 EC2 호스트의 80번 포트로 들어온 모든 트래픽을 컨테이너 내부의 8080번 포트로 정확하게 연결(포워딩)해줍니다.

**결론**: 사용자는 컨테이너 내부에서 8080만 신경 쓰면 되고, 외부 접속 포트인 80번과의 연결은 EB가 자동으로 처리해주는 편리한 방식입니다. 이는 Docker의 `-p 80:8080` 역할을 EB 환경에서 설정 파일로 대체한 것입니다.

---

#### 4. 🔑 인증 정보 (Authentication) - 핵심 분석

이 부분이 바로 "내 계정 정보가 필요해"라는 내용을 담고 있습니다.

| 필드 | 값 | 의미 |
|------|-----|------|
| `"Bucket"` | `"my-eb-docker-creds-bucket-hyechang"` | Docker 이미지를 가져오기 위해 필요한 인증 정보 파일이 저장된 Amazon S3 버킷의 이름입니다. |
| `"Key"` | `"docker-credentials/.dockercfg"` | S3 버킷 내에서 인증 정보 파일(`.dockercfg` 또는 `config.json`)의 경로와 파일 이름입니다. |

---

### ZIP 파일 생성 및 배포

AWS EB는 배포를 위해 `Dockerrun.aws.json` 파일을 포함하는 `.zip` 파일을 요구합니다.

**압축**: 작성한 `Dockerrun.aws.json` 파일을 선택하고 단독으로 압축하여 `.zip` 파일을 만듭니다 (예: `hyechang-docker-deployment.zip`).

**⚠️ 주의**: JSON 파일 자체가 ZIP 파일의 **최상위 루트**에 있어야 합니다.

---

## 7.3.9 EB 환경 생성 (JSON 배포 방식)

이제 Elastic Beanstalk에서 환경을 만들어 배포해봅시다. **앞서 JAR을 올리는 부분과 설정이 다른 경우가 많으므로 주의해야 합니다!**

### 환경 생성 개요

EB에서 RDS를 사용할 것입니다. 즉 데이터베이스를 활성화할 것입니다.

**의문**: 애초에 MySQL 도커 이미지가 있는데 MySQL 도커 이미지랑 내 애플리케이션 도커 이미지를 같이 배포해서 2개의 컨테이너로 구성하면 되는데 왜 굳이 MySQL 컨테이너를 안 쓰고 RDS를 사용할까?

#### 💡 왜 MySQL 컨테이너 대신 RDS를 사용하는가?

MySQL 컨테이너는 분명히 존재하고 다중 컨테이너 구성(Version 3)으로 EB에 올릴 수도 있지만, 실제 서비스 환경에서는 절대 사용하지 않고 RDS를 사용하는 이유는 다음과 같습니다.

**1. 🛑 데이터 손실 위험 (영속성)**

| 항목 | 설명 |
|------|------|
| **컨테이너의 본질** | 컨테이너는 기본적으로 **휘발성(Ephemeral)**입니다. 컨테이너가 중지되거나 새로운 버전으로 교체되면 그 안에 저장된 모든 데이터가 사라질 수 있습니다. |
| **EB 환경** | EB는 부하에 따라 EC2 인스턴스를 추가/제거(Scale In/Out)하거나, 문제가 생기면 인스턴스를 교체합니다. DB 컨테이너가 이 인스턴스에 있다면, 데이터는 언제든지 사라질 수 있습니다. |
| **RDS의 해결** | RDS는 DB 인스턴스와 데이터 스토리지를 분리하고, 데이터를 여러 가용 영역(AZ)에 복제하거나 자동 백업하여 데이터 손실을 원천적으로 차단합니다. |

**2. 🛡️ 고가용성 및 복구 (안정성)**

| 항목 | MySQL 컨테이너 | RDS |
|------|---------------|-----|
| **장애 대응** | 컨테이너가 다운되면 서비스 전체가 중단됩니다. 복구는 수동으로 진행해야 합니다. | RDS는 Multi-AZ(다중 AZ) 배포 기능을 제공하여, 한 AZ에 문제가 생겨도 자동으로 다른 AZ의 대기 인스턴스로 전환됩니다 (Failover). 이는 서비스의 중단 시간을 최소화합니다. |

**3. 🧑‍💻 운영 부담의 최소화 (관리 용이성)**

| 항목 | MySQL 컨테이너 | RDS |
|------|---------------|-----|
| **관리 주체** | DB 보안 패치, 모니터링, 데이터 백업 스케줄링 및 복구 테스트를 모두 개발팀이 직접 해야 합니다. | AWS가 이 모든 운영 업무를 자동으로 처리해주는 관리형(Managed) 서비스입니다. 개발팀은 오직 애플리케이션 개발에만 집중할 수 있습니다. |

#### 🔑 결론: 분리와 전문화

| 환경 | 구성 | 이유 |
|------|------|------|
| **개발 환경** | MySQL 컨테이너 사용 | 환경 설정을 단순화하고 빠르게 테스트하기 위해 애플리케이션과 DB를 함께 묶습니다. |
| **배포 환경** | 애플리케이션 컨테이너(Version 1) + RDS | 데이터의 안전과 서비스의 안정성을 보장하기 위해 **애플리케이션 컨테이너**만 배포하고, DB 관리는 전문 서비스인 RDS에 완전히 맡깁니다. |

**이것이 Version 1 + RDS 조합이 실무에서 가장 표준적인 배포 구성이 되는 이유입니다.**

그래서 지금은 **version 1 단일 인스턴스 + RDS**를 사용할 것입니다!

---

### 1단계: 새 애플리케이션 & 환경 생성

**애플리케이션 생성**

```
애플리케이션 이름: hyechang-spring-dockerUse-app
```

**환경 생성**

이전과 차이점 위주로 설명하겠습니다.

---

### 2단계: 환경 정보

```
환경 이름: hyechang-spring-dockerUse-app-test
```

---

### 3단계: 플랫폼 설정 (매우 중요)

**이전과의 차이점**

| 항목 | 이전 (JAR 배포) | 현재 (Docker 배포) |
|------|---------------|------------------|
| **플랫폼** | Java | **Docker** ✅ |

Java 플랫폼 대신 **Docker 플랫폼**을 선택합니다!

---

### 4단계: 코드 업로드 (중요)

**이전과의 차이점**

| 항목 | 이전 (JAR 배포) | 현재 (Docker 배포) |
|------|---------------|------------------|
| **업로드 파일** | JAR 파일 | **ZIP 파일** (JSON 포함) ✅ |

JAR 파일 대신 앞서 만든 **ZIP 파일**(`hyechang-docker-deployment.zip`)을 업로드합니다.

---

### 5단계: 사전 설정

```
환경 유형: 단일 인스턴스
```

---

### 6단계: 서비스 액세스 설정 (매우 중요!)

이 단계에서 **큰 차이점**이 있습니다!

#### 서비스 역할

```
서비스 역할: aws-elasticbeanstalk-service-role
```

기존과 동일합니다.

#### EC2 인스턴스 프로파일 (핵심 차이점!)

**⚠️ 중요**: 기존 `aws-elasticbeanstalk-instance-profile`을 사용하는 것이 아닙니다!

**새로운 인스턴스 프로파일 생성**

1. IAM 콘솔에서 새 역할 생성
2. **역할 이름**: `aws-elasticbeanstalk-instance-profile-s3-access`
3. **권한 정책 연결**:
   - `AWSElasticBeanstalkWebTier` (기존과 동일)
   - `AmazonS3ReadOnlyAccess` ✅ **(새로 추가!)**

**왜 `AmazonS3ReadOnlyAccess` 권한이 필요한가?**

업로드한 ZIP의 JSON에서 S3의 버킷과 파일 경로를 알려주는데, EC2 인스턴스에서 그것을 토대로 S3에 접근하여 계정 정보를 참조하고 Pull을 진행해야 하기 때문에 **EC2 인스턴스에게 S3에 접근할 수 있는 권한을 부여**합니다!

```
EC2 인스턴스 프로파일: aws-elasticbeanstalk-instance-profile-s3-access ✅
```

---

### 7단계: 네트워킹, 데이터베이스 및 태그 설정

#### VPC 설정

```
VPC: hyechangSpring-vpc (이전에 만든 VPC 선택)
퍼블릭 IP 주소: 활성화 ✅
인스턴스 서브넷: Public Subnet 2개 선택
```

#### 데이터베이스 설정 (중요!)

**version 1 + RDS 조합**

```
데이터베이스 가용성: 활성화 ✅

데이터베이스 엔진: MySQL 8.0.43
데이터베이스 인스턴스 클래스: db.t3.small
데이터베이스 사용자 이름: hyechang
데이터베이스 암호: [강력한 암호 입력]
데이터베이스 서브넷: Private Subnet 2개 선택
```

---

### 8단계: 인스턴스 트래픽 및 조정 구성

메모리가 부족할 수 있으므로 **t3.small** 또는 **t3.medium**으로 설정합니다.

```
인스턴스 유형: t3.small 또는 t3.medium
```

---

### 9단계: 업데이트, 모니터링 및 로깅 구성 (매우 중요!)

#### 환경 속성 설정 (핵심 차이점!)

**⚠️ 문제**: 환경 변수로 `PROFILES=aws`만 설정하면 문제가 생깁니다!

**왜 이전에는 RDS_HOSTNAME 등이 자동으로 넘어가지 않았나?**

| 환경 | 이전 (Java SE, Tomcat) | 현재 (Docker, 미리 빌드된 이미지) |
|------|----------------------|--------------------------------|
| **애플리케이션 실행 환경** | EC2 호스트 OS에서 직접 실행 | 격리된 Docker 컨테이너 내부에서 실행 |
| **AWS 환경 변수 (RDS_HOSTNAME 등)** | 자동 상속 | 자동 상속 불가능 (격리) |
| **DB 연결 시도 결과** | 성공 (EC2 변수 자동 인식) | 실패 (컨테이너 내부에 변수 없음 → DB 연결 정보 누락) |

**핵심 착각**: "RDS를 연결했으니, AWS가 알아서 DB 정보를 넣어줄 것이다."

**실제**: Docker는 호스트의 정보를 차단합니다. AWS가 알아서 넣어주지 않습니다.

**가장 큰 위험**: DB 연결 실패. 이전처럼 환경 변수를 생략하면, Spring Boot 앱은 실행되자마자 DB 연결 URL을 찾지 못해 구동이 중단되며, 최종적으로 사용자에게 500 Internal Server Error를 반환하게 됩니다.

#### 🛠️ 문제 해결을 위한 필수 조치

EC2 인스턴스에서 컨테이너를 실행시키는데, 이 실행 시 독립된 환경이라 EC2에 자동으로 저장된 RDS 환경 변수가 넘어가지 않습니다! 그래서 직접 수동으로 환경 변수를 설정해줍니다!

**필수 환경 변수 설정**

```
환경 속성:
  SPRING_PROFILES_ACTIVE = aws
  SPRING_DATASOURCE_URL = jdbc:mysql://${RDS_HOSTNAME}:3306/${RDS_DB_NAME}
  SPRING_DATASOURCE_USERNAME = ${RDS_USERNAME}
  SPRING_DATASOURCE_PASSWORD = ${RDS_PASSWORD}
```

이 작업은 EB 콘솔의 환경 속성 기능을 사용하여, EC2 호스트에 있는 AWS 변수들을 명시적으로 컨테이너 내부로 **'터널링(Tunneling)'** 해주는 것입니다.

---

### 최종 환경 구성 요약

**1단계: 환경 구성**

| 항목 | 설정값 |
|------|--------|
| **환경 티어** | 웹 서버 환경 |
| **환경 이름** | `hyechang-spring-dockerUse-app-test` |
| **플랫폼** | Docker running on 64bit Amazon Linux 2023 |
| **애플리케이션 이름** | `hyechang-spring-dockerUse-app` |
| **애플리케이션 코드** | `hyechang-docker-deployment.zip` |

**2단계: 서비스 액세스 구성**

| 항목 | 설정값 |
|------|--------|
| **서비스 역할** | `aws-elasticbeanstalk-service-role` |
| **EC2 인스턴스 프로파일** | `aws-elasticbeanstalk-instance-profile-s3-access` ✅ |

**3단계: 네트워킹, 데이터베이스 및 태그 설정**

| 항목 | 설정값 |
|------|--------|
| **VPC** | `hyechangSpring-vpc` |
| **퍼블릭 IP 주소** | 활성화 |
| **인스턴스 서브넷** | Public Subnet 2개 |
| **데이터베이스 가용성** | 활성화 ✅ |
| **데이터베이스 엔진** | MySQL 8.0.43 |
| **데이터베이스 인스턴스 클래스** | db.t3.small |
| **데이터베이스 사용자 이름** | hyechang |
| **데이터베이스 서브넷** | Private Subnet 2개 |

**4단계: 인스턴스 트래픽 및 크기 조정 구성**

| 항목 | 설정값 |
|------|--------|
| **환경 유형** | 단일 인스턴스 |
| **인스턴스 유형** | t3.small 또는 t3.medium |

**5단계: 업데이트, 모니터링 및 로깅 구성**

| 항목 | 설정값 |
|------|--------|
| **환경 속성** | `SPRING_PROFILES_ACTIVE=aws` |
| | `SPRING_DATASOURCE_URL=jdbc:mysql://${RDS_HOSTNAME}:3306/${RDS_DB_NAME}` |
| | `SPRING_DATASOURCE_USERNAME=${RDS_USERNAME}` |
| | `SPRING_DATASOURCE_PASSWORD=${RDS_PASSWORD}` |

---

### 환경 생성 완료

제출 버튼을 클릭하면 EB가 자동으로 환경을 구축합니다.

```
환경 개요
  상태: Ok ✅
  도메인: hyechang-spring-dockerUse-app-test.eba-hp2jpcdq.ap-northeast-2.elasticbeanstalk.com
  환경 ID: e-q3qni3ujp5
  애플리케이션 이름: hyechang-spring-dockerUse-app
```

**접속 확인**

```
http://hyechang-spring-dockeruse-app-test.eba-hp2jpcdq.ap-northeast-2.elasticbeanstalk.com/
```

애플리케이션이 정상적으로 표시되면 **배포 성공**입니다! 🎉

---

## 7.3.10 방법 2: Dockerfile을 이용한 배포

이번에는 전통적인 방식인 Dockerfile을 직접 작성하여 도커 이미지를 만들고 배포해보겠습니다.

### Dockerfile vs Buildpacks 비교

이전에 배운 `./gradlew bootBuildImage`와 어떤 차이점이 있는지를 잘 비교해야 합니다.

---

### 1단계: 프로젝트 루트로 이동

```cmd
C:\Users\ghddm> cd C:\Users\ghddm\Desktop\SpringBoot\Spring-Boot-Portfolio\spring-boot-project\Spring-Board-Project
```

---

### 2단계: Dockerfile 작성

Dockerfile을 프로젝트 루트 디렉터리에 생성합니다. Docker가 이미지 빌드 시 이 디렉터리 내부의 파일들(특히 빌드된 JAR 파일)에 접근할 수 있도록 하기 위함입니다.

**Dockerfile**

```dockerfile
FROM eclipse-temurin:21-jre-alpine

COPY build/libs/Spring-Board-Project-0.0.1-SNAPSHOT.jar /app.jar

EXPOSE 8080

ENTRYPOINT ["java", "-jar", "/app.jar"]
```

#### Dockerfile 명령어 상세 분석

| 라인 | 코드 | 역할 |
|------|------|------|
| 1 | `FROM eclipse-temurin:21-jre-alpine` | 기반 이미지를 지정합니다. 이 이미지는 **Java 실행 환경(JRE/JDK)**을 제공합니다. |
| 2 | `COPY build/libs/Spring-Board-Project-0.0.1-SNAPSHOT.jar /app.jar` | 호스트(로컬 컴퓨터)에 있는 JAR 파일을 도커 이미지 내부로 복사합니다. |
| 3 | `EXPOSE 8080` | 컨테이너가 8080 포트를 사용한다는 것을 명시합니다. (메타데이터) |
| 4 | `ENTRYPOINT ["java", "-jar", "/app.jar"]` | 컨테이너가 시작될 때 실행할 메인 명령을 정의합니다. |

#### 명령어 하나하나 제대로 분석

**FROM 명령**

`FROM` 명령어는 새로운 이미지를 빌드할 때 기반(Base)이 되는 이미지를 지정합니다.

```dockerfile
FROM eclipse-temurin:21-jre-alpine
```

**`eclipse-temurin`**은 Eclipse Foundation에서 제공하는 OpenJDK (Java Development Kit) 이미지입니다. 이 이미지를 기반으로 사용하면, 사용자는 별도로 JDK를 설치할 필요 없이 Java 코드를 실행할 수 있는 환경을 이미지에 포함하게 됩니다.

태그 `:21-jre-alpine`은 Java 21 JRE 버전과 경량화된 Alpine Linux를 의미합니다.

---

**COPY 명령 분석**

```dockerfile
COPY build/libs/Spring-Board-Project-0.0.1-SNAPSHOT.jar /app.jar
```

`COPY` 명령은 경로를 저장하는 것이 아니라, 빌드 시점에 로컬 파일 시스템에 있는 파일을 도커 이미지 내부의 파일 시스템으로 실제로 복사하는 역할을 합니다.

| 항목 | 경로 | 설명 |
|------|------|------|
| **소스 (Source)** | `build/libs/Spring-Board-Project-0.0.1-SNAPSHOT.jar` | 로컬 PC의 경로 |
| **목적지 (Destination)** | `/app.jar` | 도커 이미지 내부의 경로와 파일명 |

내 컴퓨터에 있는 JAR를 도커 이미지의 `app.jar`(나중에 이것을 실행하는 것!)에다가 복사합니다!

---

**EXPOSE 명령**

```dockerfile
EXPOSE 8080
```

`EXPOSE`는 컨테이너가 런타임에 지정된 네트워크 포트에서 수신 대기한다는 것을 Docker에게 알려주는 메타데이터입니다.

**중요**: `EXPOSE`는 실제로 포트를 열지는 않습니다. 단지 이미지를 사용하는 사람에게 "이 컨테이너는 8080 포트를 사용합니다"라고 문서화하는 역할입니다.

---

**ENTRYPOINT 명령 분석**

```dockerfile
ENTRYPOINT ["java", "-jar", "/app.jar"]
```

`ENTRYPOINT`는 이 이미지를 기반으로 컨테이너가 생성되고 시작될 때 가장 먼저 실행되는 메인 명령어를 정의합니다.

- `["java", "-jar", "/app.jar"]`는 컨테이너 내부에서 **`java -jar /app.jar`**라는 명령어를 실행하라는 의미입니다.
- `/app.jar`는 앞서 `COPY` 명령으로 이미지 내부에 복사해 넣은 파일입니다.

**Array 형식의 이유**: `ENTRYPOINT ["명령", "옵션1", "인수1"]`과 같은 배열 형식(Exec Form)을 사용하는 것은 명령이 쉘(Shell)을 거치지 않고 직접 실행되어 프로세스를 더 효율적으로 관리하고 시그널 처리에 유리하기 때문에 권장되는 방식입니다.

---

#### Dockerfile 요약

"이 Dockerfile은 'eclipse-temurin:21-jre-alpine' 기반 이미지(JDK 환경)를 가져와, 로컬에 빌드된 JAR 파일을 그 이미지 내부의 루트 디렉터리에 `/app.jar`라는 이름으로 복사해 넣어 패키징하고, 컨테이너가 8080 포트를 사용한다고 명시하며, 나중에 이 이미지로 컨테이너를 실행할 때 `java -jar /app.jar` 명령을 실행하도록 설정하는, 도커 이미지를 만들기 위한 스크립트입니다."

**파일 저장**: 도커파일을 작성했으면 **확장자 없이** `Dockerfile`이라는 이름으로 프로젝트 루트 경로에 저장합니다!

```
C:\Users\ghddm\Desktop\SpringBoot\Spring-Boot-Portfolio\spring-boot-project\Spring-Board-Project\
├── Dockerfile ✅
├── build.gradle
├── build/
│   └── libs/
│       └── Spring-Board-Project-0.0.1-SNAPSHOT.jar
```

---

### 3단계: Docker 이미지 빌드

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker build -t hyechang_dockerfile_to_dockerimage .
```

**명령어 분석**

| 부분 | 역할 |
|------|------|
| `docker build` | Docker 이미지를 빌드하는 명령 |
| `-t hyechang_dockerfile_to_dockerimage` | 빌드될 이미지에 태그(이름)를 지정. 태그를 생략하면 자동으로 `:latest`가 붙음 |
| `.` | Dockerfile이 있는 경로 (현재 디렉터리) |

**빌드 과정**

```
[+] Building 52.7s (8/8) FINISHED
 => [internal] load build definition from Dockerfile
 => [internal] load metadata for docker.io/library/eclipse-temurin:21-jre-alpine
 => [1/2] FROM docker.io/library/eclipse-temurin:21-jre-alpine
 => [2/2] COPY build/libs/Spring-Board-Project-0.0.1-SNAPSHOT.jar /app.jar
 => exporting to image
```

**이미지 확인**

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker image list
REPOSITORY                                 TAG       IMAGE ID       CREATED          SIZE
hyechang_dockerfile_to_dockerimage         latest    bd0e2c9af463   12 seconds ago   667MB
hyechang2071148/hyechang_cnb               latest    9b341b7cc7e6   2 days ago       612MB
...
```

이로써 이미지가 잘 만들어진 것을 확인할 수 있습니다.

---

### 4단계: 컨테이너 실행 (로컬 테스트)

앞서 스프링 이미지 빌드로 만든 도커 이미지를 활용하는 것과 동일합니다. 만든 도커 이미지를 실행시켜봅시다.

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker run --name spring_app -p 9000:8080 -d hyechang_dockerfile_to_dockerimage
86ff8ba1752fc4842a2ea07bf7be010d729983a86934019b027bf32dab6a1c75
```

**접속 확인**: `localhost:9000` 시 문제없이 잘 작동됩니다. ✅

---

### 5단계: 컨테이너 종료

```cmd
C:\Users\ghddm\Desktop\...\Spring-Board-Project> docker container stop spring_app
spring_app
```

---

## 7.3.11 Dockerfile + JAR 파일을 EB에 배포

지금까지 내 환경에서 Dockerfile → 도커 이미지 → 컨테이너 실행까지 실습을 해보았고, 이제 `Dockerfile + JAR 파일`을 EB에 배포하는 실습을 해보겠습니다.

### 배포 방식 비교

| 구분 | 이전 방식 (JSON 배포) | 다음 실습 방식 (Dockerfile 배포) |
|------|---------------------|--------------------------------|
| **EB 지시 파일** | Dockerrun.aws.json | Dockerfile |
| **ZIP에 포함되는 파일** | Dockerrun.aws.json 단독 | Dockerfile + build 폴더 (JAR 파일) |
| **배포 방식** | 미리 빌드된 이미지 참조 (EB가 이미지 다운로드) | 소스 코드 빌드 (EB가 Dockerfile을 이용해 이미지 직접 빌드) |
| **장점** | 배포 속도가 빠름 (빌드 시간 절약) | 이미지를 미리 올릴필요 없음 (간단한 배포에 유용) |
| **사용 버전** | EB Version 1 | EB Version 1 |

**핵심 차이점**: 앞서 JSON을 배포했을 때는 **도커 이미지가 만들어져 있어서** EB에서 활용하는 것이었고, 반면 Dockerfile을 사용하면 **EB에서 도커 이미지를 만들 수 있고**, 이것을 실행할 수 있다는 것입니다. 이 작동의 차이를 명확하게 이해할 필요가 있습니다.

---

### 1단계: ZIP 파일 만들기

이전에는 `Dockerrun.aws.json`을 ZIP 파일로 만들어서 배포했습니다. 이번에는 어떤 파일들을 ZIP 파일로 묶어야 할까요?

**답**: `Dockerfile + JAR`을 포함합니다!

#### 💾 ZIP 파일에 build 폴더를 통째로 넣는 이유

핵심은 **Docker 빌드 컨텍스트와 상대 경로의 유지**입니다.

**1. Dockerfile의 경로 (상대 경로)**

Dockerfile 내부의 `COPY` 명령어는 절대 경로가 아닌 상대 경로를 사용합니다.

```dockerfile
COPY build/libs/Spring-Board-Project-0.0.1-SNAPSHOT.jar /app.jar
```

여기서 `build/libs`는 Dockerfile이 위치한 곳(프로젝트 루트)을 기준으로 합니다.

**2. 빌드 컨텍스트의 유지**

EB가 ZIP 파일을 받으면, 그 파일을 압축 해제하고 압축 해제된 폴더를 Docker 빌드의 컨텍스트로 사용합니다.

- ZIP 파일 루트에 `Dockerfile`이 위치하고,
- ZIP 파일 루트에 `build` 폴더가 위치한다면,

Docker는 Dockerfile이 있는 곳에서 `build/libs/...` 경로를 정확하게 찾아 JAR 파일을 이미지 내부로 복사할 수 있습니다.

**3. 경로 수정 불필요**

만약 `build` 폴더를 빼고 JAR 파일만 ZIP 파일의 루트에 넣어버리면, Dockerfile의 `COPY` 명령을 `COPY Spring-Board-Project-0.0.1-SNAPSHOT.jar /app.jar`와 같이 수정해야 하는 번거로움이 생깁니다.

따라서, **Dockerfile과 build 폴더를 함께 묶어 빌드 컨텍스트 구조를 그대로 유지**하는 것이 가장 간단하고 오류를 줄이는 표준적인 방법입니다.

#### 실제로 ZIP 파일 만들기

`hyechang-deployment-use-dockerbuild.zip`라는 이름으로 `build` 폴더와 `Dockerfile`을 묶습니다.

```
hyechang-deployment-use-dockerbuild.zip
├── Dockerfile
└── build/
    └── libs/
        └── Spring-Board-Project-0.0.1-SNAPSHOT.jar
```

---

### 2단계: EB 환경에 재배포

앞에서 만든 환경 `hyechang-spring-dockerUse-app-test`에 새로운 코드를 업로드합니다.

**중요**: 이전에는 JSON을 묶은 `hyechang-docker-deployment.zip` 대신 `hyechang-deployment-use-dockerbuild.zip`을 업로드합니다.

```
Elastic Beanstalk → 환경 → hyechang-spring-dockerUse-app-test → 업로드 및 배포
파일 선택: hyechang-deployment-use-dockerbuild.zip
```

---

### ⚠️ 배포 실패 원인 분석 및 해결

#### 발생한 문제

```
Error: no EXPOSE directive found in Dockerfile, abort deployment
```

| 구분 | 내용 |
|------|------|
| **에러 메시지** | `Error: no EXPOSE directive found in Dockerfile, abort deployment` |
| **원인** | **Elastic Beanstalk (EB)**가 Dockerfile을 분석했을 때, 컨테이너 내부 포트가 무엇인지 알려주는 `EXPOSE` 명령어를 찾지 못했기 때문입니다. |
| **결론** | EB는 포트 정보를 모르므로, 외부 트래픽을 컨테이너 내부로 연결(매핑)할 수 없어 배포를 중단했습니다. |

---

#### EB의 포트 매핑 원칙 (핵심 이해)

Elastic Beanstalk 환경은 사용자가 별도로 설정하지 않아도 다음과 같이 포트를 자동으로 연결합니다.

1. **외부 접근 포트 (고정)**: 웹 표준 포트인 80번을 호스트(EC2 인스턴스)의 외부 입구로 사용합니다. EB가 이 80번 포트 관리를 책임집니다.

2. **내부 포트 (필수 정의)**: 컨테이너 내부에서 애플리케이션이 실제로 듣고 있는 포트를 명시적으로 알려줘야 합니다.

이 자동 연결은 로컬에서 사용했던 `docker run -p 80:[내부 포트]` 옵션과 동일한 역할을 EB가 대신 수행하는 것입니다.

---

#### 🛠️ 해결 방법

**추가해야 할 내용**: Dockerfile에 `EXPOSE 8080` 라인을 추가해야 합니다.

**수정된 Dockerfile**

```dockerfile
FROM eclipse-temurin:21-jre-alpine

COPY build/libs/Spring-Board-Project-0.0.1-SNAPSHOT.jar /app.jar

EXPOSE 8080

ENTRYPOINT ["java", "-jar", "/app.jar"]
```

**8080의 의미**: 네, 8080은 **컨테이너 내부의 스프링 부트 서버 포트**를 말하는 것이 맞습니다.

- 스프링 부트는 기본적으로 내장된 Tomcat 서버를 8080번 포트에서 실행하도록 설정되어 있습니다.
- `EXPOSE 8080`은 이 내장 Tomcat 서버 포트를 외부에 노출할 준비가 되었음을 EB에게 알려주는 것입니다.

**최종 동작 요약**: `EXPOSE 8080`을 추가하면, EB는 이를 확인하고 자동으로 외부 80번 포트 요청을 컨테이너 내부의 8080번 Tomcat 포트로 연결하여 서비스를 실행합니다.

---

#### 🤔 의문: 내가 로컬 컴퓨터에서는 run 했을 때 문제 발생 안 했는데?

로컬 환경에서 Dockerfile에 `EXPOSE 8080` 명령어가 없었음에도 불구하고 컨테이너가 정상 작동했던 핵심 이유는 바로 **사용자가 직접 포트 매핑을 명령**했기 때문입니다.

**로컬 vs. EB 포트 매핑 주체의 차이**

| 환경 | 포트 매핑 방식 | 설명 |
|------|--------------|------|
| **로컬 환경 (수동 매핑)** | `docker run -p 9000:8080` | 사용자가 **직접 실행 명령**으로 "호스트의 9000번 포트를 컨테이너 내부의 8080번 포트에 강제로 연결하라"고 지시. 실행 명령이 Dockerfile의 누락된 정보를 덮어쓰고(Override) 우선 적용되어 정상 작동. |
| **EB 환경 (자동 매핑)** | Dockerfile 분석 | EB는 Dockerfile을 읽어 컨테이너의 포트 정보를 얻고, 그 정보를 기반으로 자신이 직접 포트 매핑을 구성. `EXPOSE 8080`이 없으면 매핑을 진행하지 못하고 에러 발생. |

**결론**: 로컬에서는 사용자가 실행 시점에 `-p`로 직접 매핑했지만, EB에서는 자동화된 매핑을 위해 Dockerfile에 `EXPOSE 8080` 지침이 필수적이었기 때문에 문제가 발생한 것입니다.

**즉, 지금 문제가 되는 것은** EB에서 도커 이미지를 만들었고 이거를 실행할게! `run -p 80(고정):???` 컨테이너 안에 몇 번 포트로 연결해야 하지? 이에 대한 설명이 없다는 것입니다.

---

### 3단계: 수정 후 재배포

수정된 Dockerfile과 build 폴더를 다시 ZIP으로 묶고 EB에 업로드합니다.

```
hyechang-deployment-use-dockerbuild.zip (수정됨)
├── Dockerfile (EXPOSE 8080 추가됨) ✅
└── build/
    └── libs/
        └── Spring-Board-Project-0.0.1-SNAPSHOT.jar
```

**업로드 및 배포**

```
Elastic Beanstalk → 환경 → hyechang-spring-dockerUse-app-test → 업로드 및 배포
파일 선택: hyechang-deployment-use-dockerbuild.zip (수정됨)
```

---

### ⚠️ 또 다른 문제: SQL 초기화 충돌

앞서 만든 환경에 코드만 재배포하다 보니 `schema.sql`, `data.sql`이 재수행되는 문제가 생겼습니다. RDS는 다른 환경에 있으므로 재배포를 해도 데이터베이스는 그대로이기 때문에 기존에 테이블이 있는데 또 만드는 문제가 발생합니다.

```
Caused by: java.sql.SQLSyntaxErrorException: Table 'member' already exists
```

**원인**: RDS는 영속적이어서 테이블이 계속 남아있는데, 스프링 부트가 재배포 시마다 `schema.sql`을 실행하려 했기 때문.

**해결방법**: EB 환경 변수에 `SPRING_SQL_INIT_MODE=never`를 설정.

```
환경 속성 추가:
  SPRING_SQL_INIT_MODE = never ✅
```

---

### 배포 성공 ✅

이로써 `Dockerfile + JAR 파일`로 배포 성공!

---

## 7.3.12 두 가지 배포 방식 비교 및 실무 선호도

### 배포 방식별 특징 비교

| 구분 | JSON 배포 (Dockerrun.aws.json) | Dockerfile 배포 (Dockerfile + JAR) |
|------|--------------------------------|-----------------------------------|
| **핵심 동작** | 레지스트리에서 이미지 다운로드 (Pull) | EB 환경 내에서 이미지 직접 빌드 (Build) |
| **배포 시간** | 매우 빠름 (이미지 다운로드 시간만 소요) | 느림 (JDK 다운로드, JAR 복사, 이미지 빌드 시간 소요) |
| **CI/CD 통합** | 용이함 (CI 파이프라인 최종 단계가 이미지 푸시(Push)만 하면 됨) | 비효율적 (빌드 단계를 EB에 맡기므로 파이프라인 제어가 어려움) |
| **인증 필요성** | 프라이빗 이미지 사용 시 필수 | 필요 없음 (소스코드만 올리므로) |
| **실무 사용 빈도** | 🥇 가장 많이 사용 (프로덕션 배포 표준) | 🥉 상대적으로 적게 사용 (간단한 테스트나 소규모 프로젝트에 사용) |

**실무 선호**: 두 가지 배포 방식 중에서 **미리 이미지를 빌드해 레지스트리에 저장하고 다운받는 방식(JSON 배포)**을 훨씬 더 많이 사용합니다. 이는 **이미지를 다운받는 것이 배포 과정에서 압도적으로 빠르고 편리**하기 때문입니다.

---
## 7.3.13 Docker Compose를 활용한 다중 컨테이너 배포

### 📖 학습 개요

**핵심 주제**: Docker Compose를 이용한 다중 컨테이너 애플리케이션 구성 및 배포  
**사용 기술**: Docker Compose, Nginx 리버스 프록시, AWS Elastic Beanstalk (Version 3)  
**학습 목표**: 
- 컨테이너 간 네트워킹 방식의 진화 과정 이해 (--link → 사용자 정의 네트워크 → Docker Compose)
- Docker Compose를 활용한 다중 서비스 환경 구축
- Nginx 리버스 프록시를 통한 포트 통합 및 라우팅
- 로컬 개발 환경과 실제 배포 환경의 차이점 이해 및 해결

---

## 7.3.13.1 Docker Compose의 등장 배경

### 🔍 이전 방식의 한계

7.3장 초반에서 우리는 단일 컨테이너 배포 방식을 학습했습니다. 하지만 실제 애플리케이션은 여러 서비스로 구성됩니다:

- **애플리케이션 서버** (Spring Boot)
- **데이터베이스 서버** (MySQL)
- **캐시 서버** (Redis, 선택적)
- **웹 서버/프록시** (Nginx, 선택적)

이러한 다중 컨테이너 환경에서 발생하는 문제들을 해결하기 위해 컨테이너 간 통신 방식이 진화해왔습니다.

---

## 7.3.13.2 컨테이너 간 통신 방식의 진화

### 1️⃣ --link 방식 (레거시)

**사용 예시**

```bash
# DB 컨테이너 실행
docker run --name hyechang_db \
  -e MYSQL_RANDOM_ROOT_PASSWORD=yes \
  -e MYSQL_DATABASE=mydb \
  -e MYSQL_USER=hyechang \
  -e MYSQL_PASSWORD=password \
  -d mysql

# App 컨테이너 실행 (--link 사용)
docker run -d --name spring_app_container \
  --link hyechang_db:hdb \
  -p 8080:8080 \
  -e DB_HOSTNAME=hdb \
  -e DB_PORT=3306 \
  -e DB_NAME=mydb \
  -e DB_USERNAME=hyechang \
  -e DB_PASSWORD=password \
  hyechang/spring_app
```

#### --link 방식의 문제점

| 문제 유형 | 설명 |
|----------|------|
| **별칭 강제** | 컨테이너 이름과 별개로 별칭을 관리해야 하는 번거로움 |
| **환경 변수 관리** | 모든 설정을 `docker run` 명령에 `-e` 옵션으로 직접 입력 |
| **IP 주소 기반** | 내부적으로 정적 IP 주소를 사용하여 컨테이너 재시작 시 불안정 |
| **오케스트레이션 불가** | 단일 호스트에서만 작동, Docker Swarm이나 Kubernetes 미지원 |

---

### 2️⃣ 사용자 정의 네트워크 (User-Defined Network)

**사용 예시**

```bash
# 네트워크 생성
docker network create spring_db_net

# DB 컨테이너 실행
docker run --network spring_db_net \
  --name hyechang_db \
  -e MYSQL_RANDOM_ROOT_PASSWORD=yes \
  -e MYSQL_DATABASE=mydb \
  -e MYSQL_USER=hyechang \
  -e MYSQL_PASSWORD=password \
  -d mysql

# App 컨테이너 실행
docker run -d --name spring_app_container \
  --network spring_db_net \
  -p 8080:8080 \
  -e DB_HOSTNAME=hyechang_db \  # 별칭 없이 컨테이너 이름 사용!
  -e DB_PORT=3306 \
  -e DB_NAME=mydb \
  -e DB_USERNAME=hyechang \
  -e DB_PASSWORD=password \
  hyechang/spring_app
```

#### 사용자 정의 네트워크의 장점

| 항목 | 설명 |
|------|------|
| **이름 기반 통신** | 컨테이너 이름을 DNS처럼 사용하여 통신 (별칭 불필요) |
| **설정 간소화** | 복잡한 별칭 관리 없이 직관적인 컨테이너 이름 사용 |
| **안정성** | Docker 내장 DNS 서비스 사용으로 IP 변경에 독립적 |
| **격리성** | 네트워크별로 컨테이너 그룹을 논리적으로 분리 가능 |

**하지만 여전히 문제는 남아있습니다**: 매번 긴 `docker run` 명령어를 입력해야 하고, 여러 컨테이너를 동시에 관리하기 어렵습니다.

---

### 3️⃣ Docker Compose (현재 표준)

Docker Compose는 사용자 정의 네트워크의 장점을 자동화하고, YAML 파일 하나로 전체 다중 컨테이너 환경을 정의할 수 있게 해줍니다.

**핵심 개념**

```
YAML 파일 작성 → docker compose up → 모든 컨테이너 자동 실행 + 네트워크 자동 구성
```

---

## 7.3.13.3 Docker Compose 기본 개념

### 📦 docker-compose.yml 파일이란?

Docker Compose는 여러 컨테이너로 구성된 애플리케이션을 하나의 YAML 파일에 정의하고, 단일 명령어로 실행할 수 있게 해주는 도구입니다.

#### 파일명 규칙

| 파일명 | 자동 인식 | 설명 |
|--------|----------|------|
| `docker-compose.yml` | ✅ | 가장 일반적 (권장) |
| `docker-compose.yaml` | ✅ | yml과 동일 |
| `compose.yml` | ✅ | Compose V2부터 공식 권장 |
| `compose.yaml` | ✅ | compose.yml과 동일 |
| `custom.yml` | ❌ | `-f` 옵션 필요 |

**사용자 지정 파일명 사용 시**

```bash
docker compose -f custom.yml up -d
```

**권장**: 대부분의 프로젝트에서 `docker-compose.yml`을 사용하는 것이 표준입니다.

---

### 🏗️ docker-compose.yml 기본 구조

```yaml
# 프로젝트 이름 (선택, 생략 시 디렉터리 이름 사용)
name: [프로젝트 이름]

services:
  # -------------------- 서비스 1 (App) --------------------
  [App 서비스 이름]:
    # 이미지 다운로드 방식
    image: [이미지 이름:태그]
    # 또는 빌드 방식
    build:
      context: [Dockerfile 경로]
      dockerfile: Dockerfile
    
    container_name: [컨테이너 이름]
    ports:
      - "[호스트 포트]:[컨테이너 포트]"
    expose:
      - "[내부 네트워크용 포트]"
    depends_on:
      - [의존하는 서비스 이름]
    environment:
      - [환경변수 키]=[값]
    restart: always

  # -------------------- 서비스 2 (DB) --------------------
  [DB 서비스 이름]:
    image: [DB 이미지 이름:태그]
    container_name: [DB 컨테이너 이름]
    volumes:
      - [볼륨 이름]:[컨테이너 내부 경로]
    environment:
      - [DB 환경변수]
    restart: always

# 볼륨 정의
volumes:
  [볼륨 이름]:
```

---

### 🔑 주요 필드 상세 분석

#### 1. `services:`

**의미**: 모든 서비스(컨테이너) 정의를 시작하는 최상위 블록

| 항목 | 설명 |
|------|------|
| **1 서비스 = 1 컨테이너** | 기본적으로 각 서비스는 하나의 컨테이너 인스턴스를 생성 |
| **확장 가능** | `docker compose up --scale web=3` 명령으로 동일 서비스의 컨테이너를 여러 개 실행 가능 |
| **네트워크 자동 구성** | 모든 서비스는 자동으로 생성되는 네트워크에 연결되어 서비스 이름으로 통신 가능 |

---

#### 2. `image:` vs `build:`

**이미지 준비 방식 비교**

| 방식 | 사용 시기 | 장점 | 단점 |
|------|----------|------|------|
| `image:` | 미리 빌드된 이미지 사용 | 배포 속도 빠름, CI/CD 통합 용이 | 이미지를 사전 준비해야 함 |
| `build:` | 소스 코드로 현장 빌드 | 소스만 제공하면 됨 | 배포 시 빌드 시간 소요 |

**image 방식**

```yaml
services:
  app:
    image: hyechang2071148/spring-compose-image:latest
```

**build 방식**

```yaml
services:
  app:
    build:
      context: .  # Dockerfile이 있는 경로
      dockerfile: Dockerfile  # Dockerfile 이름
```

---

#### 3. `ports:` vs `expose:`

**매우 중요한 차이점!**

| 설정 | 외부 접근 | 컨테이너 간 통신 | 호스트 포트 사용 |
|------|----------|-----------------|----------------|
| `ports:` | ✅ `localhost:포트` 가능 | ✅ 가능 | ✅ 호스트 포트 바인딩 |
| `expose:` | ❌ 외부 접근 불가 | ✅ 내부 네트워크만 가능 | ❌ 사용 안 함 |

**ports 예시 (외부 노출)**

```yaml
services:
  app:
    ports:
      - "8080:8080"  # localhost:8080 접근 가능
```

**expose 예시 (내부 전용)**

```yaml
services:
  app:
    expose:
      - "8080"  # 같은 네트워크의 다른 컨테이너만 app:8080으로 접근 가능
```

**실무 사용 패턴**: Nginx 리버스 프록시를 사용할 때, 애플리케이션 컨테이너는 `expose`만 사용하고 Nginx만 `ports`로 외부에 노출합니다.

---

#### 4. `depends_on:`

**의미**: 컨테이너 시작 순서 지정

```yaml
services:
  app:
    depends_on:
      - db  # db 서비스가 먼저 시작된 후 app 시작
```

**중요한 오해**

| 오해 | 실제 |
|------|------|
| "DB가 완전히 준비될 때까지 기다린다" | ❌ 단순히 컨테이너 시작 순서만 보장 |
| "DB 연결이 가능한 상태를 확인한다" | ❌ 서비스의 준비 상태(ready)는 확인하지 않음 |

**해결책**: 애플리케이션에서 DB 연결 재시도 로직 구현 또는 `restart: always` 활용

---

#### 5. `environment:`

**의미**: 컨테이너 내부에 환경 변수 주입

```yaml
services:
  app:
    environment:
      DB_HOSTNAME: db
      DB_PORT: 3306
      DB_NAME: mydb
      DB_USERNAME: hyechang
      DB_PASSWORD: password
```

**Spring Boot와의 연동**

`application-docker.properties`:

```properties
spring.datasource.url=jdbc:mysql://${db.hostname}:${db.port}/${db.name}
spring.datasource.username=${db.username}
spring.datasource.password=${db.password}
```

환경 변수 `DB_HOSTNAME`은 Spring Boot에서 `db.hostname`으로 자동 매핑됩니다.

---

#### 6. `volumes:`

**두 가지 사용 방식**

**① 바인드 마운트 (Bind Mount) - 설정 파일 주입**

```yaml
services:
  nginx:
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
```

| 항목 | 설명 |
|------|------|
| `./nginx.conf` | 호스트 PC의 파일 경로 |
| `/etc/nginx/nginx.conf` | 컨테이너 내부 경로 |
| `:ro` | Read-Only (읽기 전용) |

**용도**: 호스트의 설정 파일을 컨테이너에 주입하여 실시간 반영

**② 이름 있는 볼륨 (Named Volume) - 데이터 영속화**

```yaml
services:
  db:
    volumes:
      - db-volume:/var/lib/mysql

volumes:
  db-volume:
```

| 항목 | 설명 |
|------|------|
| `db-volume` | Docker가 관리하는 볼륨 이름 |
| `/var/lib/mysql` | 컨테이너 내부의 데이터 저장 경로 |

**용도**: 컨테이너가 삭제되어도 데이터를 유지 (DB 데이터, 로그 등)

**핵심 차이점**

| 항목 | 바인드 마운트 | 이름 있는 볼륨 |
|------|-------------|--------------|
| **호스트 경로** | 사용자 지정 | Docker 관리 |
| **주 용도** | 설정 파일 주입 | 데이터 영속화 |
| **실시간 반영** | ✅ 가능 | ❌ 불가 |

---

#### 7. `restart:`

**컨테이너 재시작 정책**

| 옵션 | 동작 |
|------|------|
| `no` | 자동 재시작 안 함 (기본값) |
| `always` | 항상 재시작 (수동 중지 시에도) |
| `on-failure` | 오류 종료 시에만 재시작 |
| `unless-stopped` | 사용자가 중지하지 않는 한 재시작 |

**실무 권장**: `always` (DB 초기화 대기 실패 등에 유용)

---

#### 8. `container_name:` (선택적)

**스케일링과의 관계**

```yaml
services:
  app:
    container_name: my-app  # 고정 이름
```

**문제점**: 스케일링 시 컨테이너 이름 충돌

```bash
docker compose up --scale app=3  # 실패! 이름이 중복됨
```

**해결책**: `container_name`을 생략하면 Docker Compose가 자동으로 `프로젝트명-서비스명-번호` 형식으로 생성

```
예: hyechang-compose-app-1, hyechang-compose-app-2, hyechang-compose-app-3
```

---

## 7.3.13.4 로컬 환경 실습: 이미지 다운로드 방식

### 1단계: 애플리케이션 프로파일 추가

**`application-docker.properties`**

```properties
spring.datasource.url=jdbc:mysql://${db.hostname}:${db.port}/${db.name}
spring.datasource.username=${db.username}
spring.datasource.password=${db.password}

spring.session.jdbc.initialize-schema=always
```

---

### 2단계: Docker 이미지 빌드 및 푸시

**Dockerfile**

```dockerfile
FROM eclipse-temurin:21-jre-alpine

COPY build/libs/Spring-Board-Project-0.0.1-SNAPSHOT.jar /app.jar

EXPOSE 8080

ENTRYPOINT ["java", "-jar", "/app.jar"]
```

**빌드 및 푸시**

```bash
# 이미지 빌드
docker build -t spring-compose-image .

# 태그 변경
docker tag spring-compose-image:latest hyechang2071148/spring-compose-image:latest

# Docker Hub에 푸시
docker push hyechang2071148/spring-compose-image:latest
```

---

### 3단계: docker-compose.yml 작성

**`docker-compose.yml`**

```yaml
name: hyechang-compose

services:
  app:
    image: hyechang2071148/spring-compose-image:latest
    restart: always
    ports:
      - "8080:8080"
    depends_on:
      - db
    environment:
      PROFILES: docker
      DB_HOSTNAME: db
      DB_PORT: 3306
      DB_NAME: mydb
      DB_USERNAME: hyechang
      DB_PASSWORD: password

  db:
    image: mysql:latest
    restart: always
    volumes:
      - db-volume:/var/lib/mysql
    environment:
      MYSQL_RANDOM_ROOT_PASSWORD: yes
      MYSQL_DATABASE: mydb
      MYSQL_USER: hyechang
      MYSQL_PASSWORD: password

volumes:
  db-volume:
```

---

### 4단계: Docker Compose 실행

```bash
docker compose up -d
```

**출력 결과**

```
[+] Running 4/4
 ✔ Network hyechang-compose_default   Created
 ✔ Volume hyechang-compose_db-volume  Created
 ✔ Container hyechang-compose-db-1    Started
 ✔ Container hyechang-compose-app-1   Started
```

**컨테이너 확인**

```bash
docker container list
```

**접속 확인**

```
http://localhost:8080
```

---

### 5단계: 주요 명령어

| 명령어 | 동작 |
|--------|------|
| `docker compose up -d` | 모든 서비스 백그라운드 실행 |
| `docker compose down` | 모든 서비스 중지 및 제거 |
| `docker compose down -v` | 볼륨까지 함께 삭제 |
| `docker compose logs -f` | 로그 실시간 확인 |
| `docker compose ps` | 실행 중인 서비스 확인 |

---

### ⚠️ YAML 작성 주의사항

Docker Compose의 YAML 파일은 문법이 매우 엄격합니다.

**발생 가능한 오류**

| 오류 메시지 | 원인 | 해결책 |
|-----------|------|--------|
| `found a tab character` | 탭(Tab) 사용 | 공백(Space)만 사용 |
| `mapping values are not allowed` | 들여쓰기 레벨 불일치 | 모든 항목의 들여쓰기 정확히 맞추기 |
| `additional properties not allowed` | 하위 항목이 상위 레벨에 잘못 배치 | 서비스 정의를 `services:` 바로 아래 동일 레벨로 배치 |
| `non-string key in ports` | 포트 번호 형식 오류 | `"8080:8080"`처럼 큰따옴표로 묶기 |
| `volume missing a mount target` | 볼륨 매핑 구문 오류 | `db-volume:/var/lib/mysql` 형식으로 콜론 주변 공백 제거 |

**올바른 형식**

```yaml
services:
  app:  # services 바로 아래
    ports:
      - "8080:8080"  # 큰따옴표 사용
    volumes:
      - db-volume:/var/lib/mysql  # 공백 없이
```

---

## 7.3.13.5 로컬 환경의 한계와 EB 배포 문제

### 🚨 문제 상황

로컬 환경에서는 `ports: ["8080:8080"]`로 설정하여 `localhost:8080`으로 직접 접근이 가능했습니다.

```yaml
services:
  app:
    ports:
      - "8080:8080"  # 로컬에서는 문제없음
```

**하지만 AWS Elastic Beanstalk(EB) 환경에서는 문제가 발생합니다.**

---

### 🔒 EB 환경의 보안 제약

**EB의 포트 제한**

```
인터넷 → Load Balancer → EC2 인스턴스 (보안 그룹)
                           ↓
                      포트 80만 열려있음!
```

| 항목 | 설명 |
|------|------|
| **외부 접근 포트** | 80번 (HTTP) 또는 443번 (HTTPS)만 허용 |
| **내부 포트** | 8080, 3306 등은 외부에서 직접 접근 불가 |
| **문제** | 여러 애플리케이션이 있어도 80번 포트 하나로만 받아야 함 |

**예시**: `your-app.elasticbeanstalk.com:8080` 접근 시도 → 방화벽 차단!

---

### 💡 해결책: Nginx 리버스 프록시

**핵심 원리**

```
외부 요청 (80 포트)
    ↓
Nginx (리버스 프록시) ← 80 포트만 외부 노출
    ↓
경로/호스트 판단
    ↓
/           → app 컨테이너 (내부 8080)
/admin/     → 관리자 페이지 (내부 3000)
```

**장점**

- 외부 포트는 80번 하나만 사용
- Nginx가 URL 경로를 보고 알맞은 컨테이너로 라우팅
- 각 컨테이너는 외부 포트 없이 내부 네트워크로만 통신

---

## 7.3.13.6 Nginx 리버스 프록시 구성

### 수정된 docker-compose.yml

**`docker-compose.yml`**

```yaml
name: hyechang-compose

services:
  nginx:
    image: nginx:latest
    ports:
      - "80:80"  # 유일한 외부 노출 포트
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    restart: always

  app:
    image: hyechang2071148/spring-compose-image:latest
    restart: always
    expose:
      - "8080"  # 내부 네트워크 전용
    depends_on:
      - db
    environment:
      PROFILES: docker
      DB_HOSTNAME: db
      DB_PORT: 3306
      DB_NAME: mydb
      DB_USERNAME: hyechang
      DB_PASSWORD: password

  db:
    image: mysql:latest
    restart: always
    volumes:
      - db-volume:/var/lib/mysql
    environment:
      MYSQL_RANDOM_ROOT_PASSWORD: yes
      MYSQL_DATABASE: mydb
      MYSQL_USER: hyechang
      MYSQL_PASSWORD: password

volumes:
  db-volume:
```

---

### Nginx 설정 파일

**`nginx.conf`**

```nginx
events {
    worker_connections 1024;
}

http {
    upstream app {
        server app:8080;
    }
    
    server {
        listen 80;
        
        location / {
            proxy_pass http://app/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
```

---

### 📋 Nginx 설정 상세 분석

#### 1. `events` 블록

```nginx
events {
    worker_connections 1024;
}
```

| 항목 | 설명 |
|------|------|
| `worker_connections` | 워커 프로세스당 최대 동시 연결 수 |
| `1024` | 테스트/소규모 환경의 일반적 기본값 |

---

#### 2. `upstream` 블록 (백엔드 서버 그룹 정의)

```nginx
upstream app {
    server app:8080;
}
```

| 항목 | 설명 |
|------|------|
| `upstream app` | 백엔드 서버 그룹의 별칭 |
| `server app:8080` | `app`은 docker-compose의 서비스 이름, `8080`은 내부 포트 |

**동작 원리**: Docker 내부 DNS가 `app`이라는 이름을 해당 컨테이너의 IP 주소로 자동 해석합니다.

---

#### 3. `server` 블록 (포트 및 라우팅 규칙)

```nginx
server {
    listen 80;
    
    location / {
        proxy_pass http://app/;
        # ...
    }
}
```

**`listen 80`의 의미**

- Nginx 컨테이너의 **내부 포트 80**으로 들어오는 요청을 처리
- `docker-compose.yml`의 `ports: ["80:80"]`과 매핑됨

**포트 변경 시 주의사항**

만약 `listen 800`으로 변경한다면:
- `docker-compose.yml`: `ports: ["80:800"]`으로 변경
- `nginx.conf`: `listen 800;`으로 변경

---

#### 4. `location` 블록 (URL 매칭 및 라우팅)

```nginx
location / {
    proxy_pass http://app/;
}
```

**`location /`의 의미**

- 모든 요청 경로(`/`, `/login`, `/images/`)를 이 규칙으로 처리

---

#### 5. `proxy_pass` 슬래시(/) 규칙 (매우 중요!)

**경로를 제거하는 경우 (권장)**

```nginx
location /hyechang/ {
    proxy_pass http://app/;  # 슬래시 있음
}
```

| 요청 URL | 전달되는 URL | 경로 처리 |
|---------|-------------|----------|
| `localhost/hyechang/boards` | `http://app/boards` | `/hyechang/` 제거 ✅ |

**경로를 유지하는 경우**

```nginx
location /hyechang/ {
    proxy_pass http://app;  # 슬래시 없음
}
```

| 요청 URL | 전달되는 URL | 경로 처리 |
|---------|-------------|----------|
| `localhost/hyechang/boards` | `http://app/hyechang/boards` | `/hyechang/` 유지 ❌ |

**결론**: `proxy_pass` 뒤에 슬래시(`/`)를 붙이면 매칭된 경로를 제거하고 전달합니다.

---

#### 6. `proxy_set_header` (표준 설정)

```nginx
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header X-Forwarded-Proto $scheme;
```

**역할**: 백엔드 애플리케이션이 클라이언트의 진짜 정보를 알 수 있도록 HTTP 헤더를 전달합니다.

| 헤더 | 내용 |
|------|------|
| `Host` | 원본 호스트 이름 |
| `X-Real-IP` | 클라이언트의 실제 IP 주소 |
| `X-Forwarded-For` | 프록시 체인을 거친 IP 주소 목록 |
| `X-Forwarded-Proto` | 원본 프로토콜 (http 또는 https) |

**참고**: 이 설정은 리버스 프록시 환경에서 거의 고정적으로 사용하는 표준입니다.

---

### 로컬 실행 및 확인

```bash
docker compose up -d
```

**출력**

```
[+] Running 5/5
 ✔ Network hyechang-compose_default    Created
 ✔ Volume hyechang-compose_db-volume   Created
 ✔ Container hyechang-compose-db-1     Started
 ✔ Container hyechang-compose-app-1    Started
 ✔ Container hyechang-compose-nginx-1  Started
```

**접속 확인**

```
http://localhost (포트 생략 가능, 80번이 기본)
```

---

## 7.3.13.7 EB 배포: 이미지 다운로드 방식

### 배포 파일 구성

**ZIP 파일에 포함할 파일**

```
deployment.zip
├── docker-compose.yml
├── nginx.conf
└── Dockerrun.aws.json  # 인증 정보 (private 이미지용)
```

---

### Dockerrun.aws.json (인증 전용)

**`Dockerrun.aws.json`**

```json
{
  "AWSEBDockerrunVersion": "1",
  
  "Authentication": {
    "Bucket": "my-eb-docker-creds-bucket-hyechang",
    "Key": "docker-credentials/.dockercfg"
  }
}
```

**역할**: EB가 비공개 Docker Hub 저장소에서 이미지를 다운로드할 때 필요한 인증 정보 제공

**참고**: S3에 `.dockercfg` 파일을 미리 업로드해두어야 합니다 (7.3.7절 참조).

---

### EB 환경 생성

**환경 정보**

```
애플리케이션 이름: Hyechang-spring-compose-nginx-app
환경 이름: Hyechang-spring-compose-nginx-app-env
플랫폼: Docker running on 64bit Amazon Linux 2023
환경 유형: 단일 인스턴스
```

**배포 파일**

```
업로드: deployment.zip
버전 레이블: 1.0.0
```

**배포 성공 확인**

```
http://[your-app].elasticbeanstalk.com
```

---

## 7.3.13.8 EB 배포: 빌드 방식

### 배포 파일 구성

**ZIP 파일에 포함할 파일**

```
deployment-build.zip
├── docker-compose.yml  # build: 방식 사용
├── nginx.conf
├── Dockerfile
└── build/
    └── libs/
        └── Spring-Board-Project-0.0.1-SNAPSHOT.jar
```

---

### 수정된 docker-compose.yml

**`docker-compose.yml`**

```yaml
name: hyechang-compose

services:
  nginx:
    image: nginx:latest
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - app
    restart: always

  app:
    # image: hyechang2071148/spring-compose-image  # 주석 처리
    build:
      context: .
      dockerfile: Dockerfile
    restart: always
    expose:
      - "8080"
    depends_on:
      - db
    environment:
      PROFILES: docker
      DB_HOSTNAME: db
      DB_PORT: 3306
      DB_NAME: mydb
      DB_USERNAME: hyechang
      DB_PASSWORD: password

  db:
    image: mysql:latest
    restart: always
    volumes:
      - db-volume:/var/lib/mysql
    environment:
      MYSQL_RANDOM_ROOT_PASSWORD: yes
      MYSQL_DATABASE: mydb
      MYSQL_USER: hyechang
      MYSQL_PASSWORD: password

volumes:
  db-volume:
```

---

### Dockerfile

**`Dockerfile`**

```dockerfile
FROM eclipse-temurin:21-jre-alpine

COPY build/libs/Spring-Board-Project-0.0.1-SNAPSHOT.jar /app.jar

EXPOSE 8080

ENTRYPOINT ["java", "-jar", "/app.jar"]
```

---

### 로컬 테스트

**이미지 빌드**

```bash
docker compose build app
```

**실행**

```bash
docker compose up -d
```

---

### EB 배포

**배포 파일**

```
업로드: deployment-build.zip
```

**주의사항**: `Dockerrun.aws.json`은 불필요합니다 (외부 레지스트리에서 이미지를 가져오지 않으므로).

---

## 7.3.13.9 두 가지 배포 방식 최종 비교

### 배포 방식별 특징

| 구분 | 이미지 다운로드 방식 | 빌드 방식 |
|------|-------------------|----------|
| **docker-compose.yml** | `image:` 사용 | `build:` 사용 |
| **ZIP 구성** | yml + nginx.conf + Dockerrun.aws.json | yml + nginx.conf + Dockerfile + build/ |
| **빌드 시점** | CI/CD 파이프라인 또는 로컬 | EB 환경 내부 (EC2 인스턴스) |
| **배포 속도** | ⚡ 빠름 (이미지 다운로드만) | 🐢 느림 (빌드 시간 소요) |
| **인증 필요** | ✅ Private 이미지 시 필요 | ❌ 불필요 |
| **실무 선호도** | 🥇 높음 (권장) | 🥉 낮음 (테스트용) |

---

## 7.3.13.10 최종 정리 및 다음 단계

### ✅ 학습 완료 내용

| 번호 | 주제 | 핵심 내용 |
|------|------|----------|
| 1 | **컨테이너 통신 방식 진화** | --link → 사용자 정의 네트워크 → Docker Compose |
| 2 | **Docker Compose 기본** | YAML 파일 구조, 서비스 정의, 볼륨, 네트워크 |
| 3 | **로컬 실습** | 다중 컨테이너 환경 구축 및 테스트 |
| 4 | **Nginx 리버스 프록시** | 포트 통합, URL 라우팅, 설정 파일 작성 |
| 5 | **EB 배포** | 이미지 다운로드 방식과 빌드 방식 모두 경험 |

---

### 🎯 획득한 핵심 역량

**기술적 역량**

- ✅ **다중 컨테이너 관리**: Docker Compose를 활용한 서비스 오케스트레이션
- ✅ **네트워킹 이해**: 컨테이너 간 통신, DNS 기반 서비스 디스커버리
- ✅ **리버스 프록시**: Nginx를 활용한 포트 통합 및 라우팅
- ✅ **배포 전략**: 이미지 준비 방식에 따른 배포 파일 구성

**실무 경험**

- ✅ **로컬 개발 환경**: Docker Compose로 개발 환경 표준화
- ✅ **클라우드 배포**: EB Version 3를 활용한 실전 배포
- ✅ **문제 해결**: 로컬과 배포 환경의 차이점 이해 및 해결

---

### 🚀 다음 단계: CI/CD 자동화

지금까지 우리는 수동으로 이미지를 빌드하고, ZIP 파일을 만들어 EB에 업로드했습니다.

**현재 배포 프로세스의 문제점**

```
1. 로컬에서 코드 수정
   ↓
2. Gradle로 빌드
   ↓
3. Docker 이미지 빌드
   ↓
4. Docker Hub에 푸시
   ↓
5. ZIP 파일 생성
   ↓
6. EB 콘솔에서 수동 업로드
   ↓
7. 배포 완료 대기
```

**문제점**

- ⏰ 시간 소모: 전체 과정이 15~20분 소요
- 🤦 휴먼 에러: 단계를 빠뜨리거나 실수할 가능성
- 🔄 반복 작업: 매번 동일한 과정 반복

**다음 장 예고: GitHub Actions를 활용한 CI/CD**

7.4장에서는 이 모든 과정을 자동화하여, **코드를 GitHub에 push만 하면 자동으로 빌드-테스트-배포**까지 진행되는 CI/CD 파이프라인을 구축하게 됩니다.

```
GitHub에 코드 push
    ↓
GitHub Actions 자동 실행
    ↓
빌드 → 테스트 → Docker 이미지 생성 → EB 배포
    ↓
완료 (전체 5분 소요)
```

**기대 효과**

- ✅ 배포 시간 단축: 20분 → 5분
- ✅ 휴먼 에러 제거: 자동화된 프로세스
- ✅ 팀 협업 향상: 누구나 쉽게 배포 가능
- ✅ 실무 표준: 현대적인 DevOps 프랙티스 체험


---

## 7.4 CI/CD 자동화 (GitHub Actions)
---




